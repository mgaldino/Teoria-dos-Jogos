[["index.html", "Political Regime Model Capítulo1 Prefácio", " Political Regime Model Manoel Galdino 2024-03-09 Capítulo1 Prefácio Esse livro é o resultado das notas de aulas do curso de graduação da USP Teoria dos Jogos para Cientistas Sociais. O livro é largamente inspirado no de Steven Tadelis, Game Theory, an introduction, além de muitos materiais na internet para poder citá-los individualmente. "],["introdução.html", "Capítulo2 Introdução 2.1 Dilema do Prisioneiro 2.2 Dilema da Ação Coletiva 2.3 Happy hour 2.4 Dilema da Segurança 2.5 Cuidar da casa 2.6 Resumo de notação matemática 2.7 Referências", " Capítulo2 Introdução Uma das principais preocupações durante as eleições gerais de 2022 no Brasil era a disseminação de desinformação, conhecida popularmente como “fake news”. A utilização de redes sociais e aplicativos de mensagens para promover desinformação por eleitores e candidatos representava um importante ponto de potencial controle sobre a desinformação. Foi comum observar o Tribunal Superior Eleitoral determinando que plataformas removessem conteúdos contendo “fake news” eleitorais1. No entanto, essa situação se assemelhava a um jogo de “gato e rato”, uma vez que nada impedia que os divulgadores de “fake news” criassem novas postagens, perpetuando a disseminação de desinformação. Esse tipo de cenário político, no qual os atores precisam tomar decisões estratégicas, ou seja, planejar suas ações tentando antecipar as respostas dos outros, é exatamente o que a teoria dos jogos busca modelar e analisar. A política é repleta de situações em que um indivíduo deve agir supondo que os demais participantes do jogo político reagirão às suas ações e até mesmo tentarão antecipar seus movimentos, fazendo suposições e conjecturas sobre os outros. Isso representa uma das maiores dificuldades para os cientistas políticos na previsão dos efeitos de reformas eleitorais, por exemplo. Apesar de ser um tema frequentemente debatido e solicitado pela sociedade, muitas propostas são elaboradas como se o mundo não fosse estratégico, ou seja, como se os agentes políticos não fossem modificar seu comportamento devido às novas regras adotadas. Considere, por exemplo, a proibição de doações privadas de empresas para campanhas eleitorais, implementada no Brasil após decisão da Suprema Corte Federal em 2016. Muitos esperavam que isso reduzisse a influência do dinheiro nas eleições. No entanto, com o tempo, políticos aprovaram um fundo eleitoral com recursos públicos, aumentaram esse fundo sucessivamente e ainda aprovaram o que ficou conhecido como “Orçamento Secreto” para também aumentar as chances nas eleições, entre outros objetivos menos legítimos. Comparando o total de valores envolvidos após a decisão do STF com os valores anteriores, mesmo considerando o caixa dois, o montante provavelmente supera o que se gastava em eleições anteriores a 2016. É evidente que medidas como o “Orçamento Secreto” poderiam ser adotadas mesmo se o financiamento por empresas continuasse permitido, mas a mera possibilidade de que todas essas medidas sejam uma reação dos políticos à decisão do STF mostra quão difícil é antecipar as consequências de mudanças nas regras do jogo e que considerações estratégicas são fundamentais para entender a política. Portanto, a teoria dos jogos é um ramo da matemática aplicada que visa modelar situações estratégicas como essa. Um exemplo simples, mas muito esclarecedor, de como a teoria dos jogos pode elucidar essas questões é o Dilema do Prisioneiro, que apresentaremos a seguir. 2.1 Dilema do Prisioneiro Esse é talvez o mais famoso da história da Teoria do Jogos, chamado Dilema do Prisioneiro, e que foi proposto em 1951 por Merrill Flood em 1951, e primeiramente formalizado por Albert W. Tucker. A história é mais ou menos assim. A polícia prendeu dois suspeitos de cometer um crime. Tem evidência de um crime de pena menor, mas gostaria de condená-los por crimes com penas maiores. Se um ou ambos confessarem o crime maior, podem conseguir obter o que precisam. Para dar concretude, imaginem que a Polícia Federal prendeu dois executivos suspeitos de corrupção e lavagem de dinheiro, a dez anos de prisão. Possuem provas suficientes para condená-los por um crime menor, como tráfico de influência (dois anos de prisão), mas gostariam de condená-los pelo crime de pena maior. A PF colocou os dois presos em celas separadas e decidiu fazer a seguinte oferta para eles: “Nós temos evidência suficiente para condená-los, você e seu parceiro, pelo crime de tráfico de influência, que dá 2 anos de prisão para cada. Contudo, se você assinar um acordo de colaboração premiada com a gente e confessar o crime de corrupção e lavagem de dinheiro, você sairá livre e seu parceiro será condenado a dez anos de prisão. Um outro policial está na cela do seu parceiro, neste exato momento, fazendo a mesma oferta a ele. Se ele aceitar confessar o crime, e você não, então ele sairá livre e você ficará preso dez anos. Por fim, se ambos confessarem o crime, a pena de dez anos será reduzida à metade e vocês ficarão cinco anos presos. Essa proposta está por escrito, incluindo o fato de que seu parceiro está recebendo proposta igual”. O que você faria? Para analisar o DP, é comum construimos uma matriz de payoffs. Ela é uma tabela, que contém nas linhas e colunas as ações disponíveis para cada jogadora, e nas células temos os *payoffs”, que são as consequências ou resultados das combinações de ações de cada jogadora. A matriz abaixo apresenta uma possibilidade para o Dilema do Prisioneiro: Coopera Não coopera Coopera (1,1) (20,0) Não coopera (0,20) (10,10) 2.2 Dilema da Ação Coletiva O Dilema do Prisioneiro é muito utilizado como base para pensar problemas de ação coletiva. A cooperação produz resultados socialmente melhores, porém a estratégia dominante individualmente é não cooperar. A partir do conhecimento da lógica do Dilema do Prisioneiro, podemos aplicá-la para outras situações de ação coletiva. 2.3 Happy hour Ocorrências prosaicas do dia a dia frequentemente refletem um cenário análogo ao Dilema do Prisioneiro. É comum que colegas de trabalho ou de faculdade decidam sair para o “happy hour” após o expediente ou término de aulas. E também é comum que ao final a conta seja dividida igualmente entre os presentes. E inevitavelmente alguém irá reclamar de que bebeu ou comeu pouco e está pagando mais do que deveria. Isso pode ser pensado como um exemplo do Dilema do Prisioneiro. 2.4 Dilema da Segurança Nas Relações Internacionais, o chamado Dilema da Segurança entre duas potência pode ser resumido da seguinte forma: ambos os países se beneficiam mais se ambos se desarmarem do que se ambos se armarem, mas cada um tem uma vantagem individual se for o único a se armar. Portanto, em equilíbrio, temos uma corrida armamentista. Mais uma vez, há similaridade com o Dilema do Prisioneiro aqui, já que a cooperação seria mutuamente benéfica, mas os países acabam em uma situação racionalmente indidivudal mas que é pior para todos. 2.5 Cuidar da casa A limpeza de uma casa é algo que benefícia a todos os membros da casa. No entanto, limpar a casa é custoso e limpar apenas a sujeira que você causou tem pouco impacto sobre a limpeza geral da casa, especialmente quando a casa é grande. Assim, mais uma vez temos uma esturtura similar ao Dilema do Prisioneiro, em que a cooperação seria benéfica, mas o equilíbrio é a não-cooperação, já que embora todos prefiram uma casa limpa a uma suja, o equilíbrio é ninguém limpar a casa. Implicações da Teoria dos Jogos para questões mais complexas A dinâmica de limpeza em um lar reflete não apenas a organização doméstica, mas também revela estruturas sociais mais profundas, como o patriarcado e o racismo. Historicamente, no Brasil, o cuidado com a casa e a geração do bem comum dentro do lar foram frequentemente atribuídos às mulheres, uma manifestação direta do patriarcado. Este arranjo social impõe o ônus da manutenção do lar majoritariamente sobre elas, enquanto os homens são poupados desse trabalho. Além disso, em contextos de classe média e alta, o racismo estrutural tem permitido que mulheres brancas transferissem a responsabilidade do trabalho doméstico para mulheres negras. Inicialmente, essa transferência ocorria por meio da escravidão e, posteriormente, através da contratação de empregadas domésticas. Essas empregadas, até muito recentemente, desempenhavam suas funções com poucos ou nenhum direito trabalhista, o que reflete não apenas uma desvalorização do trabalho doméstico, mas também a perpetuação de desigualdades raciais e de gênero. A aprovação da PEC das Domésticas marca um ponto de inflexão nesse cenário. Ao garantir direitos trabalhistas às empregadas domésticas, a PEC aumenta os custos associados à contratação desse tipo de serviço. Esse aumento de custo desafia o equilíbrio anterior, baseado na exploração e na desigualdade. Se por um lado a PEC contribui para uma redistribuição dos custos do bem comum doméstico, favorecendo a equidade racial ao impor responsabilidades financeiras mais justas às empregadoras, por outro, não resolve completamente as questões de gênero. A menos que o equilíbrio patriarcal também seja abordado, a responsabilidade pelo trabalho doméstico continuará a recair desproporcionalmente sobre as mulheres, seja dentro do contexto familiar ou no mercado de trabalho doméstico. Portanto, a mudança real exige uma abordagem que não apenas redistribua o custo do trabalho doméstico de maneira mais equitativa entre as raças, mas que também desafie e transforme as normas de gênero que atribuem esse trabalho principalmente às mulheres. 2.6 Resumo de notação matemática \\(\\doteq\\) relação de igualdade que é verdade por definição. Ex. \\(\\bar{x} \\doteq \\frac{\\sum_{i=1}^n(x_i)}{n}\\). \\(\\approx\\) aproximadamente igual. \\(\\varpropto\\) proporcional a. \\(P(X=x)\\) Probabilidade que a variável aleatória \\(X\\) assuma o valor \\(x\\). \\(\\mathbb{E}[X]\\) esperança de \\(X\\), isto é, \\(\\mathbb{E}[X] \\doteq \\sum_x(x)p(X)\\) \\(\\arg\\max_{x}(f(x))\\) o valor de \\(x\\) que maximiza \\(f(x)\\). \\(\\mathbb{R}\\) o conjunto dos números reais. \\((a,b]\\) o intervalo dos reais entre \\(a\\) e \\(b\\), incluindo \\(b\\) mas excluindo \\(a\\). \\(\\gamma\\) a menos que especificado em contrário, parâmetro de taxa de desconto intertemporal. \\(-i\\) indicado para se referir a todos as outras jogadoras que não a jogadora \\(i\\). \\(s_i\\) estratégia da jogadora \\(i\\). \\(s_{-i}\\) estratégia de todas as outras jogadoras que não a jogadora \\(i\\). 2.7 Referências Kollock, P. (1998). Social dilemmas: The anatomy of cooperation. Annual review of sociology, 183-214. Roxborough, I. (1992). Inflação e pacto social no Brasil e no México. Lua Nova: Revista de Cultura e Política, 197-224. https://www.tse.jus.br/comunicacao/noticias/2022/Outubro/combate-a-desinformacao-tse-derruba-mais-de-uma-centena-de-postagens-com-narrativas-enganosas↩︎ "],["racionalidade-e-relações-de-preferência.html", "Capítulo3 Racionalidade e Relações de Preferência 3.1 Tomada de decisão 3.2 Relações 3.3 Mais sobre relações binárias 3.4 Racionalidade 3.5 Funções de Payoff 3.6 Utilidade Ordinal 3.7 Exercícios", " Capítulo3 Racionalidade e Relações de Preferência 3.1 Tomada de decisão Em uma eleição, cada eleitor tem um problema de decisão: em quem deve votar, dentre as várias alternativas (incluindo Nulo, branco e não ir votar). Similarmente, quando você vai almoçar, deve escolher qual comida irá comer. Ou pela manhã, quando for se arrumar para sair de casa, qual roupa vestir. Todos esses problemas se assemelham em um aspecto: uma pessoa (ou, como iremos chamar em Teoria dos Jogos, uma jogadora) deve escolher entre várias alternativas e cada escolha gerará um resultado, que pode ser melhor ou pior para a jogadora (e eventualmente outras jogadoras). A tomada de decisão consiste de três elementos fundamentais: 1. Ações : as alternativas que uma jogadora pode escolher 2. Resultados: as consequências de cada ação 3. Preferências: quais resultados as jogadoras preferem mais ou menos. E vamos designar essas preferências pela relação (binária) de preferência \\(\\succcurlyeq\\), que significa, “pelo menos tão bom quanto”, ou seja, se escrevo \\(x \\succcurlyeq y\\), então \\(x\\) é pelo menos tõ bom quanto \\(y\\) (e potencialmente melhor que \\(y\\)). 3.2 Relações O conceito de relação (binária) na matemática está associado à presença de um tipo de vínculo específico entre elementos de um conjunto. Suponha o conjunto \\(A = \\{1, 2, 3\\}\\). A Relação \\(\\geq\\), entendida por “maior ou igual que” expressa uma relação de comparação de magnitude entre os elementos do conjunto. Assim, podemos dizer que \\(3 \\geq 2\\), e que \\(2 \\geq 2\\), exemplificando como a relação “maior ou igual que” se aplica. Em geral, podemos dizer que para quaisquer pares \\(x, y \\in A\\) podemos estabelecer a relação \\(x \\geq y\\). A partir desse exemplo, temos uma intuição para construir outros tipos de relações. Em particular, a relação de preferência. Relações de preferência \\(\\succcurlyeq\\) são tais que,se \\(x \\succcurlyeq y\\), isso quer dizer que \\(x\\) é pelo menos tão bom quanto \\(y\\). Às vezes aparece como fracamente preferido, no jargão econômico. Se \\(x \\succ y\\), então \\(x\\) é preferível a \\(y\\), ou \\(x\\) é melhor que \\(y\\). Por fim, quando temos \\(x \\sim y\\), então o jogador ou jogadora é indiferente entre \\(x\\) e \\(y\\), ou \\(x\\) é tão bom quanto \\(y\\). 3.3 Mais sobre relações binárias O conceito de relação de preferência pode ser difícil de entender a primeira vista, de forma que mais exemplos de relações binárias (como é a relação de preferência), podem ser úteis. Então, eis alguns exemplos de outros tipos de relação. 3.3.1 Relação de “inclusão” Nós estamos familiarizados com a ideia de que, e teoria dos conjuntos, existe a ideia de inclusão, quando dizemos que “o conjunto A está incluso no conjunto B”. Isso também é uma relação binária, chamada de relação de inclusão, que compara dois conjuntos e determina se um é um subconjunto do outro. Por outro lado, uma relação binária de preferência compara duas opções e determina se uma opção é preferida estritamente, fracamente preferida, ou se há indiferença entre as opções. 3.3.2 Relação de “antecessor/sucessor” Similarmente, podemos dizer que existe uma relação binária chamada “antecessor/sucessor”, que compara dois números e determina sua relação de sequência, como por exemplo, quando dizemos que “3 é o antecessor de 4”. 3.4 Racionalidade Falamos em ação racional no DP. Mas o que é ser racional? A partir da noção de relação de preferência, podemos definir racionalidade a partir de dois axiomas: Axioma da completude. A relação de preferência \\(\\succcurlyeq\\) é completa. Ou seja, para quaisquer dois resultados \\(x, y \\in X\\) é possível ranqueá-los pela relação de preferência, tal que ou \\(x \\succcurlyeq y\\) ou \\(y \\succcurlyeq x\\) ou \\(x \\sim y\\). O axioma da completude me diz apenas que, se eu tiver dois resultados, sempre vou poder dizer qual prefiro (incluindo dizer que sou indiferente). Porém, não posso ficar na dúvida e não conseguir decidir qual é preferido (ou se sou indiferente). Portanto, é um axioma que requer pouco das pessoas para poder chamá-las de racionais. O segundo axioma é um pouco mais exigente e irá garantir que podemos ranquear \\(todos\\) os resultados. Axioma da transitividade. A relação de preferência \\(\\succcurlyeq\\) é transitiva. Ou seja, para quaisquer três resultados \\(x, y e z \\in X\\), se \\(x \\succcurlyeq y\\) e \\(y \\succcurlyeq z\\), então \\(x \\succcurlyeq z\\). O axioma da completude me diz que posso ranquear quaisquer dois resultados, e o axioma da transitividade me diz que não há contradição no meu ranqueamento. Para ver porque a condição de transitividade é mais demandante, considere o seguinte exemplo. Algumas pessoas preferem estritamente café sem açúcar a café com duas colheres de açúcar. Vamos supor que duas colheres de açúcar são 100 gramas de açúcar. A maioria das pessoas é indiferente entre café com 100 gramas e café com 99 gramas, porque a diferença de sabor é imperceptível. Igualmente, é indiferente entre café com 98 gramas e café com 99 gramas. E assim por diante, de modo que é indiferente a café com duas gramas de açúcar e uma grama, e também é indiferente a café com uma grama e café sem açúcar. Porém, prefere café sem açúcar a café com duas colheres de açúcar. As preferências não são transitivas. De todo modo, parece razoável exigir que pessoas racionais tenham preferências transitivas. A razão para isso é porque, se elas não tiverem de fato preferências transitivas, é possível explorar essa irracionalidade. Tomando o exemplo acima, suponha que um café sem açúcar seja mais caro que um café com açúcar (digamos que a loja é patrocinada por uma empresa de açúcar, de modo que ela ganha mais dinheiro se vende café com açúcar). Em tese a pessoa aceitaria fazer 100 trocas de um café pelo outro com uma diferença de uma grama, tendo pagado mais caro pelo produto que poderia ser comprado mais barato. E o ciclo começaria de novo, até a pessoa ficar completamente sem dinheiro. Então, uma relação de preferência que é completa e transitiva, isto é, satisfaz os dois axiomas postulados por nós, é uma relação de preferência racional. Questão em sala de aula: Será que a escolha de sofia é um exemplo de violação do axioma da completude? Para mais críticas ao axioma da completude, ver por exemplo (no contexto da teoria da utilidade cardinal): Aumann, R. J. (1962). Utility theory without the completeness axiom. Econometrica: Journal of the Econometric Society, 445-462. 3.5 Funções de Payoff Uma das vantagens de se assumir relação de preferência racional é que é possível adotar uma esquema matemático mais operacional do seguinte modo. Suponha que você vai vender suco de limão e tem três possíveis ações: suco de baixa-qualidade \\(b\\), que custa 10 e você vende a 15; suco de média-qualidade \\(m\\), que custa 15 e você vende a 25, e suco de alta-qualidade, \\(a\\), que custa 25 e você vende a 32. Exercício em sala. Escrever o conjunto de ações $ A = {b, m ,a}$, o conjunto de payoffs ou resultados, considerando o lucro, e não a receita apenas: \\(X = {5, 10, 7}\\). Escrever a relação de preferência: \\(10 \\succ 7 \\succ 5\\). Assim, a melhor escolha é \\(m\\), que dá o maior lucro. Uma outra forma de escolher a melhor ação seria definir uma função de lucro p(A), e ver qual a escolha de A que maximiza o lucro. Por exemplo \\(P(b) = 5\\), \\(P(A) = 10\\) e \\(P(A) = 7)\\). Essa mesma lógica do lucro pode ser aplicada para qualquer decisão, mesmo que não envolva retornos monetários, contanto que a relação de preferência seja racional. Definição 1. Uma função de payoff (ou função de utilidade) \\(u: X -&gt; R\\) representa a relação de preferência \\(\\succcurlyeq\\) para todo par \\(x, y \\in X\\), \\(u(x) &gt;= u(y)\\) se e somente se \\(x \\succcurlyeq y\\). O que estamos dizendo é que a função de utilidade \\(u\\) recebe resultados do conjunto \\(X\\), e retorna um número real para cada resultado. E essa função representa nossa relação de preferência racional se, sempre que a utilidade de \\(x\\) for maior que a utilidade de \\(y\\), para qualquer \\(x\\) e \\(y\\), isso implicar que \\(x \\succcurlyeq y\\) e vice-versa. Veja que o número real a ser atribuído não tem sigifnicado algum e pode ser qualquer valor, desde que a relação de ordem seja preservada. A função de utilidade é uma construção ordinal, porque os payoffs são ordinais. Se um resultado gerar utilidade 10 e outro utilidade 5, não podemos dizer de verdade que o primeiro é duas vezes preferido ao segundo. 3.6 Utilidade Ordinal Não função de utilidade definida acima, a utilidade é ordinal. Uma das consequências é que podemos fazer quaisquer transformações na função utilidade que preservem a ordem de preferência. Esse tipo de transformação é chamado de transformação monotônica. Exercícios em sala: Digamos que eu tenha uma função de utilidade \\(u(x)\\) qualquer. Diga se as seguintes transformações são montônicas (isto é, preservam a ordem). \\(2*u(x)\\) \\(u(x) + 10\\) \\(log(u(x))\\). Suponha que \\(u(x) &gt; 0\\) para todo \\(x\\). \\(u(x)^3\\) \\(u(x)^2\\) \\(u(x) - 10\\) Formalmente, uma transformação da função utilidade por outra função \\(f\\) é monotônica se \\(f(u)\\) for uma função estritamente crescente de \\(u\\). Lembrando que uma função \\(f(x)\\) é estritamente crescente se ela cresce à medida que x cresce. Ou seja, \\(u_1 &gt; u_2\\) \\(\\implies\\) \\(f(u_1) &gt; f(u_2)\\). 3.7 Exercícios Exercise 3.1 Digamos que Serena prefira sushi a pizza e pizza a hambúrguer. Escreva a relação de preferências de Serena descrita acima, usando o símbolo de relação de preferências \\(\\succ\\). Exercise 3.2 Digamos que Serena prefira hambúrguer a sushi. Escreva a relação de preferências de Serena e diga qual axioma ela violou. Exercise 3.3 Explique, com suas próprias palavras, o que é o axioma da completude. Exercise 3.4 Considere a relação binária “ser melhor que ou igual a” em um jogo de futebol. Essa relação satisfaz o axioma da transitividade? Justifique sua resposta. E se “ser melhor que ou igual” no futebol for definido apenas pelo número de pontos obtidos pelas equipes em um campeonato. Essa relação satisfaz o axioma da transitividade? Exercise 3.5 Considere a relação binária “ser mais caro do que” em um mercado de produtos. Essa relação satisfaz o axioma da completude? Justifique sua resposta. Exercise 3.6 Na questão anterior, se você respondeu negativamente, como você modificaria a relação para que ela satisfizesse o axioma da completude. Exercise 3.7 Considere a relação binária “ser paralelo a” em um plano euclidiano. Essa relação satisfaz o axioma da transitividade? Dica: pense em retas paralelas. Exercise 3.8 No poema Quadrilha, de Carlos Drumond de Andrade, podemos imaginar que temos uma relação binária “amar”. Desconsiderando por um momento J. Pinto Fernandez, você diria que com as informações disponíveis no poema podemos rankear todos os demais personagens na relação “amar”? E se incluírmos J. Pinto Fernandez, sua resposta muda? Justifique sua resposta. Exercise 3.9 Crie uma relação binária diferente das apresentadas em sala de aula e nos exercícios acima, que satisfaça o axiomada da completude e transitividade. Exercise 3.10 Considere a relação binária “\\(&gt;=\\)”. Para mostrar que essa relação implica a relação “\\(&gt;\\)”, basta mostrar o seguinte. Sejam \\(x\\) e \\(y\\) dois números pertencentes ao conjunto X. Então, dizemos que \\(x &gt; y\\) se e somente se \\(x \\geq y\\) e não \\(y \\geq x\\). Às vezes é difícil entender o que queremos dizer por não \\(y \\geq x\\). Mas é só uma forma de negar uma relação. Então, por exemplo, se \\(x=3\\) e \\(y=2\\). Só é verdade que \\(3&gt;2\\) se também é verdade que \\(3 \\geq 2\\) e também é verdade que \\(2\\) não é maior ou igual a \\(3\\). De maneira similar, mostre que é possível derivar a relação “\\(\\sim\\)” da relação “\\(\\succcurlyeq\\)” Exercise 3.11 Considere o seguinte exemplo: o agente A prefere estritamente café com 7 gramas de açúcar a café sem açúcar, mas é indiferente entre café com 7 gramas de açúcar e café com 6,9 gramas de açúcar, entre café com 6,9 gramas de açúcar e café com 6,8 gramas de açúcar, e assim por diante, até ser indiferente entre café com 0,1 gramas de açúcar e café sem açúcar. O agente A é racional no sentido da Teoria dos Jogos? Justifique sua resposta. Exercise 3.12 Suponha que uma pessoa A prefira a cor vermelha à cor verde e prefira a cor verde à cor azul. No entanto, quando confrontada com um tom específico de verde-azulado, A pode ser indiferente entre esse tom e a cor verde. Isso pode levar a uma violação da transitividade, pois A prefere vermelho a verde e verde a azul, mas é indiferente entre verde-azulado e verde. Forneça um outro exemplo, similar a esse, utilizando outro sentido que não a visão. "],["incerteza-risco-e-utilidade-esperada.html", "Capítulo4 Incerteza, risco e utilidade esperada 4.1 Risco 4.2 Incerteza 4.3 Preferências sobre loterias 4.4 Utilidade esperada 4.5 Risco versos Incerteza 4.6 Aversão a risco 4.7 Teoria e Prática 4.8 Exercícios 4.9 Referências", " Capítulo4 Incerteza, risco e utilidade esperada Raramente nossas decisões não estão envoltas em incertezas. Considere o problema de decisão do eleitorado. É preciso avaliar as alternativas disponíveis, esperando um certo resultado, que é incerto. Políticos não cumprem promessas, circunstâncias mudam, pessoas morrem e seus vices assumem etc. Similarmente, imagine uma gestora pública municipal que foi apresentada a uma nova pesquisa, que sugere que é melhor que crianças entrem na escola uma hora mais tarde. Porém, isso mudará a organização dos cuidadores das crianças, professores e toda a dinâmica escolar, além do que o estudo foi feito em poucas escolas, não necessariamente se generalizando para todo o município. decidindo se adotar uma nova política pública ou continua com a anterior. Será que vale a pena esta nova política pública? Como é uma política nova, há incerteza sobre os benefícios que podem advir dela, bem como dificuldades não antecipadas inteiramente. Portanto, nosso modelo de tomada de decisão precisa incorporar incerteza de algum modo. Em nosso paradigma da escolha racional, precisamos formalizar a incerteza para além de uma linguagem vaga. Termos como “é possível”, “pode ou não acontecer”, “talvez”… são imprecisos. Vamos então introduzir um modo pelo qual jogadoras podem comparar ações cujos resultados são incertos de uma maneira estruturada e formalizável. Nesta abordagem, utilizaremos o conceito de probabilidades, de forma a definir payoffs sobre resultados aleatórios. 4.1 Risco Imagine que você é a gestora pública. Vamos formalizar o problema que ela enfrenta da forma mais simples possível, de modo a introduzir as ideias mais importantes de como modelar incerteza. Vamos chamar suas duas possíveis ações, inovar, \\(i\\) e manter o status quo, \\(s\\), de forma que o conjunto de ações é \\(A = \\{i,s\\}\\). Vamos supor também que só há dois resultados possíveis: um benefício de \\(10\\) (digamos, a nota na avaliação municipal é dez pontos maior) ou de \\(0\\), de modo que \\(X = \\{0,10\\}\\). Entretanto, diferentemente de um mundo sem incerteza, não há correspondência unívoca entre ações e resultados. Para formalizar a ideia de incerteza aqui, precisamos atribuir probabilidades aos resultados em função de cada ação escolhida. Nesse exemplo fictício, as probabilidades são arbitrárias. Voltaremos a como determinar probabilidades mais à frente. Suponha que se ela escolher adotar a nova política há uma chance disso resultar em aumento de 10 pontos na avaliação escolar de 3 para 1, enquanto se não adotar a política e manter as coisas como estão, a chance é de 50%-50%. Dizendo de outro modo, a ação \\(i\\) gera benefício \\(10\\) com probabilidade \\(1/4\\) e benefício \\(0\\) com probabilidade \\(3/4\\), enquanto a ação \\(s\\) gera benefício \\(10\\) com probabilidade \\(1/2\\) e benefício \\(0\\) com a mesma probabilidade. A introdução de probabilidades traz incerteza para nossos jogos. Por isso é importante entender como nossa teoria de comportamento racional pode se modificar na presença de incerteza. 4.2 Incerteza A ideia da incerteza foi inicialmente abordada com a ideia de calcular o valor esperado de ações e escolher aquela ação que rende o maior valor esperado. Considere o seguinte jogo. Após responder várias perguntas corretas, uma pessoa em um programa de TV tem a seguinte escolha para fazer: a) será jogada uma moeda. Se cair coroa, ganha 100 mil reais. Se der cara, não ganha nada. b) Escolher entre três envelopes, cada um contém prêmios no valor de 90 mil reais, 30 mil reais e 15 mil reais. Qual estratégia ele deve escollher? Uma forma de responder a essa pergunta é calcular o valor esperado de cada ação, que pode ser feito da seguinte forma: a) \\(VE(A) = 100000*.5 + 0*.5 = 50.000,00\\) b) \\(VE(B) = 90000*(1/3) + 30000*(1/3) + 15000*(1/3) = 30000 + 10000 + 5000 = 45000\\) Se utilizamos como critério de decisão escolher a alternativa com maior valor esperado, a participante deveria escolher A, pois em média paga mais que do que a opção B. De maneira geral, se tenho uma ação disponível \\(s_i\\), com resultados possíveis \\(v_1, v_2, ... v_k\\) cada um deles com probabilidade \\(p_1, p_2, ..., p_k\\), de tal modo que \\(\\sum_j=1^k(p_j) = 1\\) e \\(p_j \\ge 0, \\forall j = \\{1,2,...,k\\}\\), então o valor esperado de \\(s_i\\) é dado por: \\[ VE(s_i) = v_1p_1 + v_2p_2 + ... + v_kp_k \\] Uma justificativa para a ideia de maximizar o valor esperado é a seguinte. A pessoa se defronta com várias decisões em sua vida que possuem riscos. Pode comprar um carro com algum opcional de segurança que reduz seu risco de vida em acidentes, se vai atravessar fora da faixa e pedestre, se anda de moto, se sai na chuva em dia de raios etc. Cada decisão dela tem um risco e se escolher sempre maximizando a utilidade esperada, na média de longo prazo terá um retorno maior. Um problema da abordagem de maximizar o valor esperado é ilustrado pelo Paradoxo de São Petersburgo. Considere o seguinte jogo. Uma moeda é jogada, se o resultado é coroa, o jogador é pago 1 real e o jogo acaba. Se der cara, o jogo continua e uma moeda é novamente lançada. Se der coroa, recebe dois reais e o jogo acaba. Se der cara, o jogo continua e uma moeda é novamente lançada. Se der coroa, o jogador ganha 4 reais e o jogo acaba. Se der cara, o jogo continua, e assim indefinidamente, sempre dobrando o valor pago até o momento em que der cara. Suponha que a casa tem fundos ilimitados. Qual o valor esperado desse jogo? Ou, colocando de outro modo, quanto um jogador racional (no sentido de maximizar valor esperado) deveria pagar para ter o privilégio de jogar esse jogo? O jogo basicamente tem a seguinte configuração. A casa paga 1 real com probabiliade 50%, 2 reais com probabilidade 25%, 4 reais com prob. 1/8 e assim por diante: \\(VE(jogo) = 1*(1/2) + 2*(1/4) + 4*(1/8) + ...\\) Veja que essa soma infinita é equivalente a: \\(VE(jogo) = 1/2 + 2*/4 + 4/8 + ... = 1/2 + 1/2 + 1/2 + ...\\) O que dá uma soma infinita. Usando nossa lógica de escolher ações cujo valor esperado é maior, entre a alternativa de pagar toda a fortuna de uma pessoa para jogar o jogo e não jogar e preservar a forturna, pagar a fortuna dá um valor esperado maior, pois infinito menos uma quantia finita é ainda infinito. Obviamente, não faz sentido escolher jogar esse jogo pagando toda a sua fortuna, pois na prática em algum momento a pessoa irá perder antes de recuperar o valor de sua forturna. Naturalmente, a questão seguinte a se perguntar é: podemos encontrar algum outro princípio para fundamentar a decisão sob incerteza? Daniel Bernoulli, matemático, percebeu que o valor monetário é diferente a depender de quanto dinheiro você tem. O valor de mil reais para uma pessoa pobre é diferente do valor de mil reais para uma pessoa rica. Obviamente podemos supor que mais dinheiro é preferido a menos, porém não de maneira linear. Bernoulli sugeriu uma “lei da utilidade decrescente”, como ficou conhecida depois, segundo a qual cada real adicional gera um pouco menos de utilidade. Mais ainda, ele propôs que a relação entre dinheiro e utilidade deveria ser logarítmica, o que implica que mudanças percentuais no dinheiro implicam mudanças iguais na utilidade. Duas críticas forma feitas à proposta de Bernoulli. Em primeiro lugar, a arbitrariedade do uso de logarítmo. Em segundo lugar, como medir utilidades? Nós já vimos que podemos trabalhar com utilidades ordinais. Mas utilidade cardinal é bem mais complicado. Tivemos de esperar até o trabalho de von Neumann e Morgenstern (VNM), com o livro Game Theory and Economic Behavior (1944) para haver uma reabilitação das ideias propostas por Bernoulli. A ideia chave de VNM é que é possível estimar a intensidade de preferências em uma escala intervalar (em que os pontos máximos e mínimos são arbitŕarios, como na escala de Celcius e Farenheit) a partir da elicitação de preferências sobre loterias. Com representações numéricas de utilidade, podemos calcular a utilidade esperada (à maneira do valor esperado), exceto que a utilidade marginal pode ser decrescente e, portanto, evitar o paradoxo de São Petersburgo. Para tanto, é preciso introduzir o conceito de loterias, o que faremos a seguir. 4.3 Preferências sobre loterias Já que estamos falando de loterias em nossa definição, é importante fazer um “detour” para explicar o conceito de loterias e preferências sobre loterias Uma loteria existe quando eu tenho payoffs que têm um componente aleatório. A mega-sena paga alguns milhões de reais com uma dada probabilidade, e zero reais com outra probabilidade. Por isso que temos uma loteria nesse caso. Vamos definir formalmente uma loteria em nosso contexto. Definição 4.1. Uma loteria simples sobre resultados \\(X = \\{x_1, x_2, ..., x_n\\}\\) é definida como a distribuição de probabilidade \\(p = (p(x_1), p(x_2), ..., p(x_n))\\), em que \\(p(x_k) \\ge 0\\) é a probabilidade de que \\(x_k\\) ocorra e \\(\\Sigma_{k=1}^n x_k = 1\\). Aplicando a definição para a mega-sena, e considerando um caso simplificado em que há apenas dois resultados, ganhar \\(x\\) milhões de reais e não ganhar nada (excluímos quina, quadra e divisões do prêmio para mais de um ganhador), uma loteria são as probabilidade de cada resultado. 4.4 Utilidade esperada Suponha que uma loteria tem quatro possíveis prêmios (resultados): \\(x_1, x_2, x_3, x_4\\). Suponha que os prêmios foram ordenados em ordem ascendente de preferência, isto é, \\(x_4 \\succ x_3 \\succ x_2 \\succ x_1\\). Agora, atribua valores de utilidade arbitrários para o prêmio mais desejado e o menos desejado. Digamos: \\(u(x_4) = 1\\) e \\(u(x_1) = 0\\). Veja que atribuir um máximo e mínimo arbitrário é algo que fazemos quando criamos as escalas de graus Celcius e Farenheit. Na primeira, escolhemos o máximo (\\(100 ^{\\circ}C\\)) e mínimo (\\(0 ^{\\circ}C\\)) como os pontos de ebulição e congelamento da água, em condições normais de atmosfera e pressão. Na segunda, definimos (\\(212 ^{\\circ}F\\)) como o ponto de ebulição da água e (\\(32 ^{\\circ}F\\)) como o ponto de congelamento da água. Claro que sabemos que podemos ter valores abaixo do mínimo e acima do máximo, mas para uma amostra de dados dentro desse intervalo, estamos fazendo essencialmente a mesma coisa. Voltando ao nosso exemplo. Como nas escalas Celcius e Farenheit, podemos atribuir quaisquer outros números como máximo e mínimo para a utilidade. Contudo, é conveniente matematicamente (já veremos o porquê) usar zero e um. Usando esses dois valores de utilidade como ancoragem, o ponto do teorema de VNM é que existe uma forma garantida de atribuir utilidades numéricas para as preferências de cada um dos prêmios, de forma que podemos trabalhar com o caĺculo de utilidade esperada. O procedimento é o seguinte. Considere qualquer outro prêmio (por exemplo, \\(x_2\\)). Pergutamos então a cada jogador qual a probabilidade \\(p_2\\) que tornaria ela indiferente entre ganhar \\(x_2\\) com certeza e \\(x_4\\) com probabilidade \\(p_2\\) e \\(x_1\\) com probabilidade \\(1 - p_2\\). Veja que quanto mais valioso for \\(x_2\\), maior deve ser \\(p_2\\), a chance de ganhar \\(x_4\\) o prêmio mais valorizado, para que a pessoa aceite trocar algo certo por aldo duvidoso. Assim, \\(p_2\\) mede a desejabilidade do prêmio \\(x_2\\). A gente repete esse experimento com \\(x_3\\) e assim teremos uma medida da desejabilidade de todos os prêmios. E VNM definem a utilidade de cada prêmio como a aposta (loteria) que cada jogador considera igualmente desejável ao prêmio. No caso em tela: \\(u(x_i) = p_i*1 + (1-p_i)*0 = p_i\\) Mais formalmente, temos: Definição 4.2. Seja \\(u(x)\\) a função de utilidade (ou payoff) sobre resultados \\(X = \\{x_1, x_2, ..., x_n\\}\\), e seja \\(p = \\{p_1, p_2, ..., p_n\\}\\) uma loteria sobre \\(X\\) tal que \\(p_k = p(x = x_k)\\). Definimos então a utilidade esperada da loteria \\(p\\) como: \\[ \\mathbb{E}[u(x)|p] = \\sum_{k=1}^n p_ku(x_k) = p_1u(x_1) + p_2u(x_2) +... + p_nu(x_n) \\] Ao escolher os valores máximos e mínimos da utilidade de maneira conveniente, as probabilidades passam a medir a desejabilidade diretamente de cada prêmio. Temos portanto números para as utilidades que não são apenas ordinais, mas cardinais. Eu sei que nós gastamos tempo repetindo e enfatizando que a teoria da utilidade tratava apenas de representar preferências ordinais e, portanto, os números eram completamente arbitrários. Agora não. Somente os pontos máximos e mínimos são arbitrários, mas todos os demais são derivados por esse experimento mental. Isso significa que agora os números refletem a intensidade da preferência, e não apenas mais a ordem. Isso pode alterar as decisões doa agentes, ainda que a ordem de preferências seja mantida. Na verdade, para ser mais preciso, o que VNM mostram é que se alguns axiomas forem satisfeitos, então agentes racionais se comportatão como se tivessem respondido a essas perguntas desse experimento. Mas não precisam de fato fazer esse experimento para se comportarem desse jeito. Mais ainda, em situações de incerteza, agentes racionais escolherão o que maximizar sua utilidade esperada. A Teoria da Utilidade Esperada, portanto, ajuda a explicar porque pessoas contratam seguros ou apostam em loterias como a mega-sena. Embora o valor esperado seja negativo em ambas as escolhas, as pessoas possuem utilidades distintas de cada opção (jogar ou não jogar, contratar ou não-contratar seguro). 4.5 Risco versos Incerteza Até aqui não temos feito diferenciação entre incerteza e risco. Contudo, nas ciências sociais, muita discussão foi feita ao longo do século XX sobre a diferença entre esses dois conceitos. O economia John Manard Keynes, por exemplo, defendia que risco eram aquelas situações nas quais podemos calcular uma probabilidade objetiva, enquanto incerteza seriam situações em que não poderíamos atribuir uma probabilidade. Exemplo de risco seria uma probabilidade de chover, que pode impactar os rendimentos de um evento (um show a ceu aberto) ou negócio (um bar na praia), enquanto incerteza envolveria coisas como uma decisão de investir em um novo negócio, ou a possibilidade de uma pandemia mundial. A diferença entre os dois conceitos parece ter sido introduzida pela primeira vez pelo economista Frank Knight, que escreveu em 1921: Uncertainty must be taken in a sense radically distinct from the familiar notion of risk, from which it has never been properly separated…. The essential fact is that ‘risk’ means in some cases a quantity susceptible of measurement, while at other times it is something distinctly not of this character; and there are far-reaching and crucial differences in the bearings of the phenomena depending on which of the two is really present and operating…. It will appear that a measurable uncertainty, or ‘risk’ proper, as we shall use the term, is so far different from an unmeasurable one that it is not in effect an uncertainty at all”. Em resumo, incerteza é quando eventos futuros ou resultados de ações não poderiam ter uma probabilidade associada, enquanto risco seriam situações opostas, ou seja, quando é possível atribuir uma probabilidade. Do ponto de vista da abordagem Bayesiana, que implicitamente é utilizada em nosso curso, tal diferença não faz sentido. Toda situação de incerteza pode ser modelada como uma probabilidade, ainda que subjetiva, isto é, baseada apenas em um mero chute. 4.6 Aversão a risco Tipicamente as pessoas são avessas ao risco. No contexto da utilidade esperada, isso quer dizer que as pessoas preferem um payoff certo a uma aposta justa. Em outras palavras, se eu oferecer uma escolha entre ficar como está ou uma aposta em que você ganha mil reais se der cara, paga mil reais se der coroa, as pessoas tendem a preferir a primeira opção, ainda que o valor esperado seja igual. Se você for indiferente entre as duas opções, dizemos que você é neutro ao risco. E se prefere a aposta, você é amante do risco. Tipicamente em modelos na ciência política, assume-se neutralidade ao risco ou aversão ao risco. Aversão ao risco é visto como a suposição mais aceitável e neutralidade ao risco é suposta apenas quando é mais fácil a matemática e a conclusão não muda se supusermos aversão ao risco. 4.7 Teoria e Prática Muitos testes foram feitos para verificar se o comportameto das pessoas em situações experimentais condizem com o previsto pela TUE. Em particular, Tversky and Kanheman realizaram uma série de experimentos. Vamos apresentar uma versão de um deles aqui. “Suponha que o Brasil está se preparando para um surto de uma doença que surgiu em outro país e a expectativa é que a doença matará 600 pessoas se nada for feito. Dois programas alternativos para combater as doenças foram pensados. Assuma que as exatas consequências científicas dos programas são como seguem: Programa A: 200 pessoas serão salvas. Programa B: Há uma probabilidade de \\(1/3\\) que 600 pessoas serão salvas, e uma probabilidade de \\(2/3\\) que nenhuma pessoa será salva. A utilidade esperada em função do número de pessoas salvas do programa A é: \\(u(200)\\), enquanto a de B é \\(\\frac{1}{3}u(600))\\). 72% escolheram A e 28% B Programa C: 400 pessoas morrerão. Programa D: Há uma probabilidade de \\(1/3\\) que ninguém morrerá, e uma probabilidade de \\(2/3\\) que 600 pessoas morrerão. Nesse caso, a utilidade esperada de C é \\(u(200)\\) e a de D é \\(\\frac{1}{3}u(600))\\). Já nesse cenário, 78% preferem D e 22% preferem C. Vejam que as utilidades esperadas são as mesmas, o que muda é apenas o framing das questões, em torno de pessoas salvas ou mortas. 4.8 Exercícios Exercise 4.1 Considere o seguinte jogo em um cassino. Você joga um dado de seis faces. Se sair \\(1\\), você recebe \\(25\\) reais. Se sair \\(2\\) você paga \\(5\\) reais ao cassino. Se o dado for \\(3\\), nada acontece. Se sair um \\(4\\) ou \\(5\\), você paga \\(10\\) ao cassino. Se sair um \\(6\\), você paga \\(15\\) Calcule o valor esperado do jogo. Você jogaria o jogo? Explique. Exercise 4.2 Considere o seguinte jogo. Em uma baralho comum de 52 cartas, com quatro naipes (copas, ouro, espada e paus), você escolhe uma carta ao acaso e ganha 10 reais se for de copas. Se tirar um Valete, Dama ou Rei que não seja de copas, você ganha 8. Qualquer outra carta, perde 4. Calcule o valor esperado do jogo. Exercise 4.3 Suponha que a chance de seu carro ser roubado é de uma em mil. Seu carro vale R\\(\\$\\) \\(50.000,00\\). Uma companhia de seguro decide te cobrar um prêmio de 100 reais para segurar seu carro contra roubo (e apenas contra roubo). Você faz o seguro, ou não? Explique. Você consegue imaginar uma probabilidade de roubo do seu carro que faria você mudar de ideia quanto ao seguro? Se sim, qual seria essa probabilidade? Exercise 4.4 Suponha que um indivíduo enfrenta uma loteria L que oferece uma chance de \\(50\\%\\) de ganhar 100 reais e \\(50\\%\\) de ganhar 0. Se a função de utilidade do indivíduo para dinheiro é \\(u(x)= x\\), qual é a utilidade esperada de participar na loteria L? E qual o valor esperado da loteria? Nesse caso, o valor esperado e a utilidade esperado são iguais? Como você interpreta isso? Exercise 4.5 Uma jogadora, Alice, tem a escolha entre um emprego seguro que paga uma renda certa de $50.000 por ano ou um empreendimento que pode render $100.000 anual com probabilidade de \\(50\\%\\) ou $10.000 com probabilidade de \\(50\\%\\). Calcule o valor esperado de ambas as opções. calcule a utiidade esperandas de ambas as opções se a função de utilidade for \\(u(x) = x\\), \\(u(x) = \\sqrt{x}\\) e \\(u(x) = log(x)\\), em que \\(x\\) é a renda da jogadora. Qual opção Alice deve escolher, com base na utilidade esperada para cada função de utilidade. Exercise 4.6 Dois países, A e B, estão em uma disputa sobre a poss de um território que pode levar à guerra. O país A estima que tem \\(60\\%\\) de chance de ganhar a guerra, que resultaria em controle total do território e uma utilidade de 200, já perder a guerra geraria uma utilidade de -100. Para o país B, a chance de ganhar a guerra é \\(40\\%\\), com os mesmos valores de utilidade para ganhar ou perder a guerra. Calcule a utilidade esperada de uma guerra para ambos os países. Divida a utilidade da vitória e derrota por 100. Verifique que a utilidade esperada é igual à utilidade esperada de antes, dividida por 100. Suponha que a função de utilidade do território em disputa em uma solução diplomática é \\(u(x) = 300x\\), em que \\(x\\) é o percentual (entre 0 e 1) de controle por um país do território em disputa. Se houver guerra, a função de utilidade do controle do território passa a ser \\(u(x) = 300x - 100\\). Lemebrando que, se um país vence a guerra, o controle é \\(100\\%\\) para o vencedor e \\(0\\%\\) para o perdedor. Suponha que se uma solução diplomática for acordada, ela é implementada com certeza. Se B oferecer metade do território em disputa para A, ambos os países prefeririam essa solução à guerra? Qual o tamanho mínimo do território que B deveria oferecer a A para que este fosse indiferente entre fazer ou não a guerra? 4.9 Referências Knight, F. H., 1921. Risk, uncertainty and profit. University of Chicago Press. "],["jogos-na-forma-normal.html", "Capítulo5 Jogos na Forma Normal 5.1 Conhecimento Comum. 5.2 Estratégias 5.3 Jogos na forma normal ou estratégica 5.4 Votos em comissão 5.5 Exercícios", " Capítulo5 Jogos na Forma Normal Jogos estáticos de Informação Completa (como o DP) envolvem considerações estratégicas sobre o que os outros jogadores irão fazer. Um jogo de informação completa é caracterizado pelas seguintes quatro informações serem de \\(conhecimento comum\\): 1. todas as possíveis ações de todos os jogadores, 2. todos os possíves resultados, 3. Como a combinação de cada ação de todos os jogadores afetam qual resultado irá acontecer e, materialize, and 4. As preferências de cada e todos jogadores sobre os resultados. Vejam que o DP satisfaz esse requerimento. 5.1 Conhecimento Comum. Definição 2. Um evento \\(E\\) é conhecimento comum se todo mundo sabe \\(E\\), todo mundo sabe que todos sabem \\(E\\), todo mundo sabe que todo mundo sabe que todos sabem \\(E\\) e assim por diante, até infinito. Um exemplo simples em que podemos assumir que um evento é conhecimento comum. Suponha que duas pessoas saiam da sala e, andando na rua, começa a chover e eles correm para não se molhar. É razoável assumir que é conhecimento comum que está chovendo para essas duas pessoas. 5.2 Estratégias O reality show “No limite” é uma adaptação do equivalente americano chamado “Survivor”. Nesse jogo, dois times (azul e vermelho) competem para ganhar os desafios. Como recompensa, só um membro do outro time é eliminado, além de ganharem outros benefícios (dormir em uma cama, mais comida etc.). Em uma das disputas, um jogo foi apresentado no programa que é útil para os nossos propósitos. link: https://www.youtube.com/watch?v=aonCsvi0LKc Conforme pode ser visto no vídeo, havia 21 bandeiras fincadas na areia. O time vermelho começa jogando e pode escolher 1, 2, ou 3 bandeiras (um time não pode escolher pegar 4 ou mais bandeiras, ou nenhuma bandeira). Em seguida, é a vez do time azul, que têm as mesmas opções. Quem pegar a última bandeira ganha o jogo. A solução do jogo é por indução para trás. Imagine que é sua vez de jogar e tem uma bandeira. Pegue a bandeira e ganhe o jogo. Se tiver duas, pegue as duas. Se tiver três, pegue as três. Se tiver quatro, não há o que você possa fazer para evitar que o time adversário esteja na situação anterior de ter uma, duas ou três e ganhe o jogo. Portanto, quem chegar na sua vez com quatro bandeiras, perde o jogo. O que acontece se você chegar com cinco? Você pega uma, deixa o outro time com quatro, e você ganha o jogo. Similarmente se na sua vez houver 6 ou 7 bandeiras, você pega duas ou três bandeiras respectivamente e deixa o outro time com quatro. Por outro lado, se na sua vez tiverem 8 bandeiras, não importa quantas bandeiras pegue, deixará o time adversário com 5, 6 ou 7 e eles deixarão você com quatro. Por raciocínio similar, você deve evitar ficar com 12, 16 e 20 bandeiras e, se possível, deve deixar sempre o outro time com 20, 16, 12, 8 e 4 bandeiras para escolher. Portanto, quem começa o jogo, se jogar corretamente, vence a partida. Nós iremos analisar com calma esse jogo na aula de jogos na forma extensiva, em que desenharemos a árvore do jogo. Por agora, o que quero destacar é o seguinte. Se, em vez do jogo ser sequencial, como vimos no vídeo, o jogo fosse jogado por meio de uma instrução, em que você deve especificar como deve ser jogado, a instrução vencedora seria assim: Se o time vermelho começa jogando, então poderia adotar o seguinte plano de ação. Pegue uma bandeira e o outro time ficará com 20. Se eles pegarem uma, pegue três em seguida. Se pegarem duas, pegue duas em seguida. Se pegarem três, pegue uma em seguida. Adote essa regra em cada rodada após o primeiro movimento. Uma outra forma de dizer o plano de ação é que deve começar por uma bandeira, e em seguida a jogada \\(y\\) é dada por \\(4 - x\\) bandeiras, em que \\(x\\) é quanto o outro time pegou na rodada anterior. O time azul não tem saída, mas, caso o outro time erre (como aconteceu no jogo), sua instrução poderia ser: Se houver 20, 16, 12, 8 ou 4 bandeiras, escolha qualquer número. Porém, se o número de bandeiras for diferente desses números, escolha tantas bandeiras quanto forem necessárias para sobrarem 20, 16, 12, 8 ou 4. Uma vez que o jogo é analisado e uma plano de ação é definido, tantgo faz quem pega as bandeiras. Até um robô com as instruções poderia fazer um serviço. Tal plano de ação, que define o que fazer em cada contigência, é o que chamamos de estratégia em teoria dos jogos. Pensemos em outro exemplo, como o jogo infantil pedra, tesoura e papel. Imagine que você quer jogar esse jogo, mas irá jogar por intermédio de um amigo, e você deve passar instruções sobre como jogar. Então, uma estratégia, pode ser: “jogue pedra”, e outra poderia ser “jogue papel”. A noção de estratégia é distinta de uma ação ou movimento em um jogo, embora isso não fique tão claro em jogos na forma normal ou estratégica. A razão é que, em muitos casos (como no Dilema do Prisioneiro, ou no jogo de pedra-papel-tesoura), as estratégias disponíveis para os jogadores coincidem com as ações. Quando introduzirmos a forma extensiva do jogo, a diferença entre estratégia e ação ficará mais clara. Por enquanto, é importante sabermos que os dois conceitos são distintos, ainda que possam coincidir na prática em jogos simultâneos de dois jogadores. Vamos então introduzir formalmente algumas definições relativas à noção de estratégia. Definição 2.1: Uma estratégia pura para um jogador \\(i\\) é um plano determinístico de ação. O conjunto de todas as estratégias puras para o jogador \\(i\\) é chamado de \\(S_i\\). Um perfil de estratégias puras \\(s = \\{s_1, s_2, ..., s_n\\}, s_i \\in S_i\\) para todo \\(i = 1, 2, ..., n\\) descreve uma combinação particular de estratégias puras escolhidas por todos os jogadores \\(n\\) no jogo. Vamos entender a definição primeiro por meio de um exemplo. No caso do Dilema do Prisioneiro, temos dois jogadores, ou seja, o conjunto de jogadores é dado por \\(N = \\{1,2\\}\\) e \\(n = 2\\). O conjunto de todas as estratégias pura do jogador 1 é formada por duas estratégias, confessar e não-conessar. Podemos, portanto, escrever \\(S_1 = \\{(Confessar, não-confessar)\\}\\). Similarmente para o jogador 2, de modo que \\(S_i = \\{(Confessar, não-confessar)\\}\\), para \\(i \\in {1,2}\\). Uma combinação particular de estratégias puras escolhida pelos dois jogadores pode ser o equilíbrio do jogo, ou seja, \\(s = \\{(confessar, confessar)\\}\\), em que \\(s_1 = s_2\\), que é a estratégia confessar. 5.3 Jogos na forma normal ou estratégica Um jogo na forma estratégica ou normal incluem três componentes: 1. Um conjunto finito de jogadores \\(N = \\{1, 2, ..., n\\}\\) Uma coleção de conjuntos de estratégias puras, \\(\\{S_1, S_2, ...., S_n\\}\\) Um conjunto de funções de payoff, \\(\\{v_1, v_2, .., v_n\\}\\), cada uma atribuindo um valor de payoff para cada combinação de estratégias, ou seja, um conjunto de funções \\(v_i: S_1 * S_2 * ... * S_n \\to R\\) para cada \\(i \\in N\\) Vamos destrinchar o item 3, que parece complexo e assustador, mas é bem simples. Vou usar exemplos para explicar cada uma das partes de 3. Suponha que eu tenho um conjunto \\(A\\) dado pelas cidades do estado de São Paulo, e um conjunto \\(B\\) dado pelas cidades do estado do Rio de Janeiro. Seja \\(f\\) a função que recebe duas cidades (uma de SP, outra do RJ) e retorna a distância em linha reta entre elas, calculada pelo google, em km. Eu posso descrever essa função do seguinte modo: \\(f: A \\cdot B \\to R\\). Como minha função sempre retorna uma distância em km, a distância é um número real. Então, ela recebe dois elementos, um de A e um de B, e retorna um número real. Falta explicar a parte em que escrevemos \\(A \\cdot B\\). O produto de dois conjuntos \\(X\\) e \\(Y\\) é chamado de produto Cartesiano e é denotado por \\(X \\cdot Y\\) e seu resultado é um novo conjunto, formado pelos pares ordenados \\((x,y): x \\in X , y \\in Y\\). Por exemplo, suponha que \\(X = \\{1,2\\}\\) e \\(Y = \\{3,4\\}\\). Então, o produto Cartesiano de \\(X\\) por \\(Y\\) é um conjunto de 4 elementos: \\(X \\cdot Y = \\{ (1,3), (1,4), (2,3), (2,4) \\}\\). Notem que temos apenas 4 elementos nesse conjunto, e cada elemento é um par ordenado de números, isto é, \\((3,1)\\) não faz parte do novo conjunto, por exemplo. O exemplo histórico de onde vem o termo é o plano cartesiano. Se eu considerar uma reta \\(X\\) e outra reta \\(Y\\) no plano cartesiano, então o produto dos dois conjuntos forma pares de coordenadas no plano, de forma que cada ponto do plano é um elemento do produto cartesiano de \\(X\\) e \\(Y\\). Voltando ao nosso exemplo das funções que retornam a distância entre cidades, o produto cartesiano dos dois conjuntos \\(A\\) e \\(B\\) é formado pelo par ordenado de cidades de SP e RJ. Assim, a minha função pode receber cada par de cidade e retornar uma distância em km, que é um número dos Reais. Retornando finalmente ao nosso exemplo das funções de payoff. Eu tenho o produto cartesiano dos conjuntos de estratégias de cada jogador. De modo que cada elemento desse conjunto é um par ordenado de cada estratégia, ou seja, todas as combinações de estratégias existentes estão nesse conjunto e cada combinação é um elemento do conjunto. E para cada jogador, eu tenho o payoff (que é um número real) resultante de cada combinação de estratégia. Vamos aplicar isso para o DP? Um conjunto finito de jogadores \\(N = \\{1, 2\\}\\) \\(S_1 = \\{Confessa, não-confessa\\}\\) e \\(S_2 = \\{Confessa, não_-confessa\\}\\). Ou, mais genericamente, \\(S_i = \\{Confessa, não_-confessa\\}\\) para \\(i \\in \\{1,2\\}\\) \\(v_1: \\{(Confessa, Confessa), (Confessa, não_-confessa), (não_-confessa, confessa), (não-confessa, confessa)\\} \\to R\\). Mais especificamente, Seja \\(v_i(s_1, s_2)\\) o payoff para o jogador \\(i\\) se o jogador \\(i\\) joga \\(s_1\\) e o jogador \\(2\\) joga \\(s_2\\). Então: \\[\\begin{equation} v_1(s_1, s_2) = \\begin{cases} 5 &amp; \\text{if }~~ Confessa,Confessa \\\\ 0 &amp; \\text{if }~~ Confessa,Não_-confessa \\\\ 10 &amp; \\text{if }~~ Não_-confessa,Confessa \\\\ 2&amp; \\text{otherwise.} \\end{cases} \\end{equation}\\] E similarmente para o jogador 2, já que os payoffs são simétricos. Um conjunto de funções de payoff, \\({v_1, v_2, .., v_n}\\), cada atribuindo um valor de payoff para cada combinação de estratégias, ou seja, um conjunto de funções \\(v_i: S_1 * S_2 * ... * S_n \\to R\\) para cada \\(i \\in N\\) 5.4 Votos em comissão Consideremos o seguinte exemplo. Suponha que uma comissão, formada por três pessoas, tem de votar se implementam uma nova política ou mantém o status quo (qualquer que seja ele). Por exemplo, uma comissão de professores deve decidir se continuam com uma política de aquisição de livros para a biblioteca uma vez por ano (status quo) ou duas vezes por ano (nova política). Ou um Conselho de uma empresa deve decidir se aumentam o salário do CEO (nova política) ou não (status quo), ou um júri se condenam alguém (nova política) ou deixam a pessoa livre (status quo). Por fim, pode ser uma comissão de legisladores que devem decidir se aprovam um projeto de lei ou uma nomeação para algum cargo público. Cada membro pode votat “sim” (S) ou “não” (N). Para simplificar, consideremos que o status quo dá um payoff de 0 (zero) para cada jogador. Jogadores 1 e 2 preferem a nova política, portanto seus payoffs para ela pode ser 1. Já o jogador 3 prefere o stats quo, então consideremos o payoff dela -1 para o jogador 3. Por fim, suponha que se houver uma maioria favorável à nova política, ela é adotada. Caso contrário, permanence o status quo. Como descrever esse jogo formalmente? Jogadores: \\(N = \\{1,2,3\\}\\) Conjuntos de estratégias: \\(S_i = \\{S, N, A\\}\\), para \\(i \\in \\{1,2,3\\}\\) Payoffs: Seja \\(P\\) o conjunto de perfis de estratégias para o qual uma nova política é escolhida e seja \\(Q\\) o conjunto de perfis de estratégias para o qual o status quo prevalece. Formalmente, \\(P = \\begin{bmatrix} (S,S,N) &amp; (S,N,S)\\\\ (S,S,S) &amp; (N, S, S) \\end{bmatrix}\\) e \\(Q = \\begin{bmatrix} (N,N,N) &amp; (N,N,S)\\\\ (N,S,N) &amp; (S, N, N) \\end{bmatrix}\\) Então os payoffs podem ser escritos como (aqui, para \\(i \\in \\{1,2\\}\\)): \\[\\begin{equation} v_i(s_1, s_2) = \\begin{cases} 1 &amp; \\text{if }~~ (s_1, s_2) \\in P \\\\ 0 &amp; \\text{if }~~ (s_1, s_2) \\in Q \\\\ \\end{cases} \\end{equation}\\] \\[\\begin{equation} v_3(s_1, s_2) = \\begin{cases} 0 &amp; \\text{if }~~ (s_1, s_2) \\in P \\\\ 1 &amp; \\text{if }~~ (s_1, s_2) \\in Q \\\\ \\end{cases} \\end{equation}\\] 5.5 Exercícios Escreva as informações que especificam um jogo na forma normal (Número de jogadores, estratégias e funções de utilidade) e a matriz de payoff dos seguintes jogos. Exercise 5.1 Considere um happy hour em que temos dois jogadores (um jogador, e todo o restante do grupo), e podem economizar ou não economizar. Atribua números fictícios de payoff para esse jogo, de forma a ilustrar o dilema da ação acoletiva. Escreva as informações que especificam o jogo na forma normal (Número de jogadores, estratégias e funções de utilidade) e a matriz de payoff. Exercise 5.2 Considere o jogo do par ou ímpar. Atribua números fictícios de payoff para esse jogo, de forma a captar as preferências de jogadores nesse jogo. Escreva as informações que especificam o jogo na forma normal (Número de jogadores, estratégias e funções de utilidade) e a matriz de payoff. Exercise 5.3 Digamos que Nina escreva um e-mail para Martín, perguntando se podem se encontrar às 14h da segunda-feira da semana seguinte, em frente ao restaurante central da Universidade onde estudam. Martín responde ao e-mail dizendo que pode sim. É conhecimento comum que ambos irão ao restaurante central na data e hora combinados? Explique. "],["solucao-de-um-jogo.html", "Capítulo6 Solucao de um jogo 6.1 Avaliando conceitos de solução 6.2 Dominância 6.3 Estratégia dominante 6.4 Equilíbrio de estratégia dominante. 6.5 Eliminação Iterativa de Estratégias Estritamente Dominadas (IESDS em inglês, EIEED em PT) 6.6 Racionalização (Rationalizability ou Racionalizabilidade) de estratégias 6.7 Jogos Tradicionais", " Capítulo6 Solucao de um jogo Conceitos de solução de um jogo Para fazer previsões sobre um jogo, precisamos fazer suposições sobre o comportamento e crenças dos jogadores. Estamos em busca do que chamamos de um conceito de solução. Essas soluções nós vamos chamar de equilíbrio. 6.1 Avaliando conceitos de solução Vamos avaliar concetios de solução a partir de três critérios básicos. 6.1.1 Existência A existência de um equilíbrio diz respeito à frequência com que ele existe em diferentes tipos de jogos. Quanto mais frequente um tipo de equilíbrio para diferentes tipos de jogos, melhor o conceito de solução. 6.1.2 Unicidade Unicidade diz respeito à quanto nosso conceito de equilíbrio retringe os comportamentos previstos. Se tudo pode acontecer, se tudo é um equilíbrio, o conceito é pouco útil. 6.1.3 Propriedades distributivas Por fim, queremos avaliar os resultados do nosso conceito de solução, em particular, suas propriedades distributivas. E um critério para isso é o “ótimo de Pareto”. Formalmente, dizemos que um perfil de estratégia \\(s \\in S\\) domina no sentido de pareto o perfil de estratégia \\(s^\\prime \\in S\\) se \\(v_i(s) &gt;= v_i(s^\\prime)\\) para todo \\(i\\) e \\(v_i(s) &gt; v_i(s^\\prime)\\) para pelo menos um \\(i\\). Nesse caso, diremos também que \\(s^\\prime \\in S\\) é dominada no sentido de pareto por \\(s\\). Por fim, dizemos que um perfil de estratégia é ótimo no sentido de Pareto se não é dominado no sentido de Pareto por nenhuma outra estratégia. Vamos agora introduzir alguns conceitos de solução informalmente e discutir em alguns jogos, para depois formalizá-los 6.2 Dominância Vamos introduzir algumas notações. Se eu tenho dois jogadores, e os dois jogadores possuem apenas duas estratégias cada (como no DP, Bach-Stravinski, Chichken e Stag Hunt), nós dedignamos o payoff do jogador \\(i\\) decorrente de um dado perfil de estratégias \\(s = (s_1, s_2)\\) de \\(v_i(s)\\). Por exemplo, se \\(s_1 = &quot;desvia&quot; e s_2 = &quot;desvia&quot;\\) no jogo do chicken, então o payoff do jogador \\(1\\), \\(v_1(s) = 0\\). Se um jogo qualquer com \\(n\\) jogadores, pode ser conveniente ordenar os perfis de estratégias associados a um dado payoff da seguinte maneira: \\(s = (s_1, s_2, ..., s_{i-1}, s_i, s_{i+1}, ..., s_n)\\) para um payoff \\(v_1(s) = 0\\). Em breve será útil se referir às estratégias de todos os jogadores que não \\(i\\). Para isso, diremos que \\(s_{-i} = (s_1, s_2, ..., s_{i-1}, s_{i+1}, ..., s_n)\\). Notem que pulamos \\(s_i\\), a estratégia do jogador i. Exercício: Se \\(s_1 \\in S_1\\), o conjunto de estratégias do jogador \\(1\\), e \\(s_2 \\in S_2\\), então escrevemos que um perfil de estratégia específico \\(s = (s_1, s_2) \\in S_1 * S_2\\), isto é pertence ao conjunto dado pelo produto cartesiano dos conjuntos \\(S_1 e S_2\\). Escreva o produto cartesiano ao qual \\((s_1, s_2, ..., s_{i-1}, s_{i+1}, ..., s_n)\\) pertence. Resposta: \\(S_1 * S_2 * ... * S_{i-1} * S_{i+1} * ... * S_n)\\) Para simplificar a notação iremos usar o seguinte atalho: Vamos definir \\(S_{-i} \\equiv S_1 * S_2 * ... * S_{i-1} * S_{i+1} * ... * S_n)\\) como o conjunto de todas as estratégias de todos os jogadores que não o jogador \\(i\\). E, finalmente, agora podemos definir \\(s_{-i} \\in S_{-i}\\) como um perfil particular de estratégias possíveis para todos os jogadores que não \\(i\\). Portanto, podemos reescrever o payoff do jogador \\(i\\) em função de um particular perfil de estrateǵia \\(s\\) como \\(v_i(s_i, s_{-i})\\), em que \\(s = (s_i, s_{-i})\\). 6.3 Estratégia dominante Dizemos que uma estrateǵia \\(s^\\prime_i \\in S_i\\) é estritamente dominada por outra estratégia \\(s_i \\in S_i\\) se \\(s^\\prime_i\\) é estritamente pior do que \\(s_i\\) não importa o que os outros jogadores façam (isto é, para quaisquer estratégias que os demais jogadores escolham). Mais formalmente, \\(s^\\prime_i \\in S_i\\) é estritamente dominada por outra estratégia \\(s_i \\in S_i\\) se para qualquer combinação de estratégias dos outros jogadores \\(s_{-i} \\in S_{-i}\\), \\(v_i(s_i, s_{-i}) &gt; v_i(s^\\prime_i, s_{-i})\\) para todo \\(s_{-i} \\in S_{-i}\\). Proposição: Um jogador racional jamais jogará um estratégia estritamente dominada. Exemplo de um jogo, 4.1. Esquerda Direita Alto (2,3) (5,0) Baixo (1,0) (4,3) Do ponto de vista do jogador 1, Alto é uma estratégia dominante. Se 2 jogar esquerda, alto é a melhor resposta. E se 2 jogar direita, alto é a melhor resposta. Vejam que para o jogador 2, não há estratégia dominante. Nos termos de nossa definição Baixo é dominado por Alto e um jogador racional jamais deveria jogar Baixo. Exemplo 4.2. Esquerda Centro Direita Alto (8,3) (0,4) (4,4) Médio (4,2) (1,5) (5,3) Baixo (3,7) (0,1) (2,0) Nesse exemplo, “Baixo” é dominado por “Médio”. Portanto, um jogador racional jamais deveria jogar “Baixo”. 6.4 Equilíbrio de estratégia dominante. Estratégia dominante. Definição informal: \\(s_i\\) é um estratégia estritamente dominante para \\(i\\) se todas as outras estratégias forem estritamente dominadas por ela. Mais formalmente, temos \\(v_i(s_i, s_{-i}) &gt; v_i(s^\\prime_i, s_{-i})\\) para toda \\(s^\\prime_i \\in S_i\\), \\(s^\\prime_i \\neq s_i\\) e toda \\(S_{-i} \\in S_{-i}\\). Se, como no DP, todo jogador tem uma estratégia desse tipo (isto é, uma estratégia dominante), então nossa previsão do jogo é que todos os jogadores jogarão essa estratégia dominante. Mais formalmente, dizemos que um perfil de estratégia \\(s^D \\in S\\) é um equilíbrio de estratégia dominante estrita se \\(s^D_i \\in S_i\\) é um perfril de estratégia dominante para todo \\(i \\in N\\). Portanto, temos agora uma definição formal da nossa previsão no DP. É um equilíbrio de estratégia estritamente dominante, dado por (Confessar, Confessar), e que rende o pyaoff 5 anos de prisão, 5 anos de prisão. Note que o equilíbrio é o conjunto e estratégias, e não o conjunto de payoff. É um erro comum entre estudantes (eu mesmo cometia esse erro quando estava aprendendo Teoria dos Jogos) descrever os payoffs como equilíbrio, e não as estratégias. Nosso equilíbrio sempre se refere ao que jogadores irão fazer, e não ao que irá acontecer com eles. 6.5 Eliminação Iterativa de Estratégias Estritamente Dominadas (IESDS em inglês, EIEED em PT) Racionalidade + Conhecimento comum Se um jogador racional nunca irá jogar uma estratégia estritamente dominada e isso é de conhecimento comum, então é razoável supor que todos sabem que essa estratégia nunca será jogada, e todos sabem que todos sabem e assim por diante até infinito. Podemos, portanto, eliminá-la do jogo. Consideremos o jogo do exemplo 4.2. A estratégia “Baixo” para o jogador 1 é estritamente dominada por “Médio”. Portanto, podemos eliminá-la do jogo, e ter uma nova matriz de payoff: Esquerda Centro Direita Alto (8,3) (0,4) (4,4) Médio (4,2) (1,5) (5,3) Na nova matriz de payoff, “Esquerda” é estritamente dominada por “centro” para o jogador 2. Podemos, portanto, eliminar “Esquerda” do jogo, resultando na seguinte nova matriz de payoff. Centro Direita Alto (0,4) (4,4) Médio (1,5) (5,3) Agora, Alto é estritamente dominada por Médio para o jogador 1. Novamente, podemos eliminar essa estratégiado jogo. Centro Direita Médio (1,5) (5,3) Por fim, “Direita” é estritamente dominada por “Centro” para o jogador 2, de modo que o equilíbrio do jogo é (“Médio”, “Centro”), com payoffs (1,5). Vejam que esse equilíbrio é inferior ao par de estratégias (“Alto”, “Esquerda”). Ou seja, é um equilíbrio que é Pareto inferior. Notem que o equilíbrio depende dos seguintes passos: 1. O jogador “1” é racional e elimina a estratégia “Baixo”. No passo 2. o jogador “2” é racional e sabe que “1” é racional, portanto sabendo que “baixo” nuncaserá jogada, elimina de suas estratégias a jogada “Esquerda”. No terceiro passo, o jogador 1, racional, sabe que dois é racional e sabe que 1 é racional e, portanto, eliminou a estratégia “Esquerda”. Por isso ele pode eliminar “Alto” do jogo. No quarto passo, o jogador 2 sabe que 1 fez a primeira eliminação, que 1 sabe que 2 elimnou “Esquerda”, e 2 sabe, com isso, que 1 elimina “Alto”. Pode, portanto, eliminar “Direita”. Ou seja, aqui a iteração os jogadores sabem que eles sabem que eles sabem… não precisa ir até o infinito. Três níveis de sabe que sabe que sabe é suficiente para o equilíbri do jogo. Como vimos, para um equilíbrio de estratégia dominante, bastavamos supor racionalidade dos agentes. Contudo, para um equilíbrio de EIEED, é necessário supor também conhecimento comum da racionalidade dos jogadores. Note que o equilíbrio de EIEED (que nós não definimos formalmente) é o que resta após a eliminação sucessiva de estratégias estritamente dominadas. Quando não há mais estratégias dominadas para exluir, o que restar é a previsão do jogo. Considere o jogo Bach-Stravinski. Não há estratégias estritamente dominadas. Portanto, o equilíbrio do jogo é que quaisquer pares de estratégias são possíveis. Nesse caso, há múltiplos equilíbrios e esse conceito de solução não faz previsões útgeis para nós. 6.6 Racionalização (Rationalizability ou Racionalizabilidade) de estratégias Considere novamente o jogo do DP Coopera Não coopera Coopera (2,2) (10,0) Não coopera (0,10) (5,5) Para facilitar a exposição, vou mudar os payoffs um pouco, mas o jogo ficará igual. Aqui, quanto maior o número, melhor para o jogador. Como os payoffs representam apenas preferências ordinais, não mudamos a essência do jogo. Silencia Confessa Silencia (2,2) (0,3) Confessa (3,0) (1,1) O equilíbrio é que ambos os jogadores escolhem confessar. Uma forma de ver isso é dizer que, qualquer que seja a crença do jogador \\(i\\) sobre o jogador \\(j\\), \\(i \\neq j\\), confessar gera um payoff melhor do que silenciar. Como escolher o que é melhor para si é nossa definição de racionalidade, um agente racional deve escolher confessar. Em outras palavras, nossa previsão do jogo dependeu apenas da suposição de que os agentes são racionais. Considere agora uma variante do DP, como abaixo. Silencia Confessa Silencia (3,2) (0,3) Confessa (2,0) (1,1) Se o jogador 1 acredita que 2 irá escolher “silenciar”, então ele deve silenciar. E se acreditar que o outro jogador irá escolher Confessar, deve escolher confessar. Portanto, ambas as estratégias sãos racionais, a depender da crença do jogador 1 sobre o que o jogador 2 irá fazer. A suposição de racionalidade não restringe a previsão do que o jogador 1 deve fazer. Para que a gente possa restringir a previsão, precisamos fazer alguma suposição adicional. Por exemplo, que 1 acredita que 2 é racional. Se 2 for racional, o que 2 deve fazer? Um agente racional escolhe o que é melhor para si. Do ponto de vista de 2, isso significa confessar, pois essa é a melhor resposta para qualquer comportamento de 1. Portanto, supor racionalidade de 2 implica acreditar que 2 escolherá confessar. Mas se 2 irá confessar, a única ação racional para 1 é confessar. Em resumo até agora: Na variante do DP apresentada, apenas supor racionalidade de 1 não restringe suas ações, mas restringe a de 2. Adicionar a suposição de que 2 sabe ou acredita que 1 é racional é suficiente para restringir a ação de 1 e gerar uma única previsão para o jogo. Agora, considerem uma nova variante do DP: S C S (4,2) (0,3) X (1,1) (1,0) C (3,0) (2,2) Eu adicionei uma nova ação para o jogador 1, que chamei de “X”. O ponto é que, embora a história perca seu sentido com uma nova ação “X”, para o restante das ações ainda guardar alguma similaridade com o original. Se preferirem, podem imaginar que é um outro jogo, não relacionado com o DP. Para o jogador 1, escolher “S” é racional, se ele acreditar que o outro jogador irá escolher “S”. Igualmente, “C” também é racional se o outro jogador escolher “C”. Porém, “X” não é racional. Para 2, S e C também são racionais, dado que ela acredite que 1 escolher S ou C e X, respectivamente. Portanto, se o jogador 1 assumir que 2 é racional, isso não ajuda 2 a decidire entre S ou C, já que ambas são consistentes com sua racionalidade e a do outro jogador. Diferentemente do jogo anterior, a suposição de ambos sã oracionais e que 1 sabe que 2 é racional não geou uma previsão única para o jogo. O que acontece se adicionarmos um passo na cadeia de raciocínio e 1 supor que não apenas 2 é racional, mas que 2 acredita que 1 é racional. Então, dois acredita que 1 jamais jogará “X”, e portanto não achará mais jogar “S” uma boa estratégia e jogará apenas “C”. Mas, se 1 sabe disso, então deverá escolher “C” como sua resposta. Logo, ambos estão escolhendo C, C. Em resumo, C,C é o equilíbrio do jogo desde que assumamos que: 1. é racional, 2 é racional, 1 sabe que 2 é racional, 2 sabe que 1 é racional e 1 sabe que 2 sabe que 1 é racional. Nos três jogos (DP, primeira variante e segunda variante), mostramos como, crescendo a suposição de racionalidade dos jogadores uns dos outros, restaram ações consistentes com essa suposições era C,C. É possível mostrar que isso é verdadeiro supondo maiores níveis de racionalidade (mais passos). Mais ainda, posso estender os passos indefinidamente. E nós dizemos que estratégias que possuem essa propriedade são racionalizáveis. 6.7 Jogos Tradicionais 6.7.1 Bach e Stravinski Bach Stravinski Bach (2,1) (0,0) Stravinski (0,0) (1,2) 6.7.1.1 Histórico machista - guerra dos sexos Diferentemente do DP, a melhor resposta depende do que o outro jogador irá fazer. Assim, para fazer uma previsão, precisamos fazer suposições comportamentais e sobre as crenças a respeito do outro jogador para definir um ou mais equilíbrios para o jogo. Nosso conceito de solução para o jogo será o equilíbrio do jogo. Uma das características dos equilíbrios que iremos abordar durante o curso é que ele seja do tipo que se auto-reforça, isto é, agentes que estão jogando estratégias de equilíbrio não possuem incentivos para mudar suas estratégias, ao contrário, o fato de outros estarem jogando as estratégias de equilíbrio devem reforçar o incentivo para qume um jogador permaneça no equilíbrio. 6.7.2 Stag Hunt Na teoria dos jogos, o jogo caça ao cervo (stag hunt, em inglês), às vezes é referido como jogo da garantia, dilema da confiança ou jogo do interesse comum e descreve um conflito entre segurança e cooperação social. O jogo surge do trabalho do Rousseau no segunod discurso (sobre a desigualdade) Cervo Lebre Cervo (3,3) (0,2) Lebre (2,0) (1,1) 6.7.3 Jogo da Coordenação Bach Stravinski Bach (1,1) (0,2) Stravinski (2,0) (0,0) 6.7.4 chicken - jogo anti-coordenação Desvia não desvia Desvia (0,0) (-1,3) não desvia (3,-1) (-10,-10) "],["equilíbrio-de-nash.html", "Capítulo7 Equilíbrio de Nash 7.1 P-beauty contest 7.2 Melhor resposta 7.3 Equilíbrio de Nash 7.4 Aplicação - Chile 7.5 Aplicação - Competição eleitoram sem incerteza", " Capítulo7 Equilíbrio de Nash Para introduzir o conceito mais importante da teoria dos jogos não-cooperativa, vamos começar por um jogo chamado de “p-beuaty contest”. 7.1 P-beauty contest Escolha um número inteiro, entre 0 e 100. Vence o desafio quem acertar a metade da média dos números escolhidos por todos os jogadores. Em outras palavras, vou anotar os números de cada um, computar a média e depois dividir a média por 2. Portanto, vocês devem advinhar não a média dos números, mas a média dividida por 2. Advinhar metade da média Dividir em grupos de 10 (3 grupos). Previsões: primeira vez 25. (uma rodada de dominância) Segunda vez 10 (às vezes 5 ou 6) - duas ou três rodadas de dominância Terceira vez: 3 ou 4. Mais uma rodada de dominância. Vários zeros. 7.2 Melhor resposta A ideia de melhor resposta é um conceito central para a teoria dos jogos, de modo que vale a pena defini-lo formalmente. Definição 4.1: Melhor resposta: A estratégia \\(s_i \\in Si\\) é a melhor resposta do jogador \\(i\\) às estratégias de seus oponentes \\(s_{-i} \\in S_{-i}\\) se \\(v_i(s_i, s_{-i}) &gt;= v_i(s^\\prime_i, s_{-i})\\) para todo \\(s^\\prime_i \\in S_i\\) Em palavras: a utilidade (ou payoff) do jogador \\(i\\) resultante da sua estratégia e das estratégias dos oponentes é pelo menos tão boa quanto qualquer outra estratégia que \\(i\\) possa vir a adotar. Considere o jogo da bandeira, do reality show Survivor. Se é sua vez de jogar e existem, por exemplo, 20 bandeiras, não importa o que você faça, irá perder o jogo se o outro time for racional. Portanto, sua melhor estratégia pode ser tanto 1, 2 ou 3 bandeiras. Esse exemplo mostra que a melhor estratégia pode 1: incluir múltiplas ações; 2. serem igualmente ruins e não fazer diferença nenhuma e resultar todas no mesmo payoff. 7.3 Equilíbrio de Nash Um perfil de estratégias é um equilíbrio de Nash se cada jogador está escolhendo a melhor resposta para o que acredita que os demais jogadores farão. Ou seja, todo mundo está simultaneamente escolhendo a melhor resposta uns para os outros. O equilíbrio de dominância estrita requer apenas racionalidade, enquanto o equilíbrio de EIEED requeria racionalidade e conhecimento comum de crenças (e racionalidade). Agora, iremos fazer uma suposição mais forte ainda, de que as crenças, em certo sentido, estejam corretas. Isso dará origem ao equilíbrio de Nash, formulado pela primeir vez por John Nash em 1950. Definição 5.1. O perfil de estratégias puras \\(s^\\star = (s^\\star_1, s^\\star_2, ..., s^\\star_n) \\in S\\) é um equilíbrio de Nash se \\(s^\\star_i\\) é uma melhor resposta a \\(s^\\star_{-i}\\) para todo \\(i \\in N\\). Ou seja, \\(v_i(s^\\star_i, s^\\star_{-i}) &gt;= v_i(s^\\prime_i, s^\\star_{-i})\\), para toda \\(s^\\prime_i \\in S_i\\) e todo \\(i \\in N\\). Considere o jogo abaixo. O único equilibrio de EIEED é (Alto, Esquerda). Esse também é um equilíbrio de Nash, pois Alto é a melhor resposta a L, e L é a melhor resposta para Alto. Esquerda Centro Direita Alto (4,3) (5,1) (6,2) Médio (2,1) (8,4) (3,6) Baixo (3,0) (9,6) (2,8) Considerem o Dilema do Prisioneiro. É fácil ver também que (C,C) é também um equilíbrio de Nash. Não é coincidência que Dominância estrita, EIEED e racionazabilidade sempre sejam equilíbrios de Nash. Se um equilíbrio é de dominância estrita, o único sobrevivente de EIEED e de racionazabilidade, então é o único equilíbrio de Nash. Considere o seguinte jogo. Duas jogadoras devem escolher um número inteiro entre 1 e 9. Se a soma dos números for menor ou igual a dez, elas ganham o valor em reais que cada jogadora escolheu. Se a soma for maior que dez, não ganham nada. Esse jogo é dado por \\(G = [N = 1,2; S_i = (1, 2, ..., 9), v_i(s_1, s_2) = s_i, se s_1 + s_2 &lt;= 10\\) \\(0\\), c.c.]$ Quaaisquer pares \\((1,9);(9,1)\\), \\((2,8), (8,2)\\) etc. formam equilíbrios de Nash. Em particular, uma vez revelados, nenhum jogador possui qualquer incentivo unilateral a mudar sua estratégia. Vamos enfatizar a palavra unilateral aqui. Vamos mudar o jogo anterior para o seguinte. Em vez das jogadoras ganharem os números ecolhidos cuja soma for 10, elas (cada uma) ganham a soma dos quadrados dos núemeros escolhidos. Assim, (1,9) e (9,1) geram \\(1^2 + 9^2 = 1 + 81 = 82\\) reais, enquanto \\(2^2 + 8^2 = 4 + 64 = 68\\) e \\(5^2 + 5^2 = 50\\), de forma que o melhor resultado para as jogadoras é (9,1) ou (1,9). Porém, se jogarem (2,8), nenhuma delas possui incentivo unilateral para mudar sua estratégia, pois elas constituem melhores respostas as estratégias umas das outras. Uma das lições que precisamos tirar de modelos de teoria dos jogos é que não basta boa vontade ou objetivos comuns para uma ação coletiva. É preciso que os equilíbrios sejam tal que nenhum ator tenha um incentivo unilateral para mudar sua estratégia. Em certo sentido, os equilíbrios de Nash são sustentáveis, no sentido de que não há incentivo para desviar, uma vez estando em um deles. ## Aplicação - Plano cruzado Na década de 80, o Brasil enfrentou um grave problema de hiperinflação, levando o país a adotar o Plano Cruzado durante a presidência de Sarney para combater a inflação. O plano incluía várias medidas, sendo o congelamento de preços como a principal delas, o que impedia que os preços umentassem sem autorização governamental. Apesar do sucesso inicial em reduzir a inflação, o plano eventualmente fracassou, e os preços voltaram a subir. Uma parte do diagnóstico do Plano Cruzado é que existia uma inércia inflacionária, baseada meramente na expectativa de que haverá inflação. Ou seja, se um agente espera que haja inflação, ele reajusta os preços. Se todos fizerem isso, a inflação acontece e se repete mês a mês. Essa situação pode ser modelada como um jogo de coordenação, em que queremos transitar de um equilíbrio ruim (todos reajustam os preços) para um equilíbiro bom (ninguém reajusta os preços). A ideia do congelamento de preços é justamente mover a economia entre equilíbrios, algo que o mercado não conseguiria fazer soznho, sem intervenção governamental. Para simplificar, suponhamos que temos apenas duas empresas que podem decidir reajustar os preços ou não. Se ambas não reajustam, não há inflação. Se só uma reajustar, ela perde mercado para a outra empresa. Se ambas reajustarem, há inflação. # Define Variables M=2 R=3 P=1 S=0 # Assign Pairs pair &lt;- function(x,y) sprintf(&quot;(%d,%d)&quot;, x,y) all_pairs &lt;- c(pair(M,M), pair(S,R), pair(R,S), pair(P,P)) payoff.mat &lt;- matrix(all_pairs, nrow=2) dimnames(payoff.mat) &lt;- c(rep(list(c(&quot;Não-reajusta&quot;,&quot;reajusta&quot;)), 2)) results = &quot;asis&quot; # Plot kable(payoff.mat) Não-reajusta reajusta Não-reajusta (2,2) (3,0) reajusta (0,3) (1,1) 7.4 Aplicação - Chile Vamos começar modelando um exemplo “simples”, adaptado do livro de Niou e Ordershook “Strategy and Politics. An introduction to Game Theory”. Em 1964, no Chile, Salvador Allende era o candidato da esquerda. Liberais e Conservadores acetaram apoiar o candidato do centro Eduardo Frei, que ganhou a eleição com 56,1% dos votos contra 38,9% de Allende. Em 1970, Allende ganhou a eleição com menos votos do que havia recebido em 64, 36,2%, enquanto o centrista Randomiro Tomic ganhou 27,8% e direitsta Jorge Allesandri 34,9% dos votos. Especula-se que, se um dos candidatos desistisse da eleição, Allende não teria conquistado o poder. Vamos então fazer um modelo simples para ilustrar a questão. Suponha um eleitorado com três tipos de ordenamento de preferências de candidatas \\(A\\), \\(B\\) e \\(C\\). 1. \\(A \\succ B \\succ C\\) 2. \\(B \\succ C \\succ A\\) 3. \\(C \\succ B \\succ A\\) Vamos supor adicionalmente que 40% do eleitoradotem preferências do tipo 1 o restante igualmente dividido entre o tipo 2 e 3 (30% cada). Se cada eleitor votar sinceramente (isto é, para sua candidata preferida), \\(A\\) teira 40% dos votos, \\(B\\) 30% e \\(C\\) 30%. Se a regra for como no Brasil 1945-64, em que não havia segundo turno e a candidata mais votada vence, \\(A\\) seria eleita. Se porém parearmos \\(A\\) contra \\(B\\), a vencedora seria \\(B\\) com 60% dos votos, e \\(B\\) contra \\(C\\) também daria a vitória para \\(B\\), com \\(70\\%\\) dos votos. Em casos como esse, em que há uma vencedora que ganha todas as disputas 2x2, chamamos de vencedora de Condorcet (Condorcet winner). \\(B\\) e \\(C\\), portanto, poderiam ser estratégicas e votarem não na candidata preferida para obter um resultado mais favorável. O problema que \\(B\\) e \\(C\\) enfrentam pode, portanto, ser modelado do seguinte modo. Votar em B Votar em C Votar em B B ganha A ganha Votar em C A ganha C ganha Esse jogo é muito parecido com o jogo de coordenação Bach-Stravinsky. Há dois equilíbrios de Nash, B ganha e C ganha. Porém, a escolha de qual equilíbrio acontecerá requer coordenação entre eleitores do tipo 2 e 3. Se falharem em coordenar os votos, contudo, A ganhará. Se B ou C desistir de disputar a eleição, a coordenação estará garantida, como ocorreu no Chile em 1964. Na ausência de tal coalizão, eleitores terão muita dificuldade de coordenar seu voto. Do ponto de vista da Ciência Política, é importante enfatizar alguns pontos dessa discussão: 1. É muito mais fácil para as elites polítics coordenarem entre si do que entre os eleitores, que não possuem uma forma fácil de comunicação. 2. Informações sobre candidatas com maiores intenções de voto em simulações de segundo turno permite ajudar os eleitores a tomarem decisões melhores e coordenarem seus votos. Portanto, quando vocês virem pessoas reclamando de pesquisas d intenção de voto, que isso influenciar o eleitor e faz com que ele vote estrategicamente, pergunte-se: é realmente ruim que o eleitorado vote estrategicamente? Voltaremos a essa discussão em aulas futuras. 3. Na presença de segundo turno, existe necessidade de haver coordenação antecipada? Não para evitar que A seja eleito. B ou C irá para o segundo turno contra A. 7.5 Aplicação - Competição eleitoram sem incerteza Quando as pessoas pensam em eleições, muitos acreditam que políticos anunciam as plataformas que acreditam, e eleitores escolhem a que preferem. Contudo, na ciência política é comum assumir que, mesmo que políticos se preocupem que suas plataformas sejam implementadas, sabem que para isso primeiro precisam ganhar eleições. Portanto, seja porque estão preocupados apenas com o poder ou porque precisam estar preocupados com o poder para implementar plataformas, o fato é que uma supoição comum é assumir que políticos maximizam suas chances de serem eleitos. Essa é a base do modelo discutido por Hotelling (1929). Após contribuições de Duncan Black (Black, 1948) e Anthony Downs (Downs, 1957), a ideia entrou definitvamente na Ciência Política e ficou conhecida como Teorema do Eleitor Mediano. O modelo do Hotelling tem inspiração em um modelo de competição espacial entre firmas. Ele desenvolve um jogo em dois estágios, em que duas firmas, competindo em uma rua, devem escolher sua localização geográfica no primeiro estágio, e em seguida os consumidores escolhem onde vão comprar os produtos, levando em consideração não apenas o preço dos produtos, mas o custo do transporte. E ele acha um equilíbrio de Nash (sem usar esse termo, obviamente) em que as empresas tendem a se concentrar no meio da rua. E ele notou que essa ideia poderia ser aplicada par competição política entre partidos. Nós apresentaremos aqui uma versão simplificada da ideia do Hotelling e do Teorema do Eleitor Mediano. Iremos voltar a esse modelo algumas vezes ao longo do curso, para adicionar complexidade a ele. O cenário que está sendo modelado é, claramente, o da competição política dos EUA. Suponha, portanto, dois partidos, que se importam apenas em ganhar a eleição. Existem 101 eleitores, com preferências uniformimente distribuídas em uma única dimensão do espectro político-ideológico (esquerda-direita). Em particular, suponha que o eleitor mais a esquerda está na posição -50, em seguida -49 e assim por diante, cada um com um número inteiro, até a extrema-direita, +50. Cada partido \\(i\\) escolhe uma plataforma \\(x_i\\) no espectro político-ideológico \\([-50, -49, ..., +49, +50]\\). Cada eleitor escolhe a plataforma mais próxima da sua posição ideal. Por exemplo, se o partido \\(A\\) anuncia -9 como plataforma e o partido \\(B\\) anuncia 12, o eleitor mais perto de -9 do que de 12 vota por \\(A\\), enquanto quem estiver mais perto de 12 vota por \\(B\\). Figura 7.1 - O modelo de voto do Hotteling 7.5.1 determinar os eleitores pivot do exemplo. É eleito quem obtiver mais voto. Como há um número ímpar de eleitores, a menos que alguém seja indiferente, não há empate. Se alguém for indiferente, o eleitor não vai votar e há um empate. Para escrever a função de melhor resposta de cada jogador, considere o seguinte. Vamos começar olhando para o partido \\(A\\). Se \\(B\\) anunciar uma plataforma \\(x_B &gt; 0\\), então escolher a mesma posição \\(x_A = x_B\\) ou a exata oposta \\(x_A = -X_b\\) haverá um empate. Se escolher \\(x_A &gt; x_B\\) ou \\(x_A &lt; -x_B\\), perde. O único caso em que ganha é se escolher \\(x_A = \\left[ -x_B + 1, x_B - 1 \\right]\\). De modo análogo, se \\(x_B &lt; 0\\), \\(x_A = -X_b\\) levará ao empagte, \\(x_A &gt; -x_B\\) ou \\(x_A &lt; x_B\\), perderá, e \\(\\left[ x_B + 1, -x_B - 1 \\right]\\) leva à vitória. Como ganhar é melhor que perder e empatar, temos a melhor resposta no cenário em que \\(x_B &gt; 0\\) e que \\(x_B &lt; 0\\). Se \\(x_B = 0\\), a melhor resposta é também jogar zero, isto é, \\(x_A = x_B = 0\\), já que qualquer outra posição levará à derrota de \\(A\\). Podemos então construir a correspondência de melhor resposta:para \\(A\\) \\[ x_A = \\begin{cases} \\left[ -x_B + 1, x_B - 1 \\right] &amp; \\text{se } x_B &gt; 0, \\\\ 0 &amp; \\text{se } x_B = 0, \\\\ \\left[ x_B + 1, -x_B - 1 \\right] &amp; \\text{se } x_B &lt; 0. \\\\ \\end{cases} \\] Como é tudo simétrico, as melhores respostas de cada jogador são similares. Existe um único equilíbrio de Nash, em que ambos candidatos jogam (0,0), que é o centro do espectro político. É fácil verificar que é um equilíbrio de Nash, já que ambos estão jogando uma melhor resposta à estratégia do outro partido, como pode ser verificado pela função de melhor resposta. Essa é a base para o teorema do eleitor mediano, presente já no trabalho do Hotelling. 7.5.1.1 Competição eleitoral em espaços multidimensionais O nosso modelo de competição política assumiu um espaço político unidimensional – por exemplo esquerda-direita. Mas às vezes o espaço político possui mais de uma dimensão, de modo que vale investigar como espaços multidimensionais impactam nossos resultados. Vamos considerar um espaço multidimensional em que as partes devem decidir como alocar um orçamento de tamanho \\(1\\). Esse jogo é às vezes chamado de jogo de dividir a torta. 7.5.1.2 O modelo de Wittman 7.5.1.3 Competição multipartidária 7.5.2 Aplicação - Modelo sobre guerra Nós agora estamos preparados para entender como a literatura tem utilizado teoria dos jogos para modelar e discutir fenômenos relevantes. Aqui iremos retomar aplicações que discutem a ocorrência de guerras. Fearon introduziu a questão de como a escolha racional coloca problemas para explicações tradicionais (realistas, por exemplo) para a guerra. Guerras, como a da Rússia e Ucrância, são custosas. Qualquer que sejao resultado final da guerra, em tese uma negociação que resultasse no mesmo resultsado final, sem a guerra, seria preferia por ambos os estados (pareto superior) e portanto a guerra deveria ser evitada sempre. Como explicar que guerras ocorram? Fearon aponta três explicações mais gerais: 1. Pessoas (e líderes políticos em particular) podem ser irracionais ou sofrer de vieses, que os levam a subestimar o custo da guerra ou a entender como suas ações podem provocar uma guerra. Líderes se beneficiam da guerra, mas não pagam seus custos (soldados é que lutam as guerras) e, portanto, o cálculo racional de custos não seriarelevante. Agentes racionais por alguma razão acabam guerreando. A primeira e segundas explicações, embora plausíveis, corrm risco muito grande de serem bobas. Dizer que Putin é malvado e tem mania de grandeza e por isso fez a guerra independente de qualquer cálculo racional pode servir a uma visão ideológica, mas é muito fácil. Se a pessoa faz guerra porque é burra ou má, não temos muita ciências sociais para fazer. É mais uma questão da psicologia ou psiquiatria. Portanto, mais relevante para nós são explicações racionalistas. Vejam que explicações de corte neorealistas, que enfatizam variáveis no sistema internacional são justamente do tipo que estamos interessados. Atores racionais farão guerra se o sistema internacional produzir situações que levam à guerra. Fearon irá então dizer o seguinte: Não é suficiente dizer que, sob anarquia, nada impede um estado de usar a força, ou que estados devem contar apenas com a auto-ajuda em um sistema anárquico, o que gera suspeita mútua e por fim, conflito (por espiral de suspeita ou dilema da segurança). E o ponto dele é o que falei no começo. Guerra é custosa. Isso significa que, em princípio, estados poderiam chegar a um acordo que seria pareto superior e evitasse a guerra. É um pouco como o gatoro que sofre bullyng na escola, mas os valentões nunca precisam de fato bater no garoto, porque este antecipa a derrota e já entrega o lanche que os valentões pedem. Um conflito destruiria parte do valor do lanche (no mínimo ficaria mais frio etc.) e o resultado final seria o mesmo, situação pareto inferior. Anarquia não implica na guerra porque estados poderiam chegar a um acordo preferível á guerra, mesmo sob anarquia. Digamos, A toma 10% do território de B. Se esse é o resultado da guerra, melhor chegar a ele sem guerra. Similarmente, o dilema da segurança (um estado se tornar mais seguro torna outro relativamente menos seguro) não impede de um acordo ser feito que previna a guerra. Fearondirá que é preciso argumentos mais elaborados. Considere por exemplo a explicação típica de espiral. Um estado A se arma, tornando outro, B, relativamente mais inseguro. No limite, B decide fazer uma guerra preventiva. Se A sabe que é isso que irá acontecer e antecipa, então …. Se A falha em antecipar e não queria a guerra, então o problema é mais de cálculo errado do que de anarquia. E aí é preciso mostrar que uma negociação não poderia resolver o problema do erro de cálculo. Se uma potência declinante pensa em fazer uma guerra preventiva contra uma potência ascendente, então poderia fazer uma barganha envolvendo concessões no presente e no futuro, para evitar a guerra, que seria preferível por ambos os estados. Mais ainda, a potência delclinante, sabendo que barganhas no futuro são preferíveis à guerra, não teriam razão para ter medo de serem atacados no futuro. Outro tipo de explicação é sobre utilidade esperada da guerra diferente entre estados. Bruce Bueno de Mesquista argumentou, de maneira influente, que a guerra aconteceria quando ambos os estados esperam uma utilidade esperada do conflito (isto é, benefícios esperados maiores que os custos esperados) maior do que a da paz. Porém, por que não exisitiria um acordo a ser negociado que geraria maiores benefícios, ao evitar a guerra? Fearon irá então modelar o jogo entre dois estados, para formalizar essas intuições e argumentos. Dois estados, A e B, que têm preferências sobre um objeto (como um território), representado por \\(X = [0,1]\\). Estado A prefere soluções o mais próximas de 1 possível, enquanto B é o oposto (mais perto de zero). Podemos pensar que é a divisão de um território entre as partes, e pode ir de 0% a 100%, representando o percentual do território controlado por A. Se o resultado da disputa for \\(x \\in X\\), então estados têm utilidade \\(u_a(x)\\) e \\(u_b(1-x)\\). Funções de utilidade são de VNM, com aversão a risco ou neutralidade ao risco. E vamos definir que \\(u_i(1) = 1\\) e \\(u_i(0) = 0\\), \\(i \\in {A,B}\\). Dizer que o conjunto \\(X\\) contém acordos negociados preferíveis á guerra implica que podemos dizer como os estados avaliam conflito armado a opções negociadas. Se ocorre uma guerra, \\(A\\) vence com probabilidade \\(p\\) e perde com probabilidade \\(1-p\\). Quem vencer escolher o máximo do território. A utilidade esperada de A é: \\(p*u_a(1) + (1-p)*u_a(0) - c_a= p - c_a\\), em que \\(c_a\\) é o valor perdido (em utilidade) da guerra para A. Digamos, destruição econômica mais perdas de vidas humanas e perdas de equipamento militares. Similarmente para B: \\((1-p)*u_b(1) + p*u_b(0) - c_b= 1- p - c_b\\), Suponha que a função utilidade é \\(u(x) = x\\), que representa uma função de utilidade de neutralidade ao risco. Então, se existir algum \\(x^*\\), tal que, \\(u_a(x^*) &gt; p - c_a\\) e \\(u_b(x^*) &gt; 1 - p - c_b\\), então \\(x^*\\) é preferido por ambos os estados. Se existir mais de um ponto, ou mesmo um intervalo, então esse intervalo é preferível a guerra. Resolvendo o sistema de equações de desigualdade, temos que \\(x^* &gt; p - c_a\\) e \\(1 -x^* &gt; 1 - p - c_b\\) Suponha que \\(x^* = p - c_a - 0.1\\). A primeira equação é satisfeita trivialmente, e a segunda também é satisfeita, como é fácil ver, pois \\(1 -( p - c_a - 0.1) = 1 -p + c_a + 0.1 &gt; 1 - p - c_b\\) , pois 1 cancela, p cancela, ficando \\(c_a + 0.1 &gt; -c_b\\). Como \\(c_a\\) é positivo e \\(c_b\\) é positivo, o lado esquerdo da equação é maior que o lado direito. Do mesmo modo, o ponto \\(p + c_b - .01\\) também satisfaz as duas equações. Portanto, no intervalo \\([p - c_a - 0.1, p + c_b - .01]\\), ambos os estados estão melhores do que com a guerra. De maneira geral, no intervalo aberto, posso tirar o \\(.01\\) e ficar com: \\((p - c_a, p + c_b)\\). Para dar concretude. Se A ucrância e B Rússia. Digamos que \\(p\\), a probabilidade da Ucrância prevalecer fosse 10% antes da guerra começar, \\(c_a = 2%\\) e \\(c_b = .05%\\). Então, \\((.05 - .02, .05 + .005) = (3%, .5,5%)\\). Ou seja, a Ucrânia poderia ficar com 3% do seu território + epsiolon para evitar a guerra, e a Rússia aceitaria no máximo que a Ucrância ficasse com 5,5% do território. A intuição é que a utilidade esperada da Guerra pra Ucrância é uma utilidade equivalente a 3% do território (5% do território menos 2% de destruição da guerra). Ela não poderia dar mais de 5,5% do território, pois preferiria a guerra. Quais suposições substantivas foram feitas: 1. existe uma probabilidade \\(p\\), objetiva, que cada estado irá ganhar a guerra. Ainda que ambos os estados tenham estimativas diferentes e conflitivas e haja incerteza sobre seu valor, existe uma probabilidade real, que eles não sabem. E essa probabilidade dá ensejo ao intervalo de negociação e eles sabem disso (se são racionais). Portanto, a princípio uma solução negociada ainda poderia ser tentada. Assumimos que estados são neutros ao risco ou avessos ao risco. Parece plausível, já que um acordo certo seria preferível a uma aposta de tudo ou nada com o mesmo valor esperado. Por fim, assumimos que há uma continuidade de acordos possíveis. Ou seja, o objeto é perfeitamente divisível. Há casos em que isso não é divisível, como por exemplo quando é quem é o líder que ficará no governo. Só pode ser uma pessoa. Nesse caso, indivisibilidade poderia trnar o intervalo de negociação vazio. Porém, pagamentos laterais e issue-linkage podem tornar o objeto divisível. então teria de ser mostrado porque isso não foi possível. Fearon irá sugerir que o que pode explicar a guerra nesse paradigma é, portanto, blefe resultado de incentivos a superestimar suas capacidades militares e conseguir um acordo melhor na negociação, levando à guerra. Mas aqui é necessário mostrar porque estados não conseguem transmitir informações críveis sobre suas capacidades. Commitment problems (dificuldade de se comprometer). Potência em ascenção não pode fazer um compromisso crível de ser um hegemon benigno no futuro.^ Referências Powell, R. (2006). War as a commitment problem. International organization, 60(1), 169-203. Fearon, J. D. (1995). Rationalist explanations for war. International organization, 49(3), 379-414. "],["equilíbrio-de-nash-em-estratégias-mistas.html", "Capítulo8 Equilíbrio de Nash em Estratégias Mistas", " Capítulo8 Equilíbrio de Nash em Estratégias Mistas Considere o jogo “cara” ou “coroa” a seguir. Nesse jogo, dois jogadores escolhem entre cara (heads) ou coroa (tails) ao mesmo tempo. Se as escolhas forem iguais, o Jogador 1 ganha um ponto. Caso contrário, o Jogador 2 ganha um ponto. O objetivo dos jogadores é maximizar sua pontuação. library(knitr) # Definindo a matriz de payoff payoff.mat &lt;- matrix(c(1, -1, -1, 1), nrow = 2, ncol = 2, dimnames = list(c(&quot;Cara&quot;, &quot;Coroa&quot;), c(&quot;Cara&quot;, &quot;Coroa&quot;))) # Renderizando a tabela de payoff kable(payoff.mat) Cara Coroa Cara 1 -1 Coroa -1 1 Esse jogo é similar ao de par ou ímpar, que estamos acostumados Exercício 7.1: jogue par ou ímpar com outra pessoa por 5 rodadas. library(knitr) # Definindo a matriz de payoff payoff.mat &lt;- matrix(c(1, -1, -1, 1), nrow = 2, ncol = 2, dimnames = list(c(&quot;Par&quot;, &quot;Ímpar&quot;), c(&quot;Par&quot;, &quot;Ímpar&quot;))) # Renderizando a tabela de payoff kable(payoff.mat) Par Ímpar Par 1 -1 Ímpar -1 1 Após o jogo, podemos perceber que os jogadores possuem interesses opostos e vocês esperam que o outro não consiga antecipar o que você irá fazer. Nesse caso, ele será indiferente entre jogar qualquer uma de suas estratégias, pois esperar que, na média, ambas gerem o mesmo payoff médio. Uma estratégia mista é justamente um antidoto contra as tentativas dos outros jogadores advinharem o que você irá fazer. Considere o jogo de tênis. No saque, se seu adversiário antecipar o que você irá fazer, ele terá uma vantagem. Então, você precisa jogar de um jeito que ele não consiga angtecipar ou advinhar suas estratégias. Considere o seguinte jogo. C D A (4,25) (12,5) B (16,10) (8,15) É fácil ver que não há equilíbrio de Nash em estratégias puras. Vocês viram que no jogo do par ou ímpar, o ideal é jogar cada estratégia com 50% de chance. Vamos tentar colocar alguma probabilidade nesse jogo? Que tal 50% para cada estratégia também? Vamos calcular o payoff (utilidade) esperado das novas estratégias, para poder preenhcer a nova matriz de payoff aumentada. C D 50% C, 50% D A (4,25) (12,5) (8,15) B (16,10) (8,15) (12.00,12.50) 50% C, 50% D (10.00,17.50) (10,10) (10.00,13.75) Vamos calcular o Equilíbrio de Nash, se existe? Novamente, não existe equilíbrio de Nash. Lembremos que estamos querendo deixar os jogadores indeferentes entre suas estratégias. Então, devemos procurar probabilidades que os deixem indiferentes. Isso significa que eles não poderão antecipar a estratégia do outro jogador se for um equilíbrio de Nash (é a melhor resposta simultaneamente). Como achar essas probabilidades? O payoff esperado de jogar A e B, para o jogador 1 deve ser o mesmo, pois ele é indiferente dado o que o jogador 2 está fazendo. E a estratégia mista de 1 deve deixar 2 indiferente entre jogar C e D. Formalmente: Se 2 está misturando suas estratpegias para deixar 1 indiferente, então a utilidade esperada de 1 jogar A, dado que 2 está jogando C com probabilidade \\(p_2c\\) e D com probabilidade $ 1 - p_2c$, deve ser a mesma de 1 jogar B, dado que 2 está jogando C com probabilidade \\(p_2c\\) e D com o complemento. Para o jogador 1, \\(E[U(A)] = E[U(B)]\\) e para o jogador 2, \\(E[U(C)] = E[U(D)]\\). Como calcular a utilidade esperada de jogar “A”? Suponha que o jogador 1 escolhe a com probabilidade \\(p_1\\), e B com probabilidade \\(1-p_2\\). Então: \\(E[U(A)] = p_2c*U(A| 2 joga C) + (1-p_2c)*U(A| dado 2 joga D ) = p_2c*4 + (1-p_2c)*12\\) \\(E[U(A)] = p_2c*4 + 12 -p_2c*12 = 12 - 8*p_2c\\) \\(E[U(B)] = p_2c*U(B| 2 joga C) + (1-p_2c)*U(B| dado 2 joga D ) = p_2c*16 + (1-p_2c)*8\\) \\(E[U(B)] = p_2c*16 + 8 -8*p_2c = 8 + 8*p_2c\\) Se 1 está indiferente, então: \\(E[U(A)] = E[U(B)]\\) \\(12 - 8*p_2c = 8 + 8*p_2c\\) \\(12 - 8 = 8*p_2c + 8*p_2c\\) \\(4 = 16*p_2c\\) \\(p_2c = 4/16\\) \\(p_2c = 1/4\\) \\(p_2d = 3/4\\) E agora fazemos a mesma coisa para o jogador 2. \\(E[U(C)] = E[U(D)]\\) \\(p_1a*U(C| 1 joga A) + (1-p_1a)*U(C| dado 1 joga B ) = p_1a*U(D| 1 joga A) + (1-p_1a)*U(B| dado 1 joga B )\\) \\(p_1a*25 + (1-p_1a)*10 = p_1a*5 + (1-p_1a)*15\\) \\(p_1a*25 + 10 -p_1a*10 = p_1a*5 + 15 - p_1a*15\\) \\(p_1a*15 + 10 = 15 - p_1a*10\\) \\(p_1a*25 = 5\\) \\(p_1a = 5/25\\) \\(p_1b = 4/5\\) Nossa matriz agora fica: C D 1/4 C, 3/4 D A (4,25) (12,5) (10,10) B (16,10) (8,15) (10.00,13.75) 1/5 C, 4/5 D (13.60,13.00) (8.80,13.00) (10,13) Podemos ver, em primeiro lugar, que na nova matriz de payoff, 1 é indiferente entre jogar A, B ou sua estratégia mista de equilíbrio se 2 de fato está misturando suas estratégias C e D com as probabilidade de equilíbrio. Notem que ele sempre ganha 10. Do mesmo jeito, 2 sempre ganha 13 se 1 está em sua estratégia mista. Por fim, vemos que ambas são estratégias de equilíbrio de Nash. E, nesse caso, a única estratégia mista (ou pura) de equilíbrio. Vamos agora fazer o mesmo exercício para o jogo do par ou ímpar e para pedra, papel tesoura. Aplicação em ciência política. Suponha duas candidatas, 1 e 2, que devem decidir onde alocar seus dias finais de campanha, seja no estado A ou estado B, nos EUA. As pesquisas indicam que esses são os estados que podem decidir a batalha. Suponha que as probabilidades de cada candidata ganhar a eleição são dadas como segue: A B A (0.5,0.5) (0.9,0.1) B (0.9,0.1) (0.6,0.6) Vamos calcular o ENEM (Eq. Nash em Estratégias Mistas)? Ambas vão para A com prob 3/7 (aprox. 0.43) e B com prob 4/7 (aprox. 0.57). Agora, suponha que, antes de implementar essas estratégias, novas pesquisas saem e a probabilidade muda. Se 1 for para B sozinha, sua prob é .7 e não .9. Isso é conhecimento comum. Portanto, isso poderia nos levar a crer que ela deveria gastar mais tempo em A, ou aumentar a probabilidade de ir para A. Mas os novos equilíbrios indicam que 1 agora vai para A com pob 1/5 e visitar b com 4/5. Isso porque 2 vai mudar sua estratégia e aumentar a prob de visitar A (de 3/7 para 3/5). E se ambos vão para A, a prob de 1 ganhar é menor do que se ela for para B sozinha. Esse tipo de coisa acontece com frequência em esportes. Um jogador veterano atacante se machuca e alguém das divisões de base entra no lugar. E aí, ele comeca a receber mais passes e tem mais oportunidades de gol e, por isso, marca mais gols do que o veterano. Ocorre que, como ele tem menos chance de criar jogadas e fazer gols, é melhor deixar ele mais livre e marcar outros jogadores. Isso aumenta a chance de gol do novato, mas diminui a de todos os outros jogadores. Então, embora ele esteja marcando mais gols que o veterano, o time no geral estará com desempenho pior. "],["pedra-papel-tesoura.html", "Capítulo9 Pedra-papel-tesoura 9.1 Exercícios 9.2 Carregando pacotes exigidos: ggplot2 9.3 Warning: package ‘ggplot2’ was built under R version 4.3.2", " Capítulo9 Pedra-papel-tesoura Considere o jogo pedra-papel-tesoura. Assuma que vencer gera um payoff de 1, empate 0 e perder de -1. A matriz de payoff pode ser representada do seguinte modo: Pedra Papel Tesoura Pedra (0,0) (-1,1) (1,-1) Papel (1,-1) (0,0) (-1,1) Tesoura (-1,1) (1,-1) (0,0) A correspondência de melhor resposta do jogador 1 para suas crenças a respeito do jogador 2 pode ser escrita da seguinte forma: \\(s_1(s_2) =\\) Papel quando \\(s_2 = Pedra\\) \\(s_1(s_2) =\\) Tesoura quando \\(s_2 = Papel\\) \\(s_1(s_2) =\\) Pedra quando \\(s_2 = Tesoura\\) E de maneira análoga para o jogador 2. É fácil ver que não existe equilíbrio de Nahs em estratégias puras nesse jogo. Raciocínios do tipo: “se ele acha que vou jogar pedra, então ele jogará papel, de forma que devo jogar tesoura. Porém, se ele antecipar isso, ele jogará pedra, de forma que devo jogar papel. Mas ele pode antecipar isso também e jogar tesoura, mas aí eu jogo pedra…” leva a uma regressão que nunca terminará. Em certo sentido, tanto faz o que você joga, porque não é possível advinhar o que você o outro jogador irá fazer. Mas dizer tanto faz pode ser pensado como se você aleatorizasse e jogasse cada uma das três ações com a mesma probabilidade \\(1/3\\), e o mesmo o jogador 2. Nesse caso, dizemos que os jogadores estão jogando uma estratégia mista. Neste caso em particular, joga cada uma das t^Res ações com probabilidade \\(1/3\\). Definição do Ronaldo Fiani (p. 192): Quando, em vez de escolher entre suas estratégias uma dada estratégia para jogá-la com certeza, um jogador decide alternar entre suas estratégias aleatoriamente, atribuindo uma probabilidade a cada estratégia a ser escolhida, diz-se que o jogador utiliza estratégias mistas. Caso contrário, diz-se que emprega estratégias puras. Nós vamos definir estratégias mistas da seguinte forma: Se o conjunto de estrartégias disponíveis para um jogador é \\(S = (s_1, s_2, ..., s_m)\\), então uma estratégia mista para aquele jogador é uma loteria sobre \\(S\\), \\(p = (p_1, p_2, ..., p_m)\\). Diz-se que o jogador escolheu a estratégia \\(p\\) se ele usa esta loteria para determinar qual estratégia pura irá implementar no jogo. Em outras plavras, uma estratégia mista é uma distribuição de probabilidade que determina como uma estratégia pura será jogada por meio da realização dessa distribuição. Definição 6.1. Se um conjunto de estatégias disponíveis para um jogador é \\(S = {s_1, s_2, ..., s_n}\\), então uma estratégia mista para aquele jogador é uma loteria sobre \\(S\\), \\(p = (p_1, p_2, ..., p_n)\\). Diz-se que o jogador escolhe essa estratégia \\(p\\) se ele usa essa loteria para determinar que estratégia pura irá implmentar quando de fato jogar o jogo. 9.1 Exercícios Exercise 9.1 Qual o equilíbrio de Nash em Estratégias Mistas (ENEM) do Dilema do Prisioneiro? Exercise 9.2 Qual o equilíbrio de Nash em Estratégias Mistas (ENEM)do jogo do Chicken?? Exercise 9.3 Considere o seguinte jogo representado na forma estratégica: Esquerda Centro Alto (3,3) (3,3) Baixo (3,3) (3,3) Existe algum equilíbrio de Nash em Estratégias Puras (ENEP)? Se sim, qual (ou quais)? Quantos equilíbrios de Nash em estratégias mistas existem? ::: {.exercise #unnamed-chunk-49} Considere o seguinte jogo representado na forma estratégica: ::: | |A |B |C | |:--|:------|:-----|:------| |A |(4,4) |(0,5) |(-1,0) | |B |(5,0) |(1,1) |(0,0) | |C |(0,-1) |(0,0) |(1,1) | a) Existe algum equilíbrio de Nash em Estratégias Puras (ENEP)? Se sim, qual (ou quais)? b) Existe ENEM em que os jogadores aleatorizam entre A e B? Explique. c) Existe ENEM em que os jogadores aleatorizam entre B e c? Explique. Exercise 9.4 Uma funcionária (jogadora 1) que trabalha para uma chefe (jogadora 2) pode tanto trabalhar (T) quanto enrolar (E), enquanto sua chefe pode tanto monitorar a funcionária (M) quanto ignorá-la (I). Como em muitos relacionamentos entre funcionária e chefe, se a funcionária estiver trabalhando, a chefe prefere não monitorá-la, mas se a chefe não estiver monitorando, a funcionária prefere enrolar. A matriz de payoff abaixo representa uma situação como essa. M I T (1,1) (1,2) E (0,2) (2,1) escreva a fução de melhor resposta de cada jogadora (isto é, para a jogadora 1, qual probabilidade \\(p\\) ela deve escolher para cada possível escolha de probabilidade \\(q\\) da jogadora 2). qual o equilíbrio de Nash do jogo? ::: {.exercise #unnamed-chunk-52} Qual o equilíbrio de Nash em Estratégias Mistas (ENEM) do Dilema do Prisioneiro? ::: ## Referências Gauriot, R., Page, L., &amp; Wooders, J. (2023). Expertise, gender, and equilibrium play. Quantitative Economics, 14(3), 981-1020. &lt;!--chapter:end:08-ENEM.Rmd--&gt; # Jogados Dinâmicos ## Introdução Considere novamente o jogo Bach e Stravinsky. Suponha que a jogadora 1 joga primeiro e e a jogadora 2 pode observar a esoclha de 1. Imagine que ela vai para um lugar, liga para a amiga e diz: estou aqui no lugar tal (espetáculo do Bach ou do Stravinsky). Veja que em termos de equilíbrios de Nash, continuamos com os mesmos dois equilíbrios de antes. Porém, não faz sentido achar que o equilíbrio (S,S) será jogado, pois a jogadora 1 sabe que, se for para Bach, 2 também irá. Jogos na forma normal não capturam muito bem a noção de jogos sequenciais e racionalidade sequencial. A forma estratégica do jogo, de fato, não traz informações nem sobre a ordem dos movimentos, nem as ações disponíveis para cada jogadora na sua vez de jogar. Por isso, iremos alterar a representação de nosso jogo, para a forma extensiva, que tornará explícito **a ordem** em que as jogadoras jogam, e o que cada jogadora **sabe** quando é sua vez de jogar. Nesse cenário, estratégias referem-se a planos contingentes de ações (como no jogo da bandeira), em vez de ações não-contigentes. Iremos introduzir a noção de indução reversa ou indução para trás como uma forma de solucionar jogos. Noção que for formalizada por Selten (1965) como equilíbrio de subjogo-perfeito e contempla situações em que jogadoras se movem simultaneamente em múltiplos períodos e a indução reversa não pode ser aplicada. Comecemos então pela introdução do que significa descrever um jogo na forma extensiva. ## Jogo na forma extensiva Um jogo na forma extensiva pode ser visto como uma generalização multi-estágio de árvores de decisão. &lt;div class=&quot;figure&quot;&gt; &lt;img src=&quot;imagens\\jogo-extensivo.png&quot; alt=&quot;Representação do Jogo da coordenação&quot; width=&quot;100%&quot; /&gt; &lt;p class=&quot;caption&quot;&gt;(\\#fig:bach-strav)Representação do Jogo da coordenação&lt;/p&gt; &lt;/div&gt; A árvore do jogo é lida de cima para baixo. No topo está quem joga primeiro. O retângulo com o nome da jogadora é chamado de nó. No primeiro nó, Serena tem duas ações possíveis, &quot;Bach&quot; e &quot;Stravinski&quot;. Uma vez que ela escolha sua ação, é a vez da Nina, que também tem duas opções (&quot;bach&quot; e &quot;stravinsky&quot;, em caixa baixa, para distinguir as ações das duas jogadoras). Se Serena escolheu Bach, Nina está no galho da esquerda. Se Serena escolheu Stravinsky, Nina está no galo da direita. E uma vez que Nina faça sua escolha, o jogo acaba e os payoffs finais são mostrados. O primeiro payoff é da jogadora 1, e o segundo da jogadora 2. Assim, com a forma extensiva, temos como antes: 1. Número de jogadoras, $N$. 2. Payoffs ou funções de utilidade em função dos resultados, $\\{u_i(\\cdot)\\}_{i \\in N}$ E acrescentamos: 3. Ordem dos movimentos 4. Ações das jogadoras quando for a vez delas de se moverem. 5. O conhecimento que as jogadoras possuem quando é sua vez de se moverem. O ponto 5 é importante para distinguir entre Nina joga depois da Serena de um lado, e Nina joga depois da Serena sabendo o que Serena jogou antes dela. Por fim, mantemos uma suposição feita em nossos jogos anteriores, agora estendida aos itens 1-6, que é: 7. É conhecimento comum toda a estrutura do jogo representada pelos itens 1-6 para todas as jogadoras. ### Definição de árovre de um jogo Uma **árvore do jogo** é formada por um conjunto de nós $x \\in X$ com uma relação de precedência $x &gt; x&#39;$, que significa &quot;$x$ precede a $x&#39;$&quot;. Ou seja, $x$ vem antes de $x&#39;$. Cada nó só tem um predecessor. A relação de precedência é transitiva ($x &gt; x&#39;, x&#39; &gt; x&#39;&#39; \\implies x &gt; x&#39;&#39;$), assimetrica $(x &gt; x&#39; \\implies \\neg (x&#39; &gt; x))$, isto é, $x$ precede $x&#39;$, mas $x&#39;$ não precede $x$, e incompleta (nem todos os pares podem ser ordenados). Há um nó especial, chamado raiz da árvore, denotada por $n_1$, que precede quaisquer outros nós $x \\in X$. Nós que não precedem outros nós são chamados de nós terminais, denotados pelo conjunto $Z \\subset X$. Nós terminais denotam o fim do jogo, com os payoffs associados. Cada nó $x$ que não é terminal é atribuído a um jogador $i(x)$ com o conjunto de ações $A_i(x)$, ou para natureza. É uma definição longa, masque captura a estrutura &quot;física&quot; do jogo, ao mesmo tempo em que ignora as ações (escolhas) das jogadoras e o que sabem quando jogam. ## Jogo da confiança &lt;div class=&quot;figure&quot;&gt; &lt;img src=&quot;imagens\\jogo-confianca.png&quot; alt=&quot;Representação do Jogo da Confiança&quot; width=&quot;100%&quot; /&gt; &lt;p class=&quot;caption&quot;&gt;(\\#fig:confianca)Representação do Jogo da Confiança&lt;/p&gt; &lt;/div&gt; O jogador p1 joga primeiro. Logo, $i(n_1) = p_1$. ## Informações Quais informações cada jogador tem quando é sua vez de jogar? Uma jogadora pode ter informação bem fina sobre onde está no jogo, ou bem grosseira. Vamos então introduzir a seguinte definição: Definição conjunto de informações: Cada jogador $i$ tem uma coleção de conjuntos de informação $h_i$ the particiona (divide) os nós do jogo no qual uma jogadora $i$ move com as seguintes propriedades: 1. Se $h_i$ é uma conjunto unitário (*singleton*) que inclui apenas $x$, então a jogadora $i$ que se move em $x$ sabe que está em $x$. 2. Se $x \\neq x&#39;$ e se ambos $x \\in h_i$ e $x&#39; \\in h_i$ então a jogadora $i$ que se move em $x$ não sabe se está em em $x$ ou $x&#39;$. 3. Se $x \\neq x&#39;$ e se ambos $x$ e $x&#39; \\in h_i$, então $A_i(x) = A_i(x&#39;)$. Vamos entender esta definição formal. Considere novamente o jogo do Bach e Stravinsky na forma extensiva. No gráfico temos n1, n2.. como nós, enquanto na definição usamos x1 etc. Vou falar em x em vez de n apenas para continuar com a discussão. Considere quando a jogadora 2 se move em x2. A questão é: ela sabe que está em x2? Ou não sabe se está em x2 ou x3? Se a gente escreve $h_2 = {x_2}$, então isso significa que o conjunto de informações em $x_1$ é um conjunti unitário. Portanto, a jogadora a jogadora possui informação que diz &quot;estou em x_2&quot;, que é capturado pela propriedade 1 da definição. Nesse caso, segue-se que a jogadora 2 també mtem outro conjunto de informação $h_2 = {x_3}. Se, por outro lado, a jogadora 2 não sabe se está em $x_2$ ou $x_3$, como no jogo do Bach e Stravinsky simultâneo, então deve ser verdade que sua informação é de que está em $x_1$ ou $x_2$, mas não sabe em qual dos dois. Nesse caso, escrevemos $h_2 = {x_1, x_2}$. Esta é a propriedade 2. Finalmente, a propriedade 3 é essencial para manter a lógica da informação, em particular quando as ações disponíveis em cada nós forem diferentes para uma jogadora. Considere o jogo da confiança. Se ela não sabe se está no nó x2 (onde o jogo terminou e não tem o que fazer) ou x3, então ela não pode saber quais as ações disponíveis para ela. Por fim, em alguns casos é possível acrescentar eventos aleatórios. Por exemplo, o jogo acima poderia ser modificado para incluir a chance de chover. Suponha que o espetáculo de Bach é a céu aberto, e o de Stravinski, não. Então, se choveu os payoffs das jogadoras é diferente de se não choveu. Vamos supor que elas preferem ficar juntas sob chuva que separadas. Como representar essa possibilidade? A forma como fazemos isso é criar uma jogadora fictícia, que é a natureza, que joga aleatoriamente sem considerações estratégicas. Essa probabilidade é exógena, no sentido de que é fixa e determinada antes do jogo começar, de modo que não depende das escolhas das jogadoras. Eis como ficaria o jogo nesse caso: &lt;div class=&quot;figure&quot;&gt; &lt;img src=&quot;imagens\\jogo-bofsex-nature.png&quot; alt=&quot;Representação do Jogo da coordenação, com a natureza movendo primerio&quot; width=&quot;100%&quot; /&gt; &lt;p class=&quot;caption&quot;&gt;(\\#fig:bach-strav-natureza)Representação do Jogo da coordenação, com a natureza movendo primerio&lt;/p&gt; &lt;/div&gt; Na \\@ref(fig:bach-strav-natureza), temos algumas mudanças. O primeiro nó está representado por um círculo vazado, para indicar que é a natureza quem está jogando (e não terá um payoff). Os demais nós são representados por círculos prreenchidos, sólidos. Portanto, a natureza joga e &quot;escolhe&quot; se fará sol ou chuva. Na prática as leis da natureza irão operar, e podemos calcular probabilidades (no caso, 50% de chance de chover), mas a jogadorta Serena só sabeá se haverá sol ou chuva na hora do espetáculo, após ter feito sua jogada. Isso significa que Serena não sabe em qual nós está, se no da esquerda, com chuva, ou no da direita, com sol. Para indicar essa ausência de informação, é comum circularmos com uma linha tracejada os nós nos quais uma jogadora não tem informação sobre qual nó ela está. Uma vez que Serena Joga, é a vez de Nina jogar. Note que não circulamos nós de Nina com linha tracejada, de modo que isso significa que Nina sabe em qual nó está, ou seja, sabe não apenas o que Serena jogou, mas o que a natureza jogou. Como é difícil imaginar tal situação, o melhor seria indicar também que Nina não sabe o que a Natureza jogou, mas sabe o que a Serena jogou. A árovre do jogo ficartão então. &lt;div class=&quot;figure&quot;&gt; &lt;img src=&quot;imagens\\jogo-bofsex-nature1.png&quot; alt=&quot;Representação do Jogo da coordenação, com a natureza movendo primerio, conjunto de informações corretos.&quot; width=&quot;100%&quot; /&gt; &lt;p class=&quot;caption&quot;&gt;(\\#fig:bach-strav-natureza1)Representação do Jogo da coordenação, com a natureza movendo primerio, conjunto de informações corretos.&lt;/p&gt; &lt;/div&gt; Nessa árove, vale destacar dois aspectos que são diferentes da árvore anterior. Em primeiro lugar, nós descrevemos a informação completa sobre em qual nó Nina está por meio de linha tracejada curva. Poderíamos ter usado o círculo tracejado, que daria na mesma. São duas formas distintas de representar a mesma coisa e estamos incluindo aqui para fins de completude. Em segundo lugar, note os nós que estão conectados pela linha. Quando é a vez de Nina jogar, ela não sabe o que a natureza jogou, mas sabe o que Serena jogou. Isso significa que se Serena jogou &quot;Bach&quot;, Nina não sabe se está no ramo &quot;Bach&quot; com chuva ou no ramo &quot;Bach&quot; som sol. Similarmente, se Serena jogou &quot;Stravinski&quot;, Nina não sabe em qual dos dois galhos de &quot;Stravinski&quot; ela está. É preciso, portanto, ter cuidado quando conectar nós, pois se fizemos errado, o jogo fica completamente outro. ## Jogos de informação perfeita e imperfeita Os jogos na forma normal eram chamados de jogos de informação completa, pois todas as jogadores conheciam as ações disponíveis e as funções de payoff de todas as jogadoras, e isso era conhecimento comum. Agora, nós temos uma situação em que uma jogadora pode ter conhecimento perfeito ou imperfeito do nó em que está, a depender do particionamento do conjunto de informações. Portanto, vale a pena distinguir entre dois tipos de jogos de informação completa. Definição: Um jogo de informação completa no qual cada conjunto de informação é um conjunto unitário e não há jogadas da natureza é chamado um **jogo de informação perfeita**. Um jogo no qual pelo menos um conjunto de informação contém vários nós ou um jogo com movimentop da natureza é chamado um **jogo de informação imperfeita**. ## Estratégias Nós já havíamos definido uma estratégia como um plano de ação contigente. Contudo, em jogos na forma normal, essa definição era pouco útil, pois estratégias (puras) coincidiam com as ações disponíveis para as jogadoras. Na forma externsiva, a nossa definição de estratégia se revelará mais útil. ### Estratégias mistas ## Estratégias comportamentais Definição: perfect recall (memória perfeita) ## Representação estratégica de jogos na forma extensiva ## Equilíbrio de Nash e Caminhos de jogada Definição: ... um conjunto de informação está **no caminho de equilíbrio** se ... &lt;!--chapter:end:09-Jogos-dinamicos.Rmd--&gt; # Credibilidade e racionalidade sequencial ## Introdução ## Racionalidade sequencial e indução reversa Contudo, quando o jogo é de informação imperfeita, não podemos aplicar a indução reversa. Caso em que é mais vantajoso usar uma formalização desenvolvida por Selten (?, ano?). Antes, vamos introduzir a noção de subjogo. ## Subjogo Subjogo de um jogo extensivo com informação perfeita Um subjogo é qualquer parte de um jogo na forma extensiva que satisfaz as seguintes condições: 1. Sempre se inicia em um único nó de decisão 2. Não está em um nó terminal 3. Contém todos os nós que se seguem após ele Em um jogo de informação imperfeita, acrescentamos: 4. Se contiver qualquer nós de um conjunto de informação, ele conterá todos os nós do conjunto de informação. Nós chamamos de subjogo próprio todos os subjogos que não são a árvore do jogo na sua totalidade. ## Equilíbrio de Nash Perfeito de Subjogo ## Exercícios Ache todos os subjogos do jogo abaixo. 9.2 Carregando pacotes exigidos: ggplot2 9.3 Warning: package ‘ggplot2’ was built under R version 4.3.2 ``` Modelo o jogo como uma árvore (forma extensiva) e ache todos os subjogos do jogo abaixo. (exercício 156.2c do Osborne). Os políticos Rosa e Ernesto precisam tomar uma posição sobre um assunto. As opções são Berlim (B) ou Havana (H). Eles escolhem sequencialmente. Uma terceira pessoa, Karl, determina quem escolhe primeiro. Tanto Rosa quanto Ernesto se importam apenas com as ações que escolhem, não com quem escolhe primeiro. Rosa prefere o resultado em que ambos escolhem B ao resultado em que ambos escolhem H, e prefere esse resultado a qualquer um dos casos em que ela e Ernesto escolhem ações diferentes; ela é indiferente entre esses dois últimos resultados. As preferências de Ernesto diferem das de Rosa no sentido de que os papéis de B e H são invertidos. As preferências de Karl são as mesmas que as de Ernesto. Modele essa situação como um jogo extensivo com informação perfeita. (Especifique os componentes do jogo e represente o jogo em um diagrama.) Existem 6 subjogos próprios e 7 subjogos no total, contando o jogo inteiro como um subjogo. Equilíbrio de Nash Perfeito em Subjogos Definição informal: Um equilíbrio perfeito em subjogos é um perfil estratégico \\(s^*\\) com a propriedade de que, em nenhum subjogo, qualquer jogador \\(i\\) pode se sair melhor escolhendo uma estratégia diferente de \\(s^*_i\\), dado que todos os outros jogadores \\(j\\) aderem a \\(s^*_j\\). Nessa definição (informal), requeremos que a estratrégia de cada jogadora seja ótima para toda história após ser a vez dela jogar, e não apenas no início do jogo, como no equlíbrio de Nash. Todo jogo extensivo finito com informação perfeita possui (pelo menos) um equilíbrio perfeito de subjogo. Um jogo finito significa que em nenhum momento um jogador possui infinitas opções de ações. Para dar um exemplo trivial (do Osborne): um único jogador escolhe um número menor que 1 e recebe um pagamento igual ao número que ela escolhe. Não há um número maior que todos os outros números menores que um, então o jogador único não possui uma ação ótima, e assim o jogo não possui um equilíbrio perfeito de subjogo. "],["jogos-multi-estágio.html", "Capítulo10 Jogos Multi-estágio 10.1 Introdução 10.2 Racionalidade sequencial e indução reversa 10.3 Subjogo 10.4 Equilíbrio de Nash Perfeito de Subjogo 10.5 Exercícios 10.6 Game Theory Model of Regime Change 10.7 Introdução 10.8 The Game 10.9 Strategies 10.10 Payoffs 10.11 Best Response Functions 10.12 Players and Phases 10.13 Analysis", " Capítulo10 Jogos Multi-estágio 10.1 Introdução 10.2 Racionalidade sequencial e indução reversa Contudo, quando o jogo é de informação imperfeita, não podemos aplicar a indução reversa. Caso em que é mais vantajoso usar uma formalização desenvolvida por Selten (?, ano?). Antes, vamos introduzir a noção de subjogo. 10.3 Subjogo Subjogo de um jogo extensivo com informação perfeita Um subjogo é qualquer parte de um jogo na forma extensiva que satisfaz as seguintes condições: Sempre se inicia em um único nó de decisão Não está em um nó terminal Contém todos os nós que se seguem após ele Em um jogo de informação imperfeita, acrescentamos: Se contiver qualquer nós de um conjunto de informação, ele conterá todos os nós do conjunto de informação. Nós chamamos de subjogo próprio todos os subjogos que não são a árvore do jogo na sua totalidade. 10.4 Equilíbrio de Nash Perfeito de Subjogo 10.4.1 Jogo centípoda 10.5 Exercícios Ache todos os subjogos do jogo abaixo. Modelo o jogo como uma árvore (forma extensiva) e ache todos os subjogos do jogo abaixo. (exercício 156.2c do Osborne). Os políticos Rosa e Ernesto precisam tomar uma posição sobre um assunto. As opções são Berlim (B) ou Havana (H). Eles escolhem sequencialmente. Uma terceira pessoa, Karl, determina quem escolhe primeiro. Tanto Rosa quanto Ernesto se importam apenas com as ações que escolhem, não com quem escolhe primeiro. Rosa prefere o resultado em que ambos escolhem B ao resultado em que ambos escolhem H, e prefere esse resultado a qualquer um dos casos em que ela e Ernesto escolhem ações diferentes; ela é indiferente entre esses dois últimos resultados. As preferências de Ernesto diferem das de Rosa no sentido de que os papéis de B e H são invertidos. As preferências de Karl são as mesmas que as de Ernesto. Modele essa situação como um jogo extensivo com informação perfeita. (Especifique os componentes do jogo e represente o jogo em um diagrama.) Existem 6 subjogos próprios e 7 subjogos no total, contando o jogo inteiro como um subjogo. Equilíbrio de Nash Perfeito em Subjogos Definição informal: Um equilíbrio perfeito em subjogos é um perfil estratégico \\(s^*\\) com a propriedade de que, em nenhum subjogo, qualquer jogador \\(i\\) pode se sair melhor escolhendo uma estratégia diferente de \\(s^*_i\\), dado que todos os outros jogadores \\(j\\) aderem a \\(s^*_j\\). Nessa definição (informal), requeremos que a estratrégia de cada jogadora seja ótima para toda história após ser a vez dela jogar, e não apenas no início do jogo, como no equlíbrio de Nash. Todo jogo extensivo finito com informação perfeita possui (pelo menos) um equilíbrio perfeito de subjogo. Um jogo finito significa que em nenhum momento um jogador possui infinitas opções de ações. Para dar um exemplo trivial (do Osborne): um único jogador escolhe um número menor que 1 e recebe um pagamento igual ao número que ela escolhe. Não há um número maior que todos os outros números menores que um, então o jogador único não possui uma ação ótima, e assim o jogo não possui um equilíbrio perfeito de subjogo. 10.6 Game Theory Model of Regime Change 10.7 Introdução This extended model explores the aftermath of a successful transition to democracy, focusing on the potential for elite citizens to instigate a counter-revolution aiming to reinstate an authoritarian regime. It examines the strategic calculations involved in maintaining democracy or reverting to authoritarianism, factoring in the associated costs of such challenges. 10.8 The Game TThe society is composed of \\(N\\) citizens, partitioned into three income-based classes: poor (\\(N_{\\text{poor}}\\)), middle-income (\\(N_{\\text{middle}}\\)), and rich (\\(N_{\\text{rich}}\\)), satisfying the total population equation \\(N = N_{\\text{poor}} + N_{\\text{middle}} + N_{\\text{rich}}\\). Citizens’ incomes within each class are uniform, denoted as \\(y_i\\), with income ordered as \\(y_{\\text{poor}} &lt; y_{\\text{middle}} &lt; y_{\\text{rich}}\\). The total income is normalized to 1. In an authoritarian regime, the rich enjoy reduced taxation (\\(\\tau_a\\)), whereas a democratic regime would impose higher taxes (\\(\\tau_d\\)) to facilitate wealth redistribution. The model assumes \\(\\tau_d &gt; \\tau_a\\), indicating a tax increase with the transition to democracy. Participation in challenging the regime incurs a cost \\(\\mu\\), and the challenge’s success requires the collective action of at least \\(k\\) citizens, where \\(k &gt; \\frac{N}{2}\\). 10.9 Strategies Each citizen must decide whether to challenge (\\(C\\)) or not challenge (\\(NC\\)) the regime. The success of transitioning to democracy hinges on the collective action meeting or exceeding the threshold \\(k\\). 10.10 Payoffs The utility of each citizen hinges on their action, the collective actions, and the resultant political regime: \\[\\begin{align*} \\text{Payoff under Democracy: } U_i^{D,C} &amp;= y_i(1 - \\tau_d) + \\frac{\\tau_d}{N} - \\mu \\text{, for challengers} \\\\ \\text{Payoff under Democracy: } U_i^{D,NC} &amp;= y_i(1 - \\tau_d) + \\frac{\\tau_d}{N} \\text{, for non-challengers} \\\\ \\text{Payoff under Authoritarianism: } U_i^{A,NC} &amp;= y_i(1 - \\tau_a) \\text{, for non-challengers}\\\\ \\text{Payoff under Authoritarianism: } U_i^{A,C} &amp;= y_i(1 - \\tau_a) - \\mu \\text{, for challengers} \\end{align*}\\] 10.11 Best Response Functions The best response for each citizen depends on the strategies of others and the expected outcomes: \\[\\begin{align*} BR_{\\text{poor}}(s_{-i}) &amp;= \\begin{cases} C &amp; \\text{if } \\mu &lt; y_i^{\\text{poor}}(\\tau_d - \\tau_a) + \\frac{\\tau_d}{N}, \\\\ NC &amp; \\text{otherwise}, \\end{cases} \\\\ BR_{\\text{middle}}(s_{-i}) &amp;= \\begin{cases} C &amp; \\text{if } \\mu &lt; y_i^{\\text{middle}}(\\tau_d - \\tau_a) + \\frac{\\tau_d}{N}, \\\\ NC &amp; \\text{otherwise}, \\end{cases} \\\\ BR_{\\text{rich}}(s_{-i}) &amp;= \\begin{cases} C &amp; \\text{if } \\mu &lt; y_i^{\\text{rich}}(\\tau_d - \\tau_a) + \\frac{\\tau_d}{N}, \\text{ and expecting } \\sum_{j \\neq i} h_j \\geq k - 1,\\\\ NC &amp; \\text{otherwise}. \\end{cases} \\end{align*}\\] 10.12 Players and Phases Citizens: Classified into poor, middle-income, and rich (elite) classes. Phases: Transition to Democracy: Modeled as previously, with citizens deciding whether to challenge the authoritarian regime. Post-Transition Dynamics: Elite citizens weigh the decision to challenge the democratic regime to restore authoritarian rule. Given the threshold \\(k\\) for a successful transition, a Nash Equilibrium requires that no individual citizen has an incentive to unilaterally change their strategy, considering the collective outcome of their actions. 10.13 Analysis It is easy to see that challenging is a dominated strategy for all rich citizens in this game, since. "]]
