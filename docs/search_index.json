[["index.html", "Introdução à Teoria dos Jogos para Ciências Sociais Capítulo1 Prefácio", " Introdução à Teoria dos Jogos para Ciências Sociais Manoel Galdino 2025-05-22 Capítulo1 Prefácio Esse livro é o resultado das notas de aulas do curso de graduação da USP Teoria dos Jogos para Cientistas Sociais. O livro é largamente inspirado no de Steven Tadelis, Game Theory, an introduction, além de muitos materiais na internet para poder citá-los individualmente. "],["introdução.html", "Capítulo2 Introdução 2.1 Dilema do Prisioneiro 2.2 Dilema da Ação Coletiva 2.3 Happy hour 2.4 Dilema da Segurança 2.5 Cuidar da casa 2.6 Resumo de notação matemática 2.7 Referências", " Capítulo2 Introdução Uma das principais preocupações durante as eleições gerais de 2022 no Brasil era a disseminação de desinformação, conhecida popularmente como “fake news”. A utilização de redes sociais e aplicativos de mensagens para promover desinformação por eleitores e candidatos representava um importante ponto de potencial controle sobre a desinformação. Foi comum observar o Tribunal Superior Eleitoral determinando que plataformas removessem conteúdos contendo “fake news” eleitorais1. No entanto, essa situação se assemelhava a um jogo de “gato e rato”, uma vez que nada impedia que os divulgadores de “fake news” criassem novas postagens, perpetuando a disseminação de desinformação. Esse tipo de cenário político, no qual os atores precisam tomar decisões estratégicas, ou seja, planejar suas ações tentando antecipar as respostas dos outros, é exatamente o que a teoria dos jogos busca modelar e analisar. A política é repleta de situações em que um indivíduo deve agir supondo que os demais participantes do jogo político reagirão às suas ações e até mesmo tentarão antecipar seus movimentos, fazendo suposições e conjecturas sobre os outros. Isso representa uma das maiores dificuldades para os cientistas políticos na previsão dos efeitos de reformas eleitorais, por exemplo. Apesar de ser um tema frequentemente debatido e solicitado pela sociedade, muitas propostas são elaboradas como se o mundo não fosse estratégico, ou seja, como se os agentes políticos não fossem modificar seu comportamento devido às novas regras adotadas. Considere, por exemplo, a proibição de doações privadas de empresas para campanhas eleitorais, implementada no Brasil após decisão da Suprema Corte Federal em 2016. Muitos esperavam que isso reduzisse a influência do dinheiro nas eleições. No entanto, com o tempo, políticos aprovaram um fundo eleitoral com recursos públicos, aumentaram esse fundo sucessivamente e ainda aprovaram o que ficou conhecido como “Orçamento Secreto” para também aumentar as chances nas eleições, entre outros objetivos menos legítimos. Comparando o total de valores envolvidos após a decisão do STF com os valores anteriores, mesmo considerando o caixa dois, o montante provavelmente supera o que se gastava em eleições anteriores a 2016. É evidente que medidas como o “Orçamento Secreto” poderiam ser adotadas mesmo se o financiamento por empresas continuasse permitido, mas a mera possibilidade de que todas essas medidas sejam uma reação dos políticos à decisão do STF mostra quão difícil é antecipar as consequências de mudanças nas regras do jogo e que considerações estratégicas são fundamentais para entender a política. Portanto, a teoria dos jogos é um ramo da matemática aplicada que visa modelar situações estratégicas como essa. Um exemplo simples, mas muito esclarecedor, de como a teoria dos jogos pode elucidar essas questões é o Dilema do Prisioneiro, que apresentaremos a seguir. 2.1 Dilema do Prisioneiro Esse é talvez o mais famoso da história da Teoria do Jogos, chamado Dilema do Prisioneiro, e que foi proposto em 1951 por Merrill Flood em 1951, e primeiramente formalizado por Albert W. Tucker. A história é mais ou menos assim. A polícia prendeu dois suspeitos de cometer um crime. Tem evidência de um crime de pena menor, mas gostaria de condená-los por crimes com penas maiores. Se um ou ambos confessarem o crime maior, podem conseguir obter o que precisam. Para dar concretude, imaginem que a Polícia Federal prendeu dois executivos suspeitos de corrupção e lavagem de dinheiro, a dez anos de prisão. Possuem provas suficientes para condená-los por um crime menor, como tráfico de influência (dois anos de prisão), mas gostariam de condená-los pelo crime de pena maior. A PF colocou os dois presos em celas separadas e decidiu fazer a seguinte oferta para eles: “Nós temos evidência suficiente para condená-los, você e seu parceiro, pelo crime de tráfico de influência, que dá 2 anos de prisão para cada. Contudo, se você assinar um acordo de colaboração premiada com a gente e confessar o crime de corrupção e lavagem de dinheiro, você sairá livre e seu parceiro será condenado a dez anos de prisão. Um outro policial está na cela do seu parceiro, neste exato momento, fazendo a mesma oferta a ele. Se ele aceitar confessar o crime, e você não, então ele sairá livre e você ficará preso dez anos. Por fim, se ambos confessarem o crime, a pena de dez anos será reduzida à metade e vocês ficarão cinco anos presos. Essa proposta está por escrito, incluindo o fato de que seu parceiro está recebendo proposta igual”. O que você faria? Para analisar o DP, é comum construimos uma matriz de payoffs. Ela é uma tabela, que contém nas linhas e colunas as ações disponíveis para cada jogadora, e nas células temos os *payoffs”, que são as consequências ou resultados das combinações de ações de cada jogadora. A matriz abaixo apresenta uma possibilidade para o Dilema do Prisioneiro: ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;format&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) Coopera Não coopera Coopera (1,1) (20,0) Não coopera (0,20) (10,10) 2.2 Dilema da Ação Coletiva O Dilema do Prisioneiro é muito utilizado como base para pensar problemas de ação coletiva. A cooperação produz resultados socialmente melhores, porém a estratégia dominante individualmente é não cooperar. A partir do conhecimento da lógica do Dilema do Prisioneiro, podemos aplicá-la para outras situações de ação coletiva. 2.3 Happy hour Ocorrências prosaicas do dia a dia frequentemente refletem um cenário análogo ao Dilema do Prisioneiro. É comum que colegas de trabalho ou de faculdade decidam sair para o “happy hour” após o expediente ou término de aulas. E também é comum que ao final a conta seja dividida igualmente entre os presentes. E inevitavelmente alguém irá reclamar de que bebeu ou comeu pouco e está pagando mais do que deveria. Isso pode ser pensado como um exemplo do Dilema do Prisioneiro. 2.4 Dilema da Segurança Nas Relações Internacionais, o chamado Dilema da Segurança entre duas potência pode ser resumido da seguinte forma: ambos os países se beneficiam mais se ambos se desarmarem do que se ambos se armarem, mas cada um tem uma vantagem individual se for o único a se armar. Portanto, em equilíbrio, temos uma corrida armamentista. Mais uma vez, há similaridade com o Dilema do Prisioneiro aqui, já que a cooperação seria mutuamente benéfica, mas os países acabam em uma situação racionalmente indidivudal mas que é pior para todos. 2.5 Cuidar da casa A limpeza de uma casa é algo que benefícia a todos os membros da casa. No entanto, limpar a casa é custoso e limpar apenas a sujeira que você causou tem pouco impacto sobre a limpeza geral da casa, especialmente quando a casa é grande. Assim, mais uma vez temos uma esturtura similar ao Dilema do Prisioneiro, em que a cooperação seria benéfica, mas o equilíbrio é a não-cooperação, já que embora todos prefiram uma casa limpa a uma suja, o equilíbrio é ninguém limpar a casa. Implicações da Teoria dos Jogos para questões mais complexas A dinâmica de limpeza em um lar reflete não apenas a organização doméstica, mas também revela estruturas sociais mais profundas, como o patriarcado e o racismo. Historicamente, no Brasil, o cuidado com a casa e a geração do bem comum dentro do lar foram frequentemente atribuídos às mulheres, uma manifestação direta do patriarcado. Este arranjo social impõe o ônus da manutenção do lar majoritariamente sobre elas, enquanto os homens são poupados desse trabalho. Além disso, em contextos de classe média e alta, o racismo estrutural tem permitido que mulheres brancas transferissem a responsabilidade do trabalho doméstico para mulheres negras. Inicialmente, essa transferência ocorria por meio da escravidão e, posteriormente, através da contratação de empregadas domésticas. Essas empregadas, até muito recentemente, desempenhavam suas funções com poucos ou nenhum direito trabalhista, o que reflete não apenas uma desvalorização do trabalho doméstico, mas também a perpetuação de desigualdades raciais e de gênero. A aprovação da PEC das Domésticas marca um ponto de inflexão nesse cenário. Ao garantir direitos trabalhistas às empregadas domésticas, a PEC aumenta os custos associados à contratação desse tipo de serviço. Esse aumento de custo desafia o equilíbrio anterior, baseado na exploração e na desigualdade. Se por um lado a PEC contribui para uma redistribuição dos custos do bem comum doméstico, favorecendo a equidade racial ao impor responsabilidades financeiras mais justas às empregadoras, por outro, não resolve completamente as questões de gênero. A menos que o equilíbrio patriarcal também seja abordado, a responsabilidade pelo trabalho doméstico continuará a recair desproporcionalmente sobre as mulheres, seja dentro do contexto familiar ou no mercado de trabalho doméstico. Portanto, a mudança real exige uma abordagem que não apenas redistribua o custo do trabalho doméstico de maneira mais equitativa entre as raças, mas que também desafie e transforme as normas de gênero que atribuem esse trabalho principalmente às mulheres. 2.6 Resumo de notação matemática \\(\\doteq\\) relação de igualdade que é verdade por definição. Ex. \\(\\bar{x} \\doteq \\frac{\\sum_{i=1}^n(x_i)}{n}\\). \\(\\approx\\) aproximadamente igual. \\(\\varpropto\\) proporcional a. \\(P(X=x)\\) Probabilidade que a variável aleatória \\(X\\) assuma o valor \\(x\\). \\(\\mathbb{E}[X]\\) esperança de \\(X\\), isto é, \\(\\mathbb{E}[X] \\doteq \\sum_x(x)p(X)\\) \\(\\arg\\max_{x}(f(x))\\) o valor de \\(x\\) que maximiza \\(f(x)\\). \\(\\mathbb{R}\\) o conjunto dos números reais. \\((a,b]\\) o intervalo dos reais entre \\(a\\) e \\(b\\), incluindo \\(b\\) mas excluindo \\(a\\). \\(\\gamma\\) a menos que especificado em contrário, parâmetro de taxa de desconto intertemporal. \\(-i\\) indicado para se referir a todos as outras jogadoras que não a jogadora \\(i\\). \\(s_i\\) estratégia da jogadora \\(i\\). \\(s_{-i}\\) estratégia de todas as outras jogadoras que não a jogadora \\(i\\). 2.7 Referências Kollock, P. (1998). Social dilemmas: The anatomy of cooperation. Annual review of sociology, 183-214. Roxborough, I. (1992). Inflação e pacto social no Brasil e no México. Lua Nova: Revista de Cultura e Política, 197-224. https://www.tse.jus.br/comunicacao/noticias/2022/Outubro/combate-a-desinformacao-tse-derruba-mais-de-uma-centena-de-postagens-com-narrativas-enganosas↩︎ "],["racionalidade-e-relações-de-preferência.html", "Capítulo3 Racionalidade e Relações de Preferência 3.1 Tomada de decisão 3.2 Relações 3.3 Mais sobre relações binárias 3.4 Racionalidade 3.5 Funções de Payoff 3.6 Utilidade Ordinal 3.7 Exercícios", " Capítulo3 Racionalidade e Relações de Preferência Racionalidade é um conceito obviamente muito importante em qualquer teoria social e com implicações filosóficas. Pensadores da Grécia Antiga, como Aristóteles, definiam o ser humano como um animal racional, diferentemente portanto dos demais animais. Com os modelos de Linguagem Generativa, discussões sobre Inteligência Artificial retomaram, com muita confusão e “hype” sobre o que é inteligência e o que seria inteligência articial. Para além das questões filosóficas, importa para nós principalmente que racionalidade é uma presuposição chave para nossa teoria do comportamento dos agentes. A Teoria dos Jogos envolve, fundamentalmente, em especificar como agentes tomam decisões e, portanto, comportam-se em situações estratégicas. De modo que a tomada de decisão merece ser investigada em profundidade. 3.1 Tomada de decisão Existe um capo da ciência voltado à Teoria da Decisão, que grosso modo diz respeito a como agentes tomam decisões em situações não-estratégicas. A Teoria dos Jogos se diferencia da Teoria da Decisão, portanto, pelo compoente estratégico. Mas isso não significa que não compartilhem elementos chave sobre os pressupostos comportamentais de como agentes tomam decisões. Em uma eleição, cada eleitor tem um problema de decisão: em quem deve votar, dentre as várias alternativas (incluindo Nulo, branco e não ir votar). Similarmente, quando você vai almoçar, deve escolher qual comida irá comer. Ou pela manhã, quando for se arrumar para sair de casa, qual roupa vestir. Todos esses problemas se assemelham em um aspecto: uma pessoa (ou, como iremos chamar em Teoria dos Jogos, uma jogadora) deve escolher entre várias alternativas e cada escolha gerará um resultado, que pode ser melhor ou pior para a jogadora (e eventualmente outras jogadoras). A tomada de decisão consiste de três elementos fundamentais: 1. Ações : as alternativas que uma jogadora pode escolher 2. Resultados: as consequências de cada ação 3. Preferênciasˆ[Na escola eu aprendi que o verbo preferir não permite o uso de advérbios para qualificação de intensidade. Seria gramaticalmente errado dizer: prefiro muito ou mais goiaba à maçã. A razão é que a preferência seria um conector binário, que indica ordem, mas não quantidade. Como veremos, essa nocão gramatical do português será útil, mas em algum momento deve ser abandonada quando entramos na seara da incerteza]: quais resultados as jogadoras preferem. E vamos designar essas preferências pela relação (binária) de preferência \\(\\succcurlyeq\\), que significa, “pelo menos tão bom quanto”, ou seja, se escrevo \\(x \\succcurlyeq y\\), então \\(x\\) é pelo menos tõ bom quanto \\(y\\) (e potencialmente melhor que \\(y\\)). 3.2 Relações O conceito de relação (binária) na matemática está associado à presença de um tipo de vínculo específico entre elementos de um conjunto. Suponha o conjunto \\(A = \\{1, 2, 3\\}\\). A Relação \\(\\geq\\), entendida por “maior ou igual que” expressa uma relação de comparação de magnitude entre os elementos do conjunto. Assim, podemos dizer que \\(3 \\geq 2\\), e que \\(2 \\geq 2\\), exemplificando como a relação “maior ou igual que” se aplica. Em geral, podemos dizer que para quaisquer pares \\(x, y \\in A\\) podemos estabelecer a relação \\(x \\geq y\\). A partir desse exemplo, temos uma intuição para construir outros tipos de relações. Em particular, a relação de preferência. Relações de preferência \\(\\succcurlyeq\\) são tais que,se \\(x \\succcurlyeq y\\), isso quer dizer que \\(x\\) é pelo menos tão bom quanto \\(y\\). Às vezes aparece como fracamente preferido, no jargão econômico. Se \\(x \\succ y\\), então \\(x\\) é preferível a \\(y\\), ou \\(x\\) é melhor que \\(y\\). Por fim, quando temos \\(x \\sim y\\), então o jogador ou jogadora é indiferente entre \\(x\\) e \\(y\\), ou \\(x\\) é tão bom quanto \\(y\\). 3.3 Mais sobre relações binárias O conceito de relação de preferência pode ser difícil de entender a primeira vista, de forma que mais exemplos de relações binárias (como é a relação de preferência), podem ser úteis. Então, eis alguns exemplos de outros tipos de relação. 3.3.1 Relação de “inclusão” Nós estamos familiarizados com a ideia de que, e teoria dos conjuntos, existe a ideia de inclusão, quando dizemos que “o conjunto A está incluso no conjunto B”. Isso também é uma relação binária, chamada de relação de inclusão, que compara dois conjuntos e determina se um é um subconjunto do outro. Por outro lado, uma relação binária de preferência compara duas opções e determina se uma opção é preferida estritamente, fracamente preferida, ou se há indiferença entre as opções. 3.3.2 Relação de “antecessor/sucessor” Similarmente, podemos dizer que existe uma relação binária chamada “antecessor/sucessor”, que compara dois números e determina sua relação de sequência, como por exemplo, quando dizemos que “3 é o antecessor de 4”. 3.4 Racionalidade O Dilema do Prisioneiro é um jogo estudado inicialmente pelos matemáticos Merrill Flood e Melvin Dresherin em 1950, como parte da investigação da Corporação Rand sobre Teoria dos Jogos, por possíveis aplicações em estratégia nuclear global. O título “dilema do prisioneiro” e a estrutura de payoffs associada à história dos prisioneiros foi criada pelo matemático Albert Tuckerˆ[Kuhn, Steven, “Prisoner’s Dilemma”, The Stanford Encyclopedia of Philosophy (Winter 2024 Edition), Edward N. Zalta &amp; Uri Nodelman (eds.), URL = https://plato.stanford.edu/archives/win2024/entries/prisoner-dilemma/]. Nós consideramos que os jogadores são racionais no Dilema do Prisioneiro (DP). Mas o que é ser racional? A partir da noção de relação de preferência, podemos definir racionalidade com dois axiomas: Axioma da completude. A relação de preferência \\(\\succcurlyeq\\) é completa. Ou seja, para quaisquer dois resultados \\(x, y \\in X\\) é possível ranqueá-los pela relação de preferência, tal que ou \\(x \\succcurlyeq y\\) ou \\(y \\succcurlyeq x\\) ou \\(x \\sim y\\). O axioma da completude me diz apenas que, se eu tiver dois resultados, sempre vou poder dizer qual prefiro (incluindo dizer que sou indiferente). Porém, não posso ficar na dúvida e não conseguir decidir qual é preferido (ou se sou indiferente). Portanto, é um axioma que requer pouco das pessoas para poder chamá-las de racionais. Porém, vale notar que alguns estudiosos têm insistindo que indiferença é diferente de indecisãoˆ[Para um exemplo que explicar a diferença entre um e outro, cf. o começo do trabalgo de Eliaz, K., &amp; Ok, E. A. (2006). Indifference or indecisiveness? Choice-theoretic foundations of incomplete preferences. Games and economic behavior, 56(1), 61-86.]. Se um indivíduo possui preferências incompletas, isso significa que ele está indeciso sobre sua preferência em relação a duas alternativas. O segundo axioma é um pouco mais exigente e irá garantir que podemos ranquear \\(todos\\) os resultados. Axioma da transitividade. A relação de preferência \\(\\succcurlyeq\\) é transitiva. Ou seja, para quaisquer três resultados \\(x, y e z \\in X\\), se \\(x \\succcurlyeq y\\) e \\(y \\succcurlyeq z\\), então \\(x \\succcurlyeq z\\). O axioma da completude me diz que posso ranquear quaisquer dois resultados, e o axioma da transitividade me diz que não há contradição no meu ranqueamento. Para ver porque a condição de transitividade é mais demandante, considere o seguinte exemplo. Algumas pessoas preferem estritamente café sem açúcar a café com duas colheres de açúcar. Vamos supor que duas colheres de açúcar são 100 gramas de açúcar. A maioria das pessoas é indiferente entre café com 100 gramas e café com 99 gramas, porque a diferença de sabor é imperceptível. Igualmente, é indiferente entre café com 98 gramas e café com 99 gramas. E assim por diante, de modo que é indiferente a café com duas gramas de açúcar e uma grama, e também é indiferente a café com uma grama e café sem açúcar. Porém, prefere café sem açúcar a café com duas colheres de açúcar. Logo, as preferências não são transitivas. Essse exemplo ilustra que um axioma aparentemente inócuo para definir racionalidade, em uma situaçõa simples, como a preferência entre café com e sem açucar, pode significar que na verdade tal pessoa não é racional. A intransitividade, nesse caso, parece advir na verdade da violação do axioma da completude. Talvez as pessoas não sejam capazes de ranquear duas versoes de café com uma diferença muito pequena de açucar. Ou então, uma violação direta da intransitividade mesmo. De todo modo, são dois axiomas bastante simples em certo sentido e, no entanto, esses dois axiomas em conjunto podem vir a se revelar mais demandantes. De todo modo, parece razoável exigir que pessoas racionais tenham preferências transitivas. A razão para isso é porque, se elas não tiverem de fato preferências transitivas, é possível explorar essa irracionalidade. Tomando o exemplo acima, suponha que um café sem açúcar seja mais caro que um café com açúcar (digamos que a loja é patrocinada por uma empresa de açúcar, de modo que ela ganha mais dinheiro se vende café com açúcar). Em tese a pessoa aceitaria fazer 100 trocas de um café pelo outro com uma diferença de uma grama, tendo pagado mais caro pelo produto que poderia ser comprado mais barato. E o ciclo começaria de novo, até a pessoa ficar completamente sem dinheiro. Então, uma relação de preferência que é completa e transitiva, isto é, satisfaz os dois axiomas postulados por nós, é uma relação de preferência racional. Questão em sala de aula: Será que a escolha de sofia é um exemplo de violação do axioma da completude? Para mais críticas ao axioma da completude, ver por exemplo (no contexto da teoria da utilidade cardinal): Aumann, R. J. (1962). Utility theory without the completeness axiom. Econometrica: Journal of the Econometric Society, 445-462. 3.5 Funções de Payoff Uma das vantagens de se assumir relação de preferência racional é que é possível adotar uma esquema matemático mais operacional do seguinte modo. Suponha que você vai vender suco de limão e tem três possíveis ações: suco de baixa-qualidade \\(b\\), que custa 10 e você vende a 15; suco de média-qualidade \\(m\\), que custa 15 e você vende a 25, e suco de alta-qualidade, \\(a\\), que custa 25 e você vende a 32. Exercício em sala. Escrever o conjunto de ações $ A = {b, m ,a}$, o conjunto de payoffs ou resultados, considerando o lucro, e não a receita apenas: \\(X = {5, 10, 7}\\). Escrever a relação de preferência: \\(10 \\succ 7 \\succ 5\\). Assim, a melhor escolha é \\(m\\), que dá o maior lucro. Uma outra forma de escolher a melhor ação seria definir uma função de lucro p(A), e ver qual a escolha de A que maximiza o lucro. Por exemplo \\(P(b) = 5\\), \\(P(A) = 10\\) e \\(P(A) = 7)\\). Essa mesma lógica do lucro pode ser aplicada para qualquer decisão, mesmo que não envolva retornos monetários, contanto que a relação de preferência seja racional. Definição 1. Uma função de payoff (ou função de utilidade) \\(u: X -&gt; R\\) representa a relação de preferência \\(\\succcurlyeq\\) para todo par \\(x, y \\in X\\), \\(u(x) &gt;= u(y)\\) se e somente se \\(x \\succcurlyeq y\\). O que estamos dizendo é que a função de utilidade \\(u\\) recebe resultados do conjunto \\(X\\), e retorna um número real para cada resultado. E essa função representa nossa relação de preferência racional se, sempre que a utilidade de \\(x\\) for maior que a utilidade de \\(y\\), para qualquer \\(x\\) e \\(y\\), isso implicar que \\(x \\succcurlyeq y\\) e vice-versa. Veja que o número real a ser atribuído não tem sigifnicado algum e pode ser qualquer valor, desde que a relação de ordem seja preservada. A função de utilidade é uma construção ordinal, porque os payoffs são ordinais. Se um resultado gerar utilidade 10 e outro utilidade 5, não podemos dizer de verdade que o primeiro é duas vezes preferido ao segundo. 3.6 Utilidade Ordinal Não função de utilidade definida acima, a utilidade é ordinal. Uma das consequências é que podemos fazer quaisquer transformações na função utilidade que preservem a ordem de preferência. Esse tipo de transformação é chamado de transformação monotônica. Exercícios em sala: Digamos que eu tenha uma função de utilidade \\(u(x)\\) qualquer. Diga se as seguintes transformações são montônicas (isto é, preservam a ordem). \\(2*u(x)\\) \\(u(x) + 10\\) \\(log(u(x))\\). Suponha que \\(u(x) &gt; 0\\) para todo \\(x\\). \\(u(x)^3\\) \\(u(x)^2\\) \\(u(x) - 10\\) Formalmente, uma transformação da função utilidade por outra função \\(f\\) é monotônica se \\(f(u)\\) for uma função estritamente crescente de \\(u\\). Lembrando que uma função \\(f(x)\\) é estritamente crescente se ela cresce à medida que x cresce. Ou seja, \\(u_1 &gt; u_2\\) \\(\\implies\\) \\(f(u_1) &gt; f(u_2)\\). 3.7 Exercícios Exercise 3.1 Digamos que Serena prefira sushi a pizza e pizza a hambúrguer. Escreva a relação de preferências de Serena descrita acima, usando o símbolo de relação de preferências \\(\\succ\\). Exercise 3.2 Digamos que Serena prefira hambúrguer a sushi. Escreva a relação de preferências de Serena e diga qual axioma ela violou. Exercise 3.3 Explique, com suas próprias palavras, o que é o axioma da completude. Exercise 3.4 Considere a relação binária “ser melhor que ou igual a” em um jogo de futebol. Essa relação satisfaz o axioma da transitividade? Justifique sua resposta. E se “ser melhor que ou igual” no futebol for definido apenas pelo número de pontos obtidos pelas equipes em um campeonato. Essa relação satisfaz o axioma da transitividade? Exercise 3.5 Considere a relação binária “ser mais caro do que” em um mercado de produtos. Essa relação satisfaz o axioma da completude? Justifique sua resposta. Exercise 3.6 Na questão anterior, se você respondeu negativamente, como você modificaria a relação para que ela satisfizesse o axioma da completude. Exercise 3.7 Considere a relação binária “ser paralelo a” em um plano euclidiano. Essa relação satisfaz o axioma da transitividade? Dica: pense em retas paralelas. Exercise 3.8 No poema Quadrilha, de Carlos Drumond de Andrade, podemos imaginar que temos uma relação binária “amar”. Desconsiderando por um momento J. Pinto Fernandez, você diria que com as informações disponíveis no poema podemos rankear todos os demais personagens na relação “amar”? E se incluírmos J. Pinto Fernandez, sua resposta muda? Justifique sua resposta. Exercise 3.9 Crie uma relação binária diferente das apresentadas em sala de aula e nos exercícios acima, que satisfaça o axiomada da completude e transitividade. Exercise 3.10 Considere a relação binária “\\(&gt;=\\)”. Para mostrar que essa relação implica a relação “\\(&gt;\\)”, basta mostrar o seguinte. Sejam \\(x\\) e \\(y\\) dois números pertencentes ao conjunto X. Então, dizemos que \\(x &gt; y\\) se e somente se \\(x \\geq y\\) e não \\(y \\geq x\\). Às vezes é difícil entender o que queremos dizer por não \\(y \\geq x\\). Mas é só uma forma de negar uma relação. Então, por exemplo, se \\(x=3\\) e \\(y=2\\). Só é verdade que \\(3&gt;2\\) se também é verdade que \\(3 \\geq 2\\) e também é verdade que \\(2\\) não é maior ou igual a \\(3\\). De maneira similar, mostre que é possível derivar a relação “\\(\\sim\\)” da relação “\\(\\succcurlyeq\\)” Exercise 3.11 Considere o seguinte exemplo: o agente A prefere estritamente café com 7 gramas de açúcar a café sem açúcar, mas é indiferente entre café com 7 gramas de açúcar e café com 6,9 gramas de açúcar, entre café com 6,9 gramas de açúcar e café com 6,8 gramas de açúcar, e assim por diante, até ser indiferente entre café com 0,1 gramas de açúcar e café sem açúcar. O agente A é racional no sentido da Teoria dos Jogos? Justifique sua resposta. Exercise 3.12 Suponha que uma pessoa A prefira a cor vermelha à cor verde e prefira a cor verde à cor azul. No entanto, quando confrontada com um tom específico de verde-azulado, A pode ser indiferente entre esse tom e a cor verde. Isso pode levar a uma violação da transitividade, pois A prefere vermelho a verde e verde a azul, mas é indiferente entre verde-azulado e verde. Forneça um outro exemplo, similar a esse, utilizando outro sentido que não a visão. "],["incerteza-risco-e-utilidade-esperada.html", "Capítulo4 Incerteza, risco e utilidade esperada 4.1 Risco 4.2 Incerteza 4.3 Preferências sobre loterias 4.4 Utilidade esperada 4.5 Risco versos Incerteza 4.6 Aversão a risco 4.7 Teoria e Prática 4.8 Exercícios 4.9 Referências", " Capítulo4 Incerteza, risco e utilidade esperada Frequentemente nossas decisões estão envoltas em incertezas. Considere o problema de decisão do eleitorado. É preciso avaliar as alternativas disponíveis, esperando um certo resultado, que é incerto. Políticos não cumprem promessas, circunstâncias mudam, pessoas morrem e seus vices assumem etc. Similarmente, imagine uma gestora pública municipal que foi apresentada a uma nova pesquisa, que sugere que é melhor que crianças entrem na escola uma hora mais tarde. Porém, isso mudará a organização dos cuidadores das crianças, professores e toda a dinâmica escolar, além do que o estudo foi feito em poucas escolas, não necessariamente se generalizando para todo o município. decidindo se adotar uma nova política pública ou continua com a anterior. Será que vale a pena esta nova política pública? Como é uma política nova, há incerteza sobre os benefícios que podem advir dela, bem como dificuldades não antecipadas inteiramente. Portanto, nosso modelo de tomada de decisão precisa incorporar incerteza de algum modo. Em nosso paradigma da escolha racional, precisamos formalizar a incerteza para além de uma linguagem vaga. Termos como “é possível”, “pode ou não acontecer”, “talvez”… são imprecisos. Vamos então introduzir um modo pelo qual jogadoras podem comparar ações cujos resultados são incertos de uma maneira estruturada e formalizável. Nesta abordagem, utilizaremos o conceito de probabilidades, de forma a definir payoffs sobre resultados aleatórios. 4.1 Risco Imagine que você é a gestora pública. Vamos formalizar o problema que ela enfrenta da forma mais simples possível, de modo a introduzir as ideias mais importantes de como modelar incerteza. Vamos chamar suas duas possíveis ações, inovar, \\(i\\) e manter o status quo, \\(s\\), de forma que o conjunto de ações é \\(A = \\{i,s\\}\\). Vamos supor também que só há dois resultados possíveis: um benefício de \\(10\\) (digamos, a nota na avaliação municipal é dez pontos maior) ou de \\(0\\), de modo que \\(X = \\{0,10\\}\\). Entretanto, diferentemente de um mundo sem incerteza, não há correspondência unívoca entre ações e resultados. Para formalizar a ideia de incerteza aqui, precisamos atribuir probabilidades aos resultados em função de cada ação escolhida. Nesse exemplo fictício, as probabilidades são arbitrárias. Voltaremos a como determinar probabilidades mais à frente. Suponha que se ela escolher adotar a nova política há uma chance disso resultar em aumento de 10 pontos na avaliação escolar de 3 para 1, enquanto se não adotar a política e manter as coisas como estão, a chance é de 50%-50%. Dizendo de outro modo, a ação \\(i\\) gera benefício \\(10\\) com probabilidade \\(1/4\\) e benefício \\(0\\) com probabilidade \\(3/4\\), enquanto a ação \\(s\\) gera benefício \\(10\\) com probabilidade \\(1/2\\) e benefício \\(0\\) com a mesma probabilidade. A introdução de probabilidades traz incerteza para nossos jogos. Por isso é importante entender como nossa teoria de comportamento racional pode se modificar na presença de incerteza. 4.2 Incerteza A ideia da incerteza foi inicialmente abordada com a ideia de calcular o valor esperado de ações e escolher aquela ação que rende o maior valor esperado. Considere o seguinte jogo. Após responder várias perguntas corretas, uma pessoa em um programa de TV tem a seguinte escolha para fazer: a) será jogada uma moeda. Se cair coroa, ganha 100 mil reais. Se der cara, não ganha nada. b) Escolher entre três envelopes, cada um contém prêmios no valor de 90 mil reais, 30 mil reais e 15 mil reais. Qual estratégia ele deve escollher? Uma forma de responder a essa pergunta é calcular o valor esperado de cada ação, que pode ser feito da seguinte forma: a) \\(VE(A) = 100000*.5 + 0*.5 = 50.000,00\\) b) \\(VE(B) = 90000*(1/3) + 30000*(1/3) + 15000*(1/3) = 30000 + 10000 + 5000 = 45000\\) Se utilizamos como critério de decisão escolher a alternativa com maior valor esperado, a participante deveria escolher A, pois em média paga mais que do que a opção B. De maneira geral, se tenho uma ação disponível \\(s_i\\), com resultados possíveis \\(v_1, v_2, ... v_k\\) cada um deles com probabilidade \\(p_1, p_2, ..., p_k\\), de tal modo que \\(\\sum_j=1^k(p_j) = 1\\) e \\(p_j \\ge 0, \\forall j = \\{1,2,...,k\\}\\), então o valor esperado de \\(s_i\\) é dado por: \\[ VE(s_i) = v_1p_1 + v_2p_2 + ... + v_kp_k \\] Uma justificativa para a ideia de maximizar o valor esperado é a seguinte. A pessoa se defronta com várias decisões em sua vida que possuem riscos. Pode comprar um carro com algum opcional de segurança que reduz seu risco de vida em acidentes, se vai atravessar fora da faixa e pedestre, se anda de moto, se sai na chuva em dia de raios etc. Cada decisão dela tem um risco e se escolher sempre maximizando a utilidade esperada, na média de longo prazo terá um retorno maior. Um problema da abordagem de maximizar o valor esperado é ilustrado pelo Paradoxo de São Petersburgo. Considere o seguinte jogo. Uma moeda é jogada, se o resultado é coroa, o jogador é pago 1 real e o jogo acaba. Se der cara, o jogo continua e uma moeda é novamente lançada. Se der coroa, recebe dois reais e o jogo acaba. Se der cara, o jogo continua e uma moeda é novamente lançada. Se der coroa, o jogador ganha 4 reais e o jogo acaba. Se der cara, o jogo continua, e assim indefinidamente, sempre dobrando o valor pago até o momento em que der cara. Suponha que a casa tem fundos ilimitados. Qual o valor esperado desse jogo? Ou, colocando de outro modo, quanto um jogador racional (no sentido de maximizar valor esperado) deveria pagar para ter o privilégio de jogar esse jogo? O jogo basicamente tem a seguinte configuração. A casa paga 1 real com probabiliade 50%, 2 reais com probabilidade 25%, 4 reais com prob. 1/8 e assim por diante: \\(VE(jogo) = 1*(1/2) + 2*(1/4) + 4*(1/8) + ...\\) Veja que essa soma infinita é equivalente a: \\(VE(jogo) = 1/2 + 2*/4 + 4/8 + ... = 1/2 + 1/2 + 1/2 + ...\\) O que dá uma soma infinita. Usando nossa lógica de escolher ações cujo valor esperado é maior, entre a alternativa de pagar toda a fortuna de uma pessoa para jogar o jogo e não jogar e preservar a forturna, pagar a fortuna dá um valor esperado maior, pois infinito menos uma quantia finita é ainda infinito. Obviamente, não faz sentido escolher jogar esse jogo pagando toda a sua fortuna, pois na prática em algum momento a pessoa irá perder antes de recuperar o valor de sua forturna. Naturalmente, a questão seguinte a se perguntar é: podemos encontrar algum outro princípio para fundamentar a decisão sob incerteza? Daniel Bernoulli, matemático, percebeu que o valor monetário é diferente a depender de quanto dinheiro você tem. O valor de mil reais para uma pessoa pobre é diferente do valor de mil reais para uma pessoa rica. Obviamente podemos supor que mais dinheiro é preferido a menos, porém não de maneira linear. Bernoulli sugeriu uma “lei da utilidade decrescente”, como ficou conhecida depois, segundo a qual cada real adicional gera um pouco menos de utilidade. Mais ainda, ele propôs que a relação entre dinheiro e utilidade deveria ser logarítmica, o que implica que mudanças percentuais no dinheiro implicam mudanças iguais na utilidade. Duas críticas forma feitas à proposta de Bernoulli. Em primeiro lugar, a arbitrariedade do uso de logarítmo. Em segundo lugar, como medir utilidades? Nós já vimos que podemos trabalhar com utilidades ordinais. Mas utilidade cardinal é bem mais complicado. Tivemos de esperar até o trabalho de von Neumann e Morgenstern (VNM), com o livro Game Theory and Economic Behavior (1944) para haver uma reabilitação das ideias propostas por Bernoulli. A ideia chave de VNM é que é possível estimar a intensidade de preferências em uma escala intervalar (em que os pontos máximos e mínimos são arbitŕarios, como na escala de Celcius e Farenheit) a partir da elicitação de preferências sobre loterias. Com representações numéricas de utilidade, podemos calcular a utilidade esperada (à maneira do valor esperado), exceto que a utilidade marginal pode ser decrescente e, portanto, evitar o paradoxo de São Petersburgo. Para tanto, é preciso introduzir o conceito de loterias, o que faremos a seguir. 4.3 Preferências sobre loterias Já que estamos falando de loterias em nossa definição, é importante fazer um “detour” para explicar o conceito de loterias e preferências sobre loterias Uma loteria existe quando eu tenho payoffs que têm um componente aleatório. A mega-sena paga alguns milhões de reais com uma dada probabilidade, e zero reais com outra probabilidade. Por isso que temos uma loteria nesse caso. Vamos definir formalmente uma loteria em nosso contexto. Definição 4.1. Uma loteria simples sobre resultados \\(X = \\{x_1, x_2, ..., x_n\\}\\) é definida como a distribuição de probabilidade \\(p = (p(x_1), p(x_2), ..., p(x_n))\\), em que \\(p(x_k) \\ge 0\\) é a probabilidade de que \\(x_k\\) ocorra e \\(\\Sigma_{k=1}^n x_k = 1\\). Aplicando a definição para a mega-sena, e considerando um caso simplificado em que há apenas dois resultados, ganhar \\(x\\) milhões de reais e não ganhar nada (excluímos quina, quadra e divisões do prêmio para mais de um ganhador), uma loteria são as probabilidade de cada resultado. 4.4 Utilidade esperada Suponha que uma loteria tem quatro possíveis prêmios (resultados): \\(x_1, x_2, x_3, x_4\\). Suponha que os prêmios foram ordenados em ordem ascendente de preferência, isto é, \\(x_4 \\succ x_3 \\succ x_2 \\succ x_1\\). Agora, atribua valores de utilidade arbitrários para o prêmio mais desejado e o menos desejado. Digamos: \\(u(x_4) = 1\\) e \\(u(x_1) = 0\\). Veja que atribuir um máximo e mínimo arbitrário é algo que fazemos quando criamos as escalas de graus Celcius e Farenheit. Na primeira, escolhemos o máximo (\\(100 ^{\\circ}C\\)) e mínimo (\\(0 ^{\\circ}C\\)) como os pontos de ebulição e congelamento da água, em condições normais de atmosfera e pressão. Na segunda, definimos (\\(212 ^{\\circ}F\\)) como o ponto de ebulição da água e (\\(32 ^{\\circ}F\\)) como o ponto de congelamento da água. Claro que sabemos que podemos ter valores abaixo do mínimo e acima do máximo, mas para uma amostra de dados dentro desse intervalo, estamos fazendo essencialmente a mesma coisa. Voltando ao nosso exemplo. Como nas escalas Celcius e Farenheit, podemos atribuir quaisquer outros números como máximo e mínimo para a utilidade. Contudo, é conveniente matematicamente (já veremos o porquê) usar zero e um. Usando esses dois valores de utilidade como ancoragem, o ponto do teorema de VNM é que existe uma forma garantida de atribuir utilidades numéricas para as preferências de cada um dos prêmios, de forma que podemos trabalhar com o caĺculo de utilidade esperada. O procedimento é o seguinte. Considere qualquer outro prêmio (por exemplo, \\(x_2\\)). Pergutamos então a cada jogador qual a probabilidade \\(p_2\\) que tornaria ela indiferente entre ganhar \\(x_2\\) com certeza e \\(x_4\\) com probabilidade \\(p_2\\) e \\(x_1\\) com probabilidade \\(1 - p_2\\). Veja que quanto mais valioso for \\(x_2\\), maior deve ser \\(p_2\\), a chance de ganhar \\(x_4\\) o prêmio mais valorizado, para que a pessoa aceite trocar algo certo por aldo duvidoso. Assim, \\(p_2\\) mede a desejabilidade do prêmio \\(x_2\\). A gente repete esse experimento com \\(x_3\\) e assim teremos uma medida da desejabilidade de todos os prêmios. E VNM definem a utilidade de cada prêmio como a aposta (loteria) que cada jogador considera igualmente desejável ao prêmio. No caso em tela: \\(u(x_i) = p_i*1 + (1-p_i)*0 = p_i\\) Mais formalmente, temos: Definição 4.2. Seja \\(u(x)\\) a função de utilidade (ou payoff) sobre resultados \\(X = \\{x_1, x_2, ..., x_n\\}\\), e seja \\(p = \\{p_1, p_2, ..., p_n\\}\\) uma loteria sobre \\(X\\) tal que \\(p_k = p(x = x_k)\\). Definimos então a utilidade esperada da loteria \\(p\\) como: \\[ \\mathbb{E}[u(x)|p] = \\sum_{k=1}^n p_ku(x_k) = p_1u(x_1) + p_2u(x_2) +... + p_nu(x_n) \\] Ao escolher os valores máximos e mínimos da utilidade de maneira conveniente, as probabilidades passam a medir a desejabilidade diretamente de cada prêmio. Temos portanto números para as utilidades que não são apenas ordinais, mas cardinais. Eu sei que nós gastamos tempo repetindo e enfatizando que a teoria da utilidade tratava apenas de representar preferências ordinais e, portanto, os números eram completamente arbitrários. Agora não. Somente os pontos máximos e mínimos são arbitrários, mas todos os demais são derivados por esse experimento mental. Isso significa que agora os números refletem a intensidade da preferência, e não apenas mais a ordem. Isso pode alterar as decisões doa agentes, ainda que a ordem de preferências seja mantida. Na verdade, para ser mais preciso, o que VNM mostram é que se alguns axiomas forem satisfeitos, então agentes racionais se comportatão como se tivessem respondido a essas perguntas desse experimento. Mas não precisam de fato fazer esse experimento para se comportarem desse jeito. Mais ainda, em situações de incerteza, agentes racionais escolherão o que maximizar sua utilidade esperada. A Teoria da Utilidade Esperada, portanto, ajuda a explicar porque pessoas contratam seguros ou apostam em loterias como a mega-sena. Embora o valor esperado seja negativo em ambas as escolhas, as pessoas possuem utilidades distintas de cada opção (jogar ou não jogar, contratar ou não-contratar seguro). 4.5 Risco versos Incerteza Até aqui não temos feito diferenciação entre incerteza e risco. Contudo, nas ciências sociais, muita discussão foi feita ao longo do século XX sobre a diferença entre esses dois conceitos. O economia John Manard Keynes, por exemplo, defendia que risco eram aquelas situações nas quais podemos calcular uma probabilidade objetiva, enquanto incerteza seriam situações em que não poderíamos atribuir uma probabilidade. Exemplo de risco seria uma probabilidade de chover, que pode impactar os rendimentos de um evento (um show a ceu aberto) ou negócio (um bar na praia), enquanto incerteza envolveria coisas como uma decisão de investir em um novo negócio, ou a possibilidade de uma pandemia mundial. A diferença entre os dois conceitos parece ter sido introduzida pela primeira vez pelo economista Frank Knight, que escreveu em 1921: Uncertainty must be taken in a sense radically distinct from the familiar notion of risk, from which it has never been properly separated…. The essential fact is that ‘risk’ means in some cases a quantity susceptible of measurement, while at other times it is something distinctly not of this character; and there are far-reaching and crucial differences in the bearings of the phenomena depending on which of the two is really present and operating…. It will appear that a measurable uncertainty, or ‘risk’ proper, as we shall use the term, is so far different from an unmeasurable one that it is not in effect an uncertainty at all”. Em resumo, incerteza é quando eventos futuros ou resultados de ações não poderiam ter uma probabilidade associada, enquanto risco seriam situações opostas, ou seja, quando é possível atribuir uma probabilidade. Do ponto de vista da abordagem Bayesiana, que implicitamente é utilizada em nosso curso, tal diferença não faz sentido. Toda situação de incerteza pode ser modelada como uma probabilidade, ainda que subjetiva, isto é, baseada apenas em um mero chute. 4.6 Aversão a risco Tipicamente as pessoas são avessas ao risco. No contexto da utilidade esperada, isso quer dizer que as pessoas preferem um payoff certo a uma aposta justa. Em outras palavras, se eu oferecer uma escolha entre ficar como está ou uma aposta em que você ganha mil reais se der cara, paga mil reais se der coroa, as pessoas tendem a preferir a primeira opção, ainda que o valor esperado seja igual. Se você for indiferente entre as duas opções, dizemos que você é neutro ao risco. E se prefere a aposta, você é amante do risco. Tipicamente em modelos na ciência política, assume-se neutralidade ao risco ou aversão ao risco. Aversão ao risco é visto como a suposição mais aceitável e neutralidade ao risco é suposta apenas quando é mais fácil a matemática e a conclusão não muda se supusermos aversão ao risco. 4.7 Teoria e Prática Muitos testes foram feitos para verificar se o comportameto das pessoas em situações experimentais condizem com o previsto pela TUE. Em particular, Tversky and Kanheman realizaram uma série de experimentos. Vamos apresentar uma versão de um deles aqui. “Suponha que o Brasil está se preparando para um surto de uma doença que surgiu em outro país e a expectativa é que a doença matará 600 pessoas se nada for feito. Dois programas alternativos para combater as doenças foram pensados. Assuma que as exatas consequências científicas dos programas são como seguem: Programa A: 200 pessoas serão salvas. Programa B: Há uma probabilidade de \\(1/3\\) que 600 pessoas serão salvas, e uma probabilidade de \\(2/3\\) que nenhuma pessoa será salva. A utilidade esperada em função do número de pessoas salvas do programa A é: \\(u(200)\\), enquanto a de B é \\(\\frac{1}{3}u(600))\\). 72% escolheram A e 28% B Programa C: 400 pessoas morrerão. Programa D: Há uma probabilidade de \\(1/3\\) que ninguém morrerá, e uma probabilidade de \\(2/3\\) que 600 pessoas morrerão. Nesse caso, a utilidade esperada de C é \\(u(200)\\) e a de D é \\(\\frac{1}{3}u(600))\\). Já nesse cenário, 78% preferem D e 22% preferem C. Vejam que as utilidades esperadas são as mesmas, o que muda é apenas o framing das questões, em torno de pessoas salvas ou mortas. 4.8 Exercícios Exercise 4.1 Considere o seguinte jogo em um cassino. Você joga um dado de seis faces. Se sair \\(1\\), você recebe \\(25\\) reais. Se sair \\(2\\) você paga \\(5\\) reais ao cassino. Se o dado for \\(3\\), nada acontece. Se sair um \\(4\\) ou \\(5\\), você paga \\(10\\) ao cassino. Se sair um \\(6\\), você paga \\(15\\) Calcule o valor esperado do jogo. Você jogaria o jogo? Explique. Exercise 4.2 Considere o seguinte jogo. Em uma baralho comum de 52 cartas, com quatro naipes (copas, ouro, espada e paus), você escolhe uma carta ao acaso e ganha 10 reais se for de copas. Se tirar um Valete, Dama ou Rei que não seja de copas, você ganha 8. Qualquer outra carta, perde 4. Calcule o valor esperado do jogo. Exercise 4.3 Suponha que a chance de seu carro ser roubado é de uma em mil. Seu carro vale R\\(\\$\\) \\(50.000,00\\). Uma companhia de seguro decide te cobrar um prêmio de 100 reais para segurar seu carro contra roubo (e apenas contra roubo). Você faz o seguro, ou não? Explique. Você consegue imaginar uma probabilidade de roubo do seu carro que faria você mudar de ideia quanto ao seguro? Se sim, qual seria essa probabilidade? Exercise 4.4 Suponha que um indivíduo enfrenta uma loteria L que oferece uma chance de \\(50\\%\\) de ganhar 100 reais e \\(50\\%\\) de ganhar 0. Se a função de utilidade do indivíduo para dinheiro é \\(u(x)= x\\), qual é a utilidade esperada de participar na loteria L? E qual o valor esperado da loteria? Nesse caso, o valor esperado e a utilidade esperado são iguais? Como você interpreta isso? Exercise 4.5 Uma jogadora, Alice, tem a escolha entre um emprego seguro que paga uma renda certa de $50.000 por ano ou um empreendimento que pode render $100.000 anual com probabilidade de \\(50\\%\\) ou $10.000 com probabilidade de \\(50\\%\\). Calcule o valor esperado de ambas as opções. calcule a utiidade esperandas de ambas as opções se a função de utilidade for \\(u(x) = x\\), \\(u(x) = \\sqrt{x}\\) e \\(u(x) = log(x)\\), em que \\(x\\) é a renda da jogadora. Qual opção Alice deve escolher, com base na utilidade esperada para cada função de utilidade. Exercise 4.6 Dois países, A e B, estão em uma disputa sobre a poss de um território que pode levar à guerra. O país A estima que tem \\(60\\%\\) de chance de ganhar a guerra, que resultaria em controle total do território e uma utilidade de 200, já perder a guerra geraria uma utilidade de -100. Para o país B, a chance de ganhar a guerra é \\(40\\%\\), com os mesmos valores de utilidade para ganhar ou perder a guerra. Calcule a utilidade esperada de uma guerra para ambos os países. Divida a utilidade da vitória e derrota por 100. Verifique que a utilidade esperada é igual à utilidade esperada de antes, dividida por 100. Suponha que a função de utilidade do território em disputa em uma solução diplomática é \\(u(x) = 300x\\), em que \\(x\\) é o percentual (entre 0 e 1) de controle por um país do território em disputa. Se houver guerra, a função de utilidade do controle do território passa a ser \\(u(x) = 300x - 100\\). Lemebrando que, se um país vence a guerra, o controle é \\(100\\%\\) para o vencedor e \\(0\\%\\) para o perdedor. Suponha que se uma solução diplomática for acordada, ela é implementada com certeza. Se B oferecer metade do território em disputa para A, ambos os países prefeririam essa solução à guerra? Qual o tamanho mínimo do território que B deveria oferecer a A para que este fosse indiferente entre fazer ou não a guerra? 4.9 Referências Knight, F. H., 1921. Risk, uncertainty and profit. University of Chicago Press. "],["jogos-na-forma-normal.html", "Capítulo5 Jogos na Forma Normal 5.1 Conhecimento Comum. 5.2 Estratégias 5.3 Jogos na forma normal ou estratégica 5.4 Votos em comissão 5.5 Exercícios", " Capítulo5 Jogos na Forma Normal Jogos estáticos de Informação Completa (como o DP) envolvem considerações estratégicas sobre o que os outros jogadores irão fazer. Um jogo de informação completa é caracterizado pelas seguintes quatro informações serem de conhecimento comum: 1. todas as possíveis ações de todas as jogadoras, todos os possíves resultados, Como a combinação de cada ação de todas as jogadoras afeta qual resultado irá acontecer e se materializar, e As preferências de todas jogadoras sobre os resultados. Vejam que o DP satisfaz esse requerimento. 5.1 Conhecimento Comum. Definição 5.1 Um evento \\(E\\) é conhecimento comum se todo mundo sabe \\(E\\), todo mundo sabe que todos sabem \\(E\\), todo mundo sabe que todo mundo sabe que todos sabem \\(E\\) e assim por diante, até infinito. Um exemplo simples em que podemos assumir que um evento é conhecimento comum. Suponha que duas pessoas saiam da sala e, andando na rua, começa a chover e eles correm para não se molhar. É razoável assumir que é conhecimento comum que está chovendo para essas duas pessoas. 5.2 Estratégias O reality show “No limite” é uma adaptação do equivalente americano chamado “Survivor”. Nesse jogo, dois times (azul e vermelho) competem para ganhar os desafios. Como recompensa, só um membro do outro time é eliminado, além de ganharem outros benefícios (dormir em uma cama, mais comida etc.). Em uma das disputas, um jogo foi apresentado no programa que é útil para os nossos propósitos. link: https://www.youtube.com/watch?v=aonCsvi0LKc Conforme pode ser visto no vídeo, havia 21 bandeiras fincadas na areia. O time vermelho começa jogando e pode escolher 1, 2, ou 3 bandeiras (um time não pode escolher pegar 4 ou mais bandeiras, ou nenhuma bandeira). Em seguida, é a vez do time azul, que têm as mesmas opções. Quem pegar a última bandeira ganha o jogo. A solução do jogo é por indução para trás. Imagine que é sua vez de jogar e tem uma bandeira. Pegue a bandeira e ganhe o jogo. Se tiver duas, pegue as duas. Se tiver três, pegue as três. Se tiver quatro, não há o que você possa fazer para evitar que o time adversário esteja na situação anterior de ter uma, duas ou três e ganhe o jogo. Portanto, quem chegar na sua vez com quatro bandeiras, perde o jogo. O que acontece se você chegar com cinco? Você pega uma, deixa o outro time com quatro, e você ganha o jogo. Similarmente se na sua vez houver 6 ou 7 bandeiras, você pega duas ou três bandeiras respectivamente e deixa o outro time com quatro. Por outro lado, se na sua vez tiverem 8 bandeiras, não importa quantas bandeiras pegue, deixará o time adversário com 5, 6 ou 7 e eles deixarão você com quatro. Por raciocínio similar, você deve evitar ficar com 12, 16 e 20 bandeiras e, se possível, deve deixar sempre o outro time com 20, 16, 12, 8 e 4 bandeiras para escolher. Portanto, quem começa o jogo, se jogar corretamente, vence a partida. Nós iremos analisar com calma esse jogo na aula de jogos na forma extensiva, em que desenharemos a árvore do jogo. Por agora, o que quero destacar é o seguinte. Se, em vez do jogo ser sequencial, como vimos no vídeo, o jogo fosse jogado por meio de uma instrução, em que você deve especificar como deve ser jogado, a instrução vencedora seria assim: Se o time vermelho começa jogando, então poderia adotar o seguinte plano de ação. Pegue uma bandeira e o outro time ficará com 20. Se eles pegarem uma, pegue três em seguida. Se pegarem duas, pegue duas em seguida. Se pegarem três, pegue uma em seguida. Adote essa regra em cada rodada após o primeiro movimento. Uma outra forma de dizer o plano de ação é que deve começar por uma bandeira, e em seguida a jogada \\(y\\) é dada por \\(4 - x\\) bandeiras, em que \\(x\\) é quanto o outro time pegou na rodada anterior. O time azul não tem saída, mas, caso o outro time erre (como aconteceu no jogo), sua instrução poderia ser: Se houver 20, 16, 12, 8 ou 4 bandeiras, escolha qualquer número. Porém, se o número de bandeiras for diferente desses números, escolha tantas bandeiras quanto forem necessárias para sobrarem 20, 16, 12, 8 ou 4. Uma vez que o jogo é analisado e uma plano de ação é definido, tanto faz quem pega as bandeiras. Até um robô com as instruções poderia fazer um serviço. Tal plano de ação, que define o que fazer em cada contigência, é o que chamamos de estratégia em teoria dos jogos. Pensemos em outro exemplo, como o jogo infantil pedra, tesoura e papel. Imagine que você quer jogar esse jogo, mas irá jogar por intermédio de um amigo, e você deve passar instruções sobre como jogar. Então, uma estratégia, pode ser: “jogue pedra”, e outra poderia ser “jogue papel”. A noção de estratégia é distinta de uma ação ou movimento em um jogo, embora isso não fique tão claro em jogos na forma normal ou estratégica. A razão é que, em muitos casos (como no Dilema do Prisioneiro, ou no jogo de pedra-papel-tesoura), as estratégias disponíveis para os jogadores coincidem com as ações. Quando introduzirmos a forma extensiva do jogo, a diferença entre estratégia e ação ficará mais clara. Por enquanto, é importante sabermos que os dois conceitos são distintos, ainda que possam coincidir na prática em jogos simultâneos de dois jogadores. Vamos então introduzir formalmente algumas definições relativas à noção de estratégia. Definição 5.2: Uma estratégia pura para uma jogadora \\(i\\) é um plano determinístico de ação. O conjunto de todas as estratégias puras para o jogador \\(i\\) é chamado de \\(S_i\\). Um perfil de estratégias puras \\(s = \\{s_1, s_2, ..., s_n\\}, s_i \\in S_i\\) para todo \\(i = 1, 2, ..., n\\) descreve uma combinação particular de estratégias puras escolhidas por todos as \\(n\\) jogadoras no jogo. Vamos entender a definição primeiro por meio de um exemplo. No caso do Dilema do Prisioneiro, temos dois jogadores, ou seja, o conjunto de jogadores é dado por \\(N = \\{1,2\\}\\) e \\(n = 2\\). O conjunto de todas as estratégias pura do jogador 1 é formada por duas estratégias, confessar e não-conessar. Podemos, portanto, escrever \\(S_1 = \\{(\\text{Confessar}, \\text{não-confessar})\\}\\). Similarmente para o jogador 2, de modo que \\(S_i = \\{(\\text{Confessar, não-confessar})\\}\\), para \\(i \\in {1,2}\\). Uma combinação particular de estratégias puras escolhida pelos dois jogadores pode ser o equilíbrio do jogo, ou seja, \\(s = \\{(\\text{confessar, confessar})\\}\\), em que \\(s_1 = s_2\\), que é a estratégia confessar. 5.3 Jogos na forma normal ou estratégica Um jogo na forma estratégica ou normal incluem três componentes: 1. Um conjunto finito de jogadoras \\(N = \\{1, 2, ..., n\\}\\) Uma coleção de conjuntos de estratégias puras, \\(\\{S_1, S_2, ...., S_n\\}\\) Um conjunto de funções de payoff, \\(\\{v_1, v_2, .., v_n\\}\\), cada uma atribuindo um valor de payoff para cada combinação de estratégias, ou seja, um conjunto de funções \\(v_i: S_1 * S_2 * ... * S_n \\to R\\) para cada \\(i \\in N\\) Vamos destrinchar o item 3, que parece complexo e assustador, mas é bem simples. Vou usar exemplos para explicar cada uma das partes de 3. Suponha que eu tenho um conjunto \\(A\\) dado pelas cidades do estado de São Paulo, e um conjunto \\(B\\) dado pelas cidades do estado do Rio de Janeiro. Seja \\(f\\) a função que recebe duas cidades (uma de SP, outra do RJ) e retorna a distância em linha reta entre elas, calculada pelo google, em km. Eu posso descrever essa função do seguinte modo: \\(f: A \\cdot B \\to R\\). Como minha função sempre retorna uma distância em km, a distância é um número real. Então, ela recebe dois elementos, um de A e um de B, e retorna um número real. Falta explicar a parte em que escrevemos \\(A \\cdot B\\). O produto de dois conjuntos \\(X\\) e \\(Y\\) é chamado de produto Cartesiano e é denotado por \\(X \\cdot Y\\) e seu resultado é um novo conjunto, formado pelos pares ordenados \\((x,y): x \\in X , y \\in Y\\). Por exemplo, suponha que \\(X = \\{1,2\\}\\) e \\(Y = \\{3,4\\}\\). Então, o produto Cartesiano de \\(X\\) por \\(Y\\) é um conjunto de 4 elementos: \\(X \\cdot Y = \\{ (1,3), (1,4), (2,3), (2,4) \\}\\). Notem que temos apenas 4 elementos nesse conjunto, e cada elemento é um par ordenado de números, isto é, \\((3,1)\\) não faz parte do novo conjunto, por exemplo. O exemplo histórico de onde vem o termo é o plano cartesiano. Se eu considerar uma reta \\(X\\) e outra reta \\(Y\\) no plano cartesiano, então o produto dos dois conjuntos forma pares de coordenadas no plano, de forma que cada ponto do plano é um elemento do produto cartesiano de \\(X\\) e \\(Y\\). Voltando ao nosso exemplo das funções que retornam a distância entre cidades, o produto cartesiano dos dois conjuntos \\(A\\) e \\(B\\) é formado pelo par ordenado de cidades de SP e RJ. Assim, a minha função pode receber cada par de cidade e retornar uma distância em km, que é um número dos Reais. Retornando finalmente ao nosso exemplo das funções de payoff. Eu tenho o produto cartesiano dos conjuntos de estratégias de cada jogador. De modo que cada elemento desse conjunto é um par ordenado de cada estratégia, ou seja, todas as combinações de estratégias existentes estão nesse conjunto e cada combinação é um elemento do conjunto. E para cada jogador, eu tenho o payoff (que é um número real) resultante de cada combinação de estratégia. Vamos aplicar isso para o DP? Um conjunto finito de jogadoras \\(N = \\{1, 2\\}\\) \\(S_1 = \\{\\text{Confessa, não-confessa}\\}\\) e \\(S_2 = \\{\\text{Confessa, não_-confessa}\\}\\). Ou, mais genericamente, \\(S_i = \\{\\text{Confessa, não-confessa}\\}\\) para \\(i \\in \\{1,2\\}\\) \\(u_1: \\{\\text{(Confessa, Confessa), (Confessa, não-confessa), (não-confessa, confessa), (não-confessa, confessa)}\\} \\to R\\). Mais especificamente: \\[\\begin{equation} u_1(s_1, s_2) = \\begin{cases} -10 &amp; \\text{if }~~ Confessa,Confessa \\\\ 0 &amp; \\text{if }~~ Confessa,Não-confessa \\\\ -20 &amp; \\text{if }~~ Não-confessa,Confessa \\\\ 1&amp; \\text{Não-confessa, Não-confessa} \\end{cases} \\end{equation}\\] E para a jogadora 2, temos: \\[\\begin{equation} u_2(s_1, s_2) = \\begin{cases} -10 &amp; \\text{if }~~ Confessa,Confessa \\\\ -20 &amp; \\text{if }~~ Confessa,Não-confessa \\\\ 0 &amp; \\text{if }~~ Não-confessa,Confessa \\\\ 1&amp; \\text{Não-confessa, Não-confessa} \\end{cases} \\end{equation}\\] 5.4 Votos em comissão Consideremos o seguinte exemplo. Suponha que uma comissão, formada por três pessoas, tem de votar se implementam uma nova política ou mantém o status quo (qualquer que seja ele). Por exemplo, uma comissão de professores deve decidir se continuam com uma política de aquisição de livros para a biblioteca uma vez por ano (status quo) ou duas vezes por ano (nova política). Ou um Conselho de uma empresa deve decidir se aumentam o salário do CEO (nova política) ou não (status quo), ou um júri se condenam alguém (nova política) ou deixam a pessoa livre (status quo). Por fim, pode ser uma comissão de legisladores que devem decidir se aprovam um projeto de lei ou uma nomeação para algum cargo público. Cada membro pode votat “sim” (S) ou “não” (N). Para simplificar, consideremos que o status quo dá um payoff de 0 (zero) para cada jogadora. Jogadoras 1 e 2 preferem a nova política, portanto seus payoffs podem ser 1. Já a jogadora 3 prefere o stats quo, então consideremos o payoff dela -1 para a jogadora 3. Por fim, suponha que se houver uma maioria favorável à nova política, ela é adotada. Caso contrário, permanence o status quo. Como descrever esse jogo formalmente? Jogadores: \\(N = \\{1,2,3\\}\\) Conjuntos de estratégias: \\(S_i = \\{S, N, A\\}\\), para \\(i \\in \\{1,2,3\\}\\) Payoffs: Seja \\(P\\) o conjunto de perfis de estratégias para o qual uma nova política é escolhida e seja \\(Q\\) o conjunto de perfis de estratégias para o qual o status quo prevalece. Formalmente, \\(P = \\begin{bmatrix} (S,S,N) &amp; (S,N,S)\\\\ (S,S,S) &amp; (N, S, S) \\end{bmatrix}\\) e \\(Q = \\begin{bmatrix} (N,N,N) &amp; (N,N,S)\\\\ (N,S,N) &amp; (S, N, N) \\end{bmatrix}\\) Então os payoffs podem ser escritos como (aqui, para \\(i \\in \\{1,2\\}\\)): \\[\\begin{equation} v_i(s_1, s_2, s_3) = \\begin{cases} 1 &amp; \\text{if }~~ (s_1, s_2, s_3) \\in P \\\\ 0 &amp; \\text{if }~~ (s_1, s_2, s_3) \\in Q \\\\ \\end{cases} \\end{equation}\\] \\[\\begin{equation} v_3(s_1, s_2, s_3) = \\begin{cases} -1 &amp; \\text{if }~~ (s_1, s_2, s_3) \\in P \\\\ 0 &amp; \\text{if }~~ (s_1, s_2, s_3) \\in Q \\\\ \\end{cases} \\end{equation}\\] 5.5 Exercícios Escreva as informações que especificam um jogo na forma normal (Número de jogadores, estratégias e funções de utilidade) e a matriz de payoff dos seguintes jogos. Exercise 5.1 Considere um happy hour em que temos dois jogadores (um jogador, e todo o restante do grupo), e podem economizar ou não economizar. Atribua números fictícios de payoff para esse jogo, de forma a ilustrar o dilema da ação acoletiva. Escreva as informações que especificam o jogo na forma normal (Número de jogadores, estratégias e funções de utilidade) e a matriz de payoff. Exercise 5.2 Considere o jogo do par ou ímpar. Atribua números fictícios de payoff para esse jogo, de forma a captar as preferências de jogadores nesse jogo. Escreva as informações que especificam o jogo na forma normal (Número de jogadores, estratégias e funções de utilidade) e a matriz de payoff. Exercise 5.3 Digamos que Nina escreva um e-mail para Martín, perguntando se podem se encontrar às 14h da segunda-feira da semana seguinte, em frente ao restaurante central da Universidade onde estudam. Martín responde ao e-mail dizendo que pode sim. É conhecimento comum que ambos irão ao restaurante central na data e hora combinados? Explique. "],["solucao-de-um-jogo.html", "Capítulo6 Solucao de um jogo 6.1 Avaliando conceitos de solução 6.2 Dominância 6.3 Estratégia dominante 6.4 Equilíbrio de estratégia dominante. 6.5 Eliminação Iterativa de Estratégias Estritamente Dominadas (IESDS em inglês, EIEED em PT) 6.6 Racionalização (Rationalizability ou Racionalizabilidade) de estratégias 6.7 Jogos Tradicionais", " Capítulo6 Solucao de um jogo Conceitos de solução de um jogo Para fazer previsões sobre um jogo, precisamos fazer suposições sobre o comportamento e crenças dos jogadores. Estamos em busca do que chamamos de um conceito de solução. Essas soluções nós vamos chamar de equilíbrio. 6.1 Avaliando conceitos de solução Vamos avaliar concetios de solução a partir de três critérios básicos. 6.1.1 Existência A existência de um equilíbrio diz respeito à frequência com que ele existe em diferentes tipos de jogos. Quanto mais frequente um tipo de equilíbrio para diferentes tipos de jogos, melhor o conceito de solução. 6.1.2 Unicidade Unicidade diz respeito à quanto nosso conceito de equilíbrio retringe os comportamentos previstos. Se tudo pode acontecer, se tudo é um equilíbrio, o conceito é pouco útil. 6.1.3 Propriedades distributivas Por fim, queremos avaliar os resultados do nosso conceito de solução, em particular, suas propriedades distributivas. E um critério para isso é o “ótimo de Pareto”. Formalmente, dizemos que um perfil de estratégia \\(s \\in S\\) domina no sentido de pareto o perfil de estratégia \\(s^\\prime \\in S\\) se \\(v_i(s) &gt;= v_i(s^\\prime)\\) para todo \\(i\\) e \\(v_i(s) &gt; v_i(s^\\prime)\\) para pelo menos um \\(i\\). Nesse caso, diremos também que \\(s^\\prime \\in S\\) é dominada no sentido de pareto por \\(s\\). Por fim, dizemos que um perfil de estratégia é ótimo no sentido de Pareto se não é dominado no sentido de Pareto por nenhuma outra estratégia. Vamos agora introduzir alguns conceitos de solução informalmente e discutir em alguns jogos, para depois formalizá-los 6.2 Dominância Vamos introduzir algumas notações. Se eu tenho dois jogadores, e os dois jogadores possuem apenas duas estratégias cada (como no DP, Bach-Stravinski, Chichken e Stag Hunt), nós dedignamos o payoff do jogador \\(i\\) decorrente de um dado perfil de estratégias \\(s = (s_1, s_2)\\) de \\(v_i(s)\\). Por exemplo, se \\(s_1 = &quot;desvia&quot; e s_2 = &quot;desvia&quot;\\) no jogo do chicken, então o payoff do jogador \\(1\\), \\(v_1(s) = 0\\). Se um jogo qualquer com \\(n\\) jogadores, pode ser conveniente ordenar os perfis de estratégias associados a um dado payoff da seguinte maneira: \\(s = (s_1, s_2, ..., s_{i-1}, s_i, s_{i+1}, ..., s_n)\\) para um payoff \\(v_1(s) = 0\\). Em breve será útil se referir às estratégias de todos os jogadores que não \\(i\\). Para isso, diremos que \\(s_{-i} = (s_1, s_2, ..., s_{i-1}, s_{i+1}, ..., s_n)\\). Notem que pulamos \\(s_i\\), a estratégia do jogador i. Exercício: Se \\(s_1 \\in S_1\\), o conjunto de estratégias do jogador \\(1\\), e \\(s_2 \\in S_2\\), então escrevemos que um perfil de estratégia específico \\(s = (s_1, s_2) \\in S_1 * S_2\\), isto é pertence ao conjunto dado pelo produto cartesiano dos conjuntos \\(S_1 e S_2\\). Escreva o produto cartesiano ao qual \\((s_1, s_2, ..., s_{i-1}, s_{i+1}, ..., s_n)\\) pertence. Resposta: \\(S_1 * S_2 * ... * S_{i-1} * S_{i+1} * ... * S_n)\\) Para simplificar a notação iremos usar o seguinte atalho: Vamos definir \\(S_{-i} \\equiv S_1 * S_2 * ... * S_{i-1} * S_{i+1} * ... * S_n)\\) como o conjunto de todas as estratégias de todos os jogadores que não o jogador \\(i\\). E, finalmente, agora podemos definir \\(s_{-i} \\in S_{-i}\\) como um perfil particular de estratégias possíveis para todos os jogadores que não \\(i\\). Portanto, podemos reescrever o payoff do jogador \\(i\\) em função de um particular perfil de estrateǵia \\(s\\) como \\(v_i(s_i, s_{-i})\\), em que \\(s = (s_i, s_{-i})\\). 6.3 Estratégia dominante Dizemos que uma estrateǵia \\(s^\\prime_i \\in S_i\\) é estritamente dominada por outra estratégia \\(s_i \\in S_i\\) se \\(s^\\prime_i\\) é estritamente pior do que \\(s_i\\) não importa o que os outros jogadores façam (isto é, para quaisquer estratégias que os demais jogadores escolham). Mais formalmente, \\(s^\\prime_i \\in S_i\\) é estritamente dominada por outra estratégia \\(s_i \\in S_i\\) se para qualquer combinação de estratégias dos outros jogadores \\(s_{-i} \\in S_{-i}\\), \\(v_i(s_i, s_{-i}) &gt; v_i(s^\\prime_i, s_{-i})\\) para todo \\(s_{-i} \\in S_{-i}\\). Proposição: Um jogador racional jamais jogará um estratégia estritamente dominada. Exemplo de um jogo, 4.1. ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;format&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) Esquerda Direita Alto (2,3) (5,0) Baixo (1,0) (4,3) Do ponto de vista do jogador 1, Alto é uma estratégia dominante. Se 2 jogar esquerda, alto é a melhor resposta. E se 2 jogar direita, alto é a melhor resposta. Vejam que para o jogador 2, não há estratégia dominante. Nos termos de nossa definição Baixo é dominado por Alto e um jogador racional jamais deveria jogar Baixo. Exemplo 4.2. ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;format&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) Esquerda Centro Direita Alto (8,3) (0,4) (4,4) Médio (4,2) (1,5) (5,3) Baixo (3,7) (0,1) (2,0) Nesse exemplo, “Baixo” é dominado por “Médio”. Portanto, um jogador racional jamais deveria jogar “Baixo”. 6.4 Equilíbrio de estratégia dominante. Estratégia dominante. Definição informal: \\(s_i\\) é um estratégia estritamente dominante para \\(i\\) se todas as outras estratégias forem estritamente dominadas por ela. Mais formalmente, temos \\(v_i(s_i, s_{-i}) &gt; v_i(s^\\prime_i, s_{-i})\\) para toda \\(s^\\prime_i \\in S_i\\), \\(s^\\prime_i \\neq s_i\\) e toda \\(S_{-i} \\in S_{-i}\\). Se, como no DP, todo jogador tem uma estratégia desse tipo (isto é, uma estratégia dominante), então nossa previsão do jogo é que todos os jogadores jogarão essa estratégia dominante. Mais formalmente, dizemos que um perfil de estratégia \\(s^D \\in S\\) é um equilíbrio de estratégia dominante estrita se \\(s^D_i \\in S_i\\) é um perfril de estratégia dominante para todo \\(i \\in N\\). Portanto, temos agora uma definição formal da nossa previsão no DP. É um equilíbrio de estratégia estritamente dominante, dado por (Confessar, Confessar), e que rende o pyaoff 5 anos de prisão, 5 anos de prisão. Note que o equilíbrio é o conjunto e estratégias, e não o conjunto de payoff. É um erro comum entre estudantes (eu mesmo cometia esse erro quando estava aprendendo Teoria dos Jogos) descrever os payoffs como equilíbrio, e não as estratégias. Nosso equilíbrio sempre se refere ao que jogadores irão fazer, e não ao que irá acontecer com eles. 6.5 Eliminação Iterativa de Estratégias Estritamente Dominadas (IESDS em inglês, EIEED em PT) Racionalidade + Conhecimento comum Se um jogador racional nunca irá jogar uma estratégia estritamente dominada e isso é de conhecimento comum, então é razoável supor que todos sabem que essa estratégia nunca será jogada, e todos sabem que todos sabem e assim por diante até infinito. Podemos, portanto, eliminá-la do jogo. Consideremos o jogo do exemplo 4.2. A estratégia “Baixo” para o jogador 1 é estritamente dominada por “Médio”. Portanto, podemos eliminá-la do jogo, e ter uma nova matriz de payoff: ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;format&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) Esquerda Centro Direita Alto (8,3) (0,4) (4,4) Médio (4,2) (1,5) (5,3) Na nova matriz de payoff, “Esquerda” é estritamente dominada por “centro” para o jogador 2. Podemos, portanto, eliminar “Esquerda” do jogo, resultando na seguinte nova matriz de payoff. ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;format&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) Centro Direita Alto (0,4) (4,4) Médio (1,5) (5,3) Agora, Alto é estritamente dominada por Médio para o jogador 1. Novamente, podemos eliminar essa estratégiado jogo. ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;format&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) Centro Direita Médio (1,5) (5,3) Por fim, “Direita” é estritamente dominada por “Centro” para o jogador 2, de modo que o equilíbrio do jogo é (“Médio”, “Centro”), com payoffs (1,5). Vejam que esse equilíbrio é inferior ao par de estratégias (“Alto”, “Esquerda”). Ou seja, é um equilíbrio que é Pareto inferior. Notem que o equilíbrio depende dos seguintes passos: 1. O jogador “1” é racional e elimina a estratégia “Baixo”. No passo 2. o jogador “2” é racional e sabe que “1” é racional, portanto sabendo que “baixo” nuncaserá jogada, elimina de suas estratégias a jogada “Esquerda”. No terceiro passo, o jogador 1, racional, sabe que dois é racional e sabe que 1 é racional e, portanto, eliminou a estratégia “Esquerda”. Por isso ele pode eliminar “Alto” do jogo. No quarto passo, o jogador 2 sabe que 1 fez a primeira eliminação, que 1 sabe que 2 elimnou “Esquerda”, e 2 sabe, com isso, que 1 elimina “Alto”. Pode, portanto, eliminar “Direita”. Ou seja, aqui a iteração os jogadores sabem que eles sabem que eles sabem… não precisa ir até o infinito. Três níveis de sabe que sabe que sabe é suficiente para o equilíbri do jogo. Como vimos, para um equilíbrio de estratégia dominante, bastavamos supor racionalidade dos agentes. Contudo, para um equilíbrio de EIEED, é necessário supor também conhecimento comum da racionalidade dos jogadores. Note que o equilíbrio de EIEED (que nós não definimos formalmente) é o que resta após a eliminação sucessiva de estratégias estritamente dominadas. Quando não há mais estratégias dominadas para exluir, o que restar é a previsão do jogo. Considere o jogo Bach-Stravinski. Não há estratégias estritamente dominadas. Portanto, o equilíbrio do jogo é que quaisquer pares de estratégias são possíveis. Nesse caso, há múltiplos equilíbrios e esse conceito de solução não faz previsões útgeis para nós. 6.6 Racionalização (Rationalizability ou Racionalizabilidade) de estratégias Considere novamente o jogo do DP ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;format&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) Coopera Não coopera Coopera (2,2) (10,0) Não coopera (0,10) (5,5) Para facilitar a exposição, vou mudar os payoffs um pouco, mas o jogo ficará igual. Aqui, quanto maior o número, melhor para o jogador. Como os payoffs representam apenas preferências ordinais, não mudamos a essência do jogo. ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;format&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) Silencia Confessa Silencia (2,2) (0,3) Confessa (3,0) (1,1) O equilíbrio é que ambos os jogadores escolhem confessar. Uma forma de ver isso é dizer que, qualquer que seja a crença do jogador \\(i\\) sobre o jogador \\(j\\), \\(i \\neq j\\), confessar gera um payoff melhor do que silenciar. Como escolher o que é melhor para si é nossa definição de racionalidade, um agente racional deve escolher confessar. Em outras palavras, nossa previsão do jogo dependeu apenas da suposição de que os agentes são racionais. Considere agora uma variante do DP, como abaixo. ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;format&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) Silencia Confessa Silencia (3,2) (0,3) Confessa (2,0) (1,1) Se o jogador 1 acredita que 2 irá escolher “silenciar”, então ele deve silenciar. E se acreditar que o outro jogador irá escolher Confessar, deve escolher confessar. Portanto, ambas as estratégias sãos racionais, a depender da crença do jogador 1 sobre o que o jogador 2 irá fazer. A suposição de racionalidade não restringe a previsão do que o jogador 1 deve fazer. Para que a gente possa restringir a previsão, precisamos fazer alguma suposição adicional. Por exemplo, que 1 acredita que 2 é racional. Se 2 for racional, o que 2 deve fazer? Um agente racional escolhe o que é melhor para si. Do ponto de vista de 2, isso significa confessar, pois essa é a melhor resposta para qualquer comportamento de 1. Portanto, supor racionalidade de 2 implica acreditar que 2 escolherá confessar. Mas se 2 irá confessar, a única ação racional para 1 é confessar. Em resumo até agora: Na variante do DP apresentada, apenas supor racionalidade de 1 não restringe suas ações, mas restringe a de 2. Adicionar a suposição de que 2 sabe ou acredita que 1 é racional é suficiente para restringir a ação de 1 e gerar uma única previsão para o jogo. Agora, considerem uma nova variante do DP: ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;format&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) S C S (4,2) (0,3) X (1,1) (1,0) C (3,0) (2,2) Eu adicionei uma nova ação para o jogador 1, que chamei de “X”. O ponto é que, embora a história perca seu sentido com uma nova ação “X”, para o restante das ações ainda guardar alguma similaridade com o original. Se preferirem, podem imaginar que é um outro jogo, não relacionado com o DP. Para o jogador 1, escolher “S” é racional, se ele acreditar que o outro jogador irá escolher “S”. Igualmente, “C” também é racional se o outro jogador escolher “C”. Porém, “X” não é racional. Para 2, S e C também são racionais, dado que ela acredite que 1 escolher S ou C e X, respectivamente. Portanto, se o jogador 1 assumir que 2 é racional, isso não ajuda 2 a decidire entre S ou C, já que ambas são consistentes com sua racionalidade e a do outro jogador. Diferentemente do jogo anterior, a suposição de ambos sã oracionais e que 1 sabe que 2 é racional não geou uma previsão única para o jogo. O que acontece se adicionarmos um passo na cadeia de raciocínio e 1 supor que não apenas 2 é racional, mas que 2 acredita que 1 é racional. Então, dois acredita que 1 jamais jogará “X”, e portanto não achará mais jogar “S” uma boa estratégia e jogará apenas “C”. Mas, se 1 sabe disso, então deverá escolher “C” como sua resposta. Logo, ambos estão escolhendo C, C. Em resumo, C,C é o equilíbrio do jogo desde que assumamos que: 1. é racional, 2 é racional, 1 sabe que 2 é racional, 2 sabe que 1 é racional e 1 sabe que 2 sabe que 1 é racional. Nos três jogos (DP, primeira variante e segunda variante), mostramos como, crescendo a suposição de racionalidade dos jogadores uns dos outros, restaram ações consistentes com essa suposições era C,C. É possível mostrar que isso é verdadeiro supondo maiores níveis de racionalidade (mais passos). Mais ainda, posso estender os passos indefinidamente. E nós dizemos que estratégias que possuem essa propriedade são racionalizáveis. 6.7 Jogos Tradicionais 6.7.1 Bach e Stravinski ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;format&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) Bach Stravinski Bach (2,1) (0,0) Stravinski (0,0) (1,2) 6.7.1.1 Histórico machista - guerra dos sexos Diferentemente do DP, a melhor resposta depende do que o outro jogador irá fazer. Assim, para fazer uma previsão, precisamos fazer suposições comportamentais e sobre as crenças a respeito do outro jogador para definir um ou mais equilíbrios para o jogo. Nosso conceito de solução para o jogo será o equilíbrio do jogo. Uma das características dos equilíbrios que iremos abordar durante o curso é que ele seja do tipo que se auto-reforça, isto é, agentes que estão jogando estratégias de equilíbrio não possuem incentivos para mudar suas estratégias, ao contrário, o fato de outros estarem jogando as estratégias de equilíbrio devem reforçar o incentivo para qume um jogador permaneça no equilíbrio. 6.7.2 Stag Hunt Na teoria dos jogos, o jogo caça ao cervo (stag hunt, em inglês), às vezes é referido como jogo da garantia, dilema da confiança ou jogo do interesse comum e descreve um conflito entre segurança e cooperação social. O jogo surge do trabalho do Rousseau no segunod discurso (sobre a desigualdade) ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;format&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) Cervo Lebre Cervo (3,3) (0,2) Lebre (2,0) (1,1) 6.7.3 Jogo da Coordenação ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;format&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) Bach Stravinski Bach (1,1) (0,2) Stravinski (2,0) (0,0) 6.7.4 chicken - jogo anti-coordenação ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;format&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) Desvia não desvia Desvia (0,0) (-1,3) não desvia (3,-1) (-10,-10) "],["equilíbrio-de-nash.html", "Capítulo7 Equilíbrio de Nash 7.1 P-beauty contest 7.2 Melhor resposta 7.3 Equilíbrio de Nash 7.4 Aplicação - Plano cruzado 7.5 Aplicação - Chile 7.6 Aplicação - Competição eleitoral sem incerteza 7.7 Generalizando o modelo de Hotteling 7.8 Competição eleitoral em espaços multidimensionais 7.9 O modelo de Wittman 7.10 Competição multipartidária 7.11 Aplicação - Modelo sobre guerra 7.12 Exercícios", " Capítulo7 Equilíbrio de Nash Para introduzir o conceito mais importante da teoria dos jogos não-cooperativa, vamos começar por um jogo chamado de “p-beauty contest”. 7.1 P-beauty contest Escolha um número inteiro, entre 0 e 100. Vence o desafio quem acertar a metade da média dos números escolhidos por todos os jogadores. Em outras palavras, vou anotar os números de cada um, computar a média e depois dividir a média por 2. Portanto, vocês devem advinhar não a média dos números, mas a média dividida por 2. 7.2 Melhor resposta A ideia de melhor resposta é um conceito central para a teoria dos jogos, de modo que vale a pena defini-lo formalmente. Definição 4.1: Melhor resposta: A estratégia \\(s_i \\in Si\\) é a melhor resposta do jogador \\(i\\) às estratégias de seus oponentes \\(s_{-i} \\in S_{-i}\\) se \\(v_i(s_i, s_{-i}) &gt;= v_i(s^\\prime_i, s_{-i})\\) para todo \\(s^\\prime_i \\in S_i\\) Em palavras: a utilidade (ou payoff) do jogador \\(i\\) resultante da sua estratégia e das estratégias dos oponentes é pelo menos tão boa quanto qualquer outra estratégia que \\(i\\) possa vir a adotar. Considere o jogo da bandeira (cujo nome original é o Nim game), do reality show Survivor. Se é sua vez de jogar e existem, por exemplo, 20 bandeiras, não importa o que você faça, irá perder o jogo se o outro time for racional. Portanto, sua melhor estratégia pode ser tanto 1, 2 ou 3 bandeiras. Esse exemplo mostra que a melhor estratégia pode 1: incluir múltiplas ações; 2. serem igualmente ruins e não fazer diferença nenhuma e resultar todas no mesmo payoff. 7.3 Equilíbrio de Nash Um perfil de estratégias é um equilíbrio de Nash se cada jogador está escolhendo a melhor resposta para o que acredita que os demais jogadores farão. Ou seja, todo mundo está simultaneamente escolhendo a melhor resposta uns para os outros. O equilíbrio de dominância estrita requer apenas racionalidade, enquanto o equilíbrio de EIEED requeria racionalidade e conhecimento comum de crenças (e racionalidade). Agora, iremos fazer uma suposição mais forte ainda, de que as crenças, em certo sentido, estejam corretas. Isso dará origem ao equilíbrio de Nash, formulado pela primeir vez por John Nash em 1950. Definição 5.1. O perfil de estratégias puras \\(s^\\star = (s^\\star_1, s^\\star_2, ..., s^\\star_n) \\in S\\) é um equilíbrio de Nash se \\(s^\\star_i\\) é uma melhor resposta a \\(s^\\star_{-i}\\) para todo \\(i \\in N\\). Ou seja, \\(v_i(s^\\star_i, s^\\star_{-i}) &gt;= v_i(s^\\prime_i, s^\\star_{-i})\\), para toda \\(s^\\prime_i \\in S_i\\) e todo \\(i \\in N\\). Considere o jogo abaixo. O único equilibrio de EIEED é (Alto, Esquerda). Esse também é um equilíbrio de Nash, pois Alto é a melhor resposta a L, e L é a melhor resposta para Alto. ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;format&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) Esquerda Centro Direita Alto (4,3) (5,1) (6,2) Médio (2,1) (8,4) (3,6) Baixo (3,0) (9,6) (2,8) Considerem o Dilema do Prisioneiro. É fácil ver também que (C,C) é também um equilíbrio de Nash. Não é coincidência que Dominância estrita, EIEED e racionazabilidade sempre sejam equilíbrios de Nash. Se um equilíbrio é de dominância estrita, ou o único sobrevivente de EIEED ou de racionazabilidade, então é o único equilíbrio de Nash. Considere o seguinte jogo. Duas jogadoras devem escolher um número inteiro entre 1 e 9. Se a soma dos números for menor ou igual a dez, elas ganham o valor em reais que cada jogadora escolheu. Se a soma for maior que dez, não ganham nada. Esse jogo é dado por \\(G = [N = 1,2; S_i = (1, 2, ..., 9), v_i(s_1, s_2) = s_i, se s_1 + s_2 &lt;= 10\\) \\(0\\), c.c.]$ Quaaisquer pares \\((1,9);(9,1)\\), \\((2,8), (8,2)\\) etc. formam equilíbrios de Nash. Em particular, uma vez revelados, nenhum jogador possui qualquer incentivo unilateral a mudar sua estratégia. Vamos enfatizar a palavra unilateral aqui. Vamos mudar o jogo anterior para o seguinte. Em vez das jogadoras ganharem os números ecolhidos cuja soma for 10, elas (cada uma) ganham a soma dos quadrados dos números escolhidos. Assim, (1,9) e (9,1) geram \\(1^2 + 9^2 = 1 + 81 = 82\\) reais, enquanto \\(2^2 + 8^2 = 4 + 64 = 68\\) e \\(5^2 + 5^2 = 50\\), de forma que o melhor resultado para as jogadoras é (9,1) ou (1,9). Porém, se jogarem (2,8), nenhuma delas possui incentivo unilateral para mudar sua estratégia, pois elas constituem melhores respostas às estratégias umas das outras. Uma das lições que precisamos tirar de modelos de teoria dos jogos é que não basta boa vontade ou objetivos comuns para uma ação coletiva. É preciso que os equilíbrios sejam tal que nenhum ator tenha um incentivo unilateral para mudar sua estratégia. Em certo sentido, os equilíbrios de Nash são sustentáveis, no sentido de que não há incentivo para desviar, uma vez estando em um deles. 7.4 Aplicação - Plano cruzado Na década de 80, o Brasil enfrentou um grave problema de hiperinflação, levando o país a adotar o Plano Cruzado durante a presidência de Sarney para combater a inflação. O plano incluía várias medidas, sendo o congelamento de preços como a principal delas, o que impedia que os preços umentassem sem autorização governamental. Apesar do sucesso inicial em reduzir a inflação, o plano eventualmente fracassou, e os preços voltaram a subir. Uma parte do diagnóstico do Plano Cruzado é que existia uma inércia inflacionária, baseada meramente na expectativa de que haverá inflação. Ou seja, se um agente espera que haja inflação, ele reajusta os preços. Se todos fizerem isso, a inflação acontece e se repete mês a mês. Essa situação pode ser modelada como um jogo de coordenação, em que queremos transitar de um equilíbrio ruim (todos reajustam os preços) para um equilíbiro bom (ninguém reajusta os preços). A ideia do congelamento de preços é justamente mover a economia entre equilíbrios, algo que o mercado não conseguiria fazer soznho, sem intervenção governamental. Para simplificar, suponhamos que temos apenas duas empresas que podem decidir reajustar os preços ou não. Se ambas não reajustam, não há inflação. Se só uma reajustar, ela perde mercado para a outra empresa. Se ambas reajustarem, há inflação. # Define Variables M=2 R=3 P=1 S=0 # Assign Pairs pair &lt;- function(x,y) sprintf(&quot;(%d,%d)&quot;, x,y) all_pairs &lt;- c(pair(M,M), pair(S,R), pair(R,S), pair(P,P)) payoff.mat &lt;- matrix(all_pairs, nrow=2) dimnames(payoff.mat) &lt;- c(rep(list(c(&quot;Não-reajusta&quot;,&quot;reajusta&quot;)), 2)) results = &quot;asis&quot; # Plot kable(payoff.mat) ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;format&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) Não-reajusta reajusta Não-reajusta (2,2) (3,0) reajusta (0,3) (1,1) 7.5 Aplicação - Chile Vamos começar modelando um exemplo “simples”, adaptado do livro de Niou e Ordershook “Strategy and Politics. An introduction to Game Theory”. Em 1964, no Chile, Salvador Allende era o candidato da esquerda. Liberais e Conservadores acetaram apoiar o candidato do centro Eduardo Frei, que ganhou a eleição com 56,1% dos votos contra 38,9% de Allende. Em 1970, Allende ganhou a eleição com menos votos do que havia recebido em 64, 36,2%, enquanto o centrista Randomiro Tomic ganhou 27,8% e direitsta Jorge Allesandri 34,9% dos votos. Especula-se que, se um dos candidatos desistisse da eleição, Allende não teria conquistado o poder. Vamos então fazer um modelo simples para ilustrar a questão. Suponha um eleitorado com três tipos de ordenamento de preferências de candidatas \\(A\\), \\(B\\) e \\(C\\). 1. \\(A \\succ B \\succ C\\) 2. \\(B \\succ C \\succ A\\) 3. \\(C \\succ B \\succ A\\) Vamos supor adicionalmente que 40% do eleitoradotem preferências do tipo 1 o restante igualmente dividido entre o tipo 2 e 3 (30% cada). Se cada eleitor votar sinceramente (isto é, para sua candidata preferida), \\(A\\) teria 40% dos votos, \\(B\\) 30% e \\(C\\) 30%. Se a regra for como no Brasil 1945-64, em que não havia segundo turno e a candidata mais votada vence, \\(A\\) seria eleita. Se porém parearmos \\(A\\) contra \\(B\\), a vencedora seria \\(B\\) com 60% dos votos, e \\(B\\) contra \\(C\\) também daria a vitória para \\(B\\), com \\(70\\%\\) dos votos. Em casos como esse, em que há uma vencedora que ganha todas as disputas 2x2, chamamos de vencedora de Condorcet (Condorcet winner). \\(B\\) e \\(C\\), portanto, poderiam ser estratégicas e votarem não na candidata preferida para obter um resultado mais favorável. O problema que \\(B\\) e \\(C\\) enfrentam pode, portanto, ser modelado do seguinte modo. ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;format&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) Votar em B Votar em C Votar em B B ganha A ganha Votar em C A ganha C ganha Esse jogo é muito parecido com o jogo de coordenação Bach-Stravinsky. Nele, há dois equilíbrios de Nash, B ganha e C ganha. Porém, a escolha de qual equilíbrio acontecerá requer coordenação entre eleitores do tipo 2 e 3. Se falharem em coordenar os votos, contudo, A ganhará. Se B ou C desistir de disputar a eleição, a coordenação estará garantida, como ocorreu no Chile em 1964. Na ausência de tal coalizão, eleitores terão muita dificuldade de coordenar seu voto. Do ponto de vista da Ciência Política, é importante enfatizar alguns pontos dessa discussão: É muito mais fácil para as elites polítics coordenarem entre si do que entre os eleitores, que não possuem uma forma fácil de comunicação e são em número muiro maior. Informações sobre candidatas com maiores intenções de voto em simulações de segundo turno permite os eleitores a tomarem decisões melhores e coordenarem seus votos. Portanto, quando vocês virem pessoas reclamando de pesquisas de intenção de voto, que isso influencia o eleitor e faz com que ele vote estrategicamente, pergunte-se: é realmente ruim que o eleitorado vote estrategicamente? Voltaremos a essa discussão em aulas futuras. Na presença de segundo turno, existe necessidade de haver coordenação antecipada? Não para evitar que A seja eleito. B ou C irá para o segundo turno contra A. 7.6 Aplicação - Competição eleitoral sem incerteza Quando as pessoas pensam em eleições, muitos acreditam que políticos anunciam as plataformas que acreditam, e eleitores escolhem a que preferem. Contudo, na ciência política é comum assumir que, mesmo que políticos se preocupem que suas plataformas sejam implementadas, sabem que para isso primeiro precisam ganhar eleições. Portanto, seja porque estão preocupados apenas com o poder ou porque precisam estar preocupados com o poder para implementar plataformas, o fato é que uma supoição comum é assumir que políticos maximizam suas chances de serem eleitos. Essa é a base do modelo discutido por Hotelling (1929). Após contribuições de Duncan Black (Black, 1948) e Anthony Downs (Downs, 1957), a ideia entrou definitvamente na Ciência Política e ficou conhecida como Teorema do Eleitor Mediano. O modelo do Hotelling tem inspiração em um modelo de competição espacial entre firmas. Ele desenvolve um jogo em dois estágios, em que duas firmas, competindo em uma rua, devem escolher sua localização geográfica no primeiro estágio, e em seguida os consumidores escolhem onde vão comprar os produtos, levando em consideração não apenas o preço dos produtos, mas o custo do transporte. E ele acha um equilíbrio de Nash (sem usar esse termo, obviamente) em que as empresas tendem a se concentrar no meio da rua. E ele notou que essa ideia poderia ser aplicada par competição política entre partidos. Nós apresentaremos aqui uma versão simplificada da ideia do Hotelling e do Teorema do Eleitor Mediano. O cenário que está sendo modelado é, claramente, o da competição política dos EUA. Suponha, portanto, dois partidos, que se importam apenas em ganhar a eleição. Existem 101 eleitores, com preferências uniformimente distribuídas em uma única dimensão do espectro político-ideológico (esquerda-direita). Em particular, suponha que o eleitor mais a esquerda está na posição -50, em seguida -49 e assim por diante, cada um com um número inteiro, até a extrema-direita, +50. Cada partido \\(i\\) escolhe uma plataforma \\(x_i\\) no espectro político-ideológico \\([-50, -49, ..., +49, +50]\\). Cada eleitor escolhe a plataforma mais próxima da sua posição ideal. Por exemplo, se o partido \\(A\\) anuncia -9 como plataforma e o partido \\(B\\) anuncia 12, o eleitor mais perto de -9 do que de 12 vota por \\(A\\), enquanto quem estiver mais perto de 12 vota por \\(B\\). Figura 7.1 - O modelo de voto do Hotteling 7.6.1 determinar os eleitores pivot do exemplo. É eleito quem obtiver mais voto. Como há um número ímpar de eleitores, a menos que alguém seja indiferente, não há empate. Se alguém for indiferente, o eleitor não vai votar e há um empate. Para escrever a função de melhor resposta de cada jogador, considere o seguinte. Vamos começar olhando para o partido \\(A\\). Se \\(B\\) anunciar uma plataforma \\(x_B &gt; 0\\), então escolher a mesma posição \\(x_A = x_B\\) ou a exata oposta \\(x_A = -X_b\\) haverá um empate. Se escolher \\(x_A &gt; x_B\\) ou \\(x_A &lt; -x_B\\), perde. O único caso em que ganha é se escolher \\(x_A = \\left[ -x_B + 1, x_B - 1 \\right]\\). De modo análogo, se \\(x_B &lt; 0\\), \\(x_A = -X_b\\) levará ao empagte, \\(x_A &gt; -x_B\\) ou \\(x_A &lt; x_B\\), perderá, e \\(\\left[ x_B + 1, -x_B - 1 \\right]\\) leva à vitória. Como ganhar é melhor que perder e empatar, temos a melhor resposta no cenário em que \\(x_B &gt; 0\\) e que \\(x_B &lt; 0\\). Se \\(x_B = 0\\), a melhor resposta é também jogar zero, isto é, \\(x_A = x_B = 0\\), já que qualquer outra posição levará à derrota de \\(A\\). Podemos então construir a correspondência de melhor resposta:para \\(A\\) \\[ x_A = \\begin{cases} \\left[ -x_B + 1, x_B - 1 \\right] &amp; \\text{se } x_B &gt; 0, \\\\ 0 &amp; \\text{se } x_B = 0, \\\\ \\left[ x_B + 1, -x_B - 1 \\right] &amp; \\text{se } x_B &lt; 0. \\\\ \\end{cases} \\] Como é tudo simétrico, as melhores respostas de cada jogador são similares. Existe um único equilíbrio de Nash, em que ambos candidatos jogam (0,0), que é o centro do espectro político. É fácil verificar que é um equilíbrio de Nash, já que ambos estão jogando uma melhor resposta à estratégia do outro partido, como pode ser verificado pela função de melhor resposta. Essa é a base para o teorema do eleitor mediano, presente já no trabalho do Hotelling. 7.7 Generalizando o modelo de Hotteling Normalmente, o modelo de Hotteling é apresentado com funções de utilidade contínuas2. Assim, a utilidade pode ser descrita como \\(u_ i(x) = |x - x_i|\\). Às vezes, em vez de usar a distância euclidiana, utilizamos funções quadráticas: \\(u_ i(x) = (x - x_i)^2\\). E vamos supor um contínuo de eleitores, cada um com um ponto ideal \\(x_i\\) único, estritamente crescente em algum intervalo (digamos, \\(0-1\\)), de tal modo que há um único ponto ideal mediano, \\(x_m\\). Eleitores continuam votando sinceramente e se houver empate na distância, eleitores se abstém. Sejam \\(x_a\\) e \\(x_b\\) a plataforma anunciada por A e B, respecitivamente. Seja \\(\\pi_A(x_a, x_b)\\) a probabilidade que o partido A ganhe a eleição. Então, essa probabilidade é \\(1\\) se a fração de eleitores que preferem estritamente \\(x_a\\) a \\(x_b\\) é maior que meio, \\(0\\) se a fração de eleitores que preferem estritamente \\(x_a\\) a \\(x_b\\) é menor que meio, e \\(1/2\\) caso contrário (isto é, em caso de empate). Para achar o equilíbrio de Nash, derivamos a melhor resposta de A e B. Comecemos por B, dado que A anuniciou \\(x_a\\). Se \\(x_a &lt; x_m\\), então B ganha com certeza adotando qualquer posição mais próxima do eleitor mediano que A. Por outro lado, se \\(x_b = x_a\\) ou \\(x_b = x_m + (x_m - x_a)\\), então há empate e a probabilidade é \\(1/2\\) e se \\(x_b &lt; x_a\\) ou \\(x_b &gt; x_m + (x_m - x_a)\\) B perde com certeza. Lógica similar se aplica a \\(x_a &gt; x_m\\). Portanto, quando \\(x_a \\neq x_m\\), qualquer \\(x_b\\) mais próximos de \\(x_m\\) gera vitória com certeza. Por fim, quando \\(x_a = x_m\\), a única melhor resposta é \\(x_b = x_a = x_m\\), já que de outro modo perderá com certeza. Raciocínio similar se aplica para derivarmos a melhor resposta de \\(A\\), de modo que as melhores respostas simultâneas são justamente \\(x_a = x_b\\). O equilíbrio de Nash, portanto, é dado por \\(x_a^{\\star} = x_b^{\\star} = x_m\\). 7.8 Competição eleitoral em espaços multidimensionais O nosso modelo de competição política assumiu um espaço político unidimensional – por exemplo esquerda-direita. Mas às vezes o espaço político possui mais de uma dimensão, de modo que vale investigar como espaços multidimensionais impactam nossos resultados. Vamos considerar um espaço multidimensional em que três partes (1, 2 e 3) devem decidir como alocar um orçamento de tamanho \\(1\\). Esse jogo é às vezes chamado de jogo de dividir a torta ou bolo. Seja \\(q_1\\) a parcela do bolo que fica com a jogadora \\(1\\), \\(q_2\\) para \\(2\\) e \\(1- q_1 - q_2\\) a parcela para \\(3\\). As jogadoras preferem mais bolo a menos. Então, não há vencedor de Condorcet aqui. Para ver isso, assuma que existe um vencedor de Condorcet \\((q_1, q_2)\\). Como a distribuição soma \\(1\\), alguém está recebendo uma quantidade positiva. Portanto, uma coalizão alternativa pode ser construída, divididndo essa quantidade entre as duas outras jogadoras, o que atrairá o voto dessas duas jogadoras. Portanto, não existe vencedor de Condorcet. Podemos aplicar uma lógica similar a uma competição de três partidos, \\(1, 2, 3\\). 7.9 O modelo de Wittman Wittman (1973)3 foi o primeiro a formular um modelo de políticos ou partidos policy-seeking em vez office-seeking. Suponha que temos dois partidos \\(E\\) e \\(D\\) com pontos ideais \\(0\\) e \\(1\\), e funcções utilidades dadas por \\(-|x|\\) para \\(E\\) e \\(-|x-1|\\) para \\(D\\) se a política \\(x\\) for implementada. Suponha ademais que o eleito mediano \\(x_m\\) está entre os ponos ideais dos dois partidos. Os partidos \\(E\\) e \\(D\\) maximizam a utilidade esperada escolhendo uma plataforma \\(x_E\\) e \\(x_D\\), respectivamente. Seja \\(\\pi(x_E, x_D)\\) a probailidade do partido \\(E\\) ganhar a eleição. A função que \\(E\\) maximiza é: \\[\\max_{x_E} \\pi(x_E, x_D)(-|x_L|) + (1 - \\pi(x_E, x_D))(-|x_D|)\\] Já \\(D\\) maximiza: \\[\\max_{x_D} \\pi(x_E, x_D)(-|x_D-1|) + (1-\\pi(x_E, x_D))(-|x_E-1|)\\] É fácil ver que existe um Equilíbrio de Nash no qual ambos partidos anunciam \\(x_m\\) e ganham com probabilidade \\(1/2\\). Para ver que é um EN, notem que se um deles desviar, perde a eleição com certeza e a política implementada é a mesma. Então, não há ganho e a utilidade é a mesma de antes (o EN não é estrito). E esse é o único EN. A prova é um pouco mais complicada, mas similar ao que fizemos antes. Antes é só necessário eliminar estratégias dominadas (anunciar plataforma fora do espectro \\(0-1\\) e que \\(x_E &lt; X_m &lt; x_D\\)) e que \\(|x_E - x_m| = |x_m - x_D|\\). 7.10 Competição multipartidária Até aqui analisamos apenas competição bipartidária. Consideremos um modelo com três partidos A, B e C, que novamente maximizam probabilidade de vitória. A outra mudança é que se eleitores são indiferentes entre dois partidos, votam por um deles com probabilidade \\(1/2\\) em vez de se absterem. Mantento a eleição de um turno em que vence o partido com mais votos (maioria simples, em vez de absoluta), o que acontece? Primeiro, vejamos que não é um equilíbrio de Nash todos os partidos anunciarem o ponto mediano. Um deles teria incentivo para desviar unilateralmente, anunciando uma plataforma aribtrariamente próxima de \\(x_m\\), ganhando quase metade dos votos e deixando os demais dividindo a outra metade e ganhando a eleição. Existe EN? Depende da distribuição de preferência dos eleitores. Assuma que eleitores tenham funções de utilidade euclidianas e distribuidas uniformemente no \\([0-1]\\). Portanto, as seguintes plataformas constituem um EN: \\(x_A = x_B = \\frac{1}{3}\\), e \\(x_c = 2/3\\) e C ganha, pois recebe metade dos votos e A e B dividem a outra metade. Nenhum partido tem incentivo para desviar, pois não conseguem melhorar com qualquer outra estratégia. Obviamente, podemos trocar os rótulos e teremos igualmente equilíbrios de Nash, ou seja, \\(X_A = X_C\\) e B ganha, ou \\(X_B = X_C\\) e A ganha. Portanto, temos três equilíbrios de Nash, e similares entre si. A disputa entre os partidos é para quem ver quem ocupa a posição \\(2/3\\), enquanto os outro dois precisam disputar votos do mesmo espectro político entre si. Outro problema do modelo é: se \\(A\\) e \\(B\\) (por exemplo) sabem que vão perder, porque entram na disputa em primeiro lugar? E aí precisamos modelar os benefícios de disputar uma eleição em que vocÊ sabe que vai perder, para tentar ganhar no futuro e aí precisamos modelar a entrada e saída endógena de partidos em eleições. Por fim, vale notar que o equilíbrio só existe se partidosmaximizam a chance de vitória, não o número de votos ou o percentual de votos. Se maximizassem o percentual de votos, C poderia ganhar mais votos mudando sua posição em direção a \\(1/3\\). Só que aí não haveria mais equilíbrio de Nash no jogo. Se tivermos quatro partidos, então, com as suposições do jogo anterior, temos o seguinte equilíbrio de Nash: \\(x_A = x_B = \\frac{1}{4}\\) e \\(x_C = x_D = \\frac{3}{4}\\). 7.11 Aplicação - Modelo sobre guerra Nós agora estamos preparados para entender como a literatura tem utilizado teoria dos jogos para modelar e discutir fenômenos relevantes. Aqui iremos retomar aplicações que discutem a ocorrência de guerras. Fearon introduziu a questão de como a escolha racional coloca problemas para explicações tradicionais (realistas, por exemplo) para a guerra. Guerras, como a da Rússia e Ucrância, são custosas. Qualquer que sejao resultado final da guerra, em tese uma negociação que resultasse no mesmo resultsado final, sem a guerra, seria preferia por ambos os estados (pareto superior) e portanto a guerra deveria ser evitada sempre. Como explicar que guerras ocorram? Fearon aponta três explicações mais gerais: 1. Pessoas (e líderes políticos em particular) podem ser irracionais ou sofrer de vieses, que os levam a subestimar o custo da guerra ou a entender como suas ações podem provocar uma guerra. Líderes se beneficiam da guerra, mas não pagam seus custos (soldados é que lutam as guerras) e, portanto, o cálculo racional de custos não seriarelevante. Agentes racionais por alguma razão acabam guerreando. A primeira e segundas explicações, embora plausíveis, corrm risco muito grande de serem bobas. Dizer que Putin é malvado e tem mania de grandeza e por isso fez a guerra independente de qualquer cálculo racional pode servir a uma visão ideológica, mas é muito fácil. Se a pessoa faz guerra porque é burra ou má, não temos muita ciências sociais para fazer. É mais uma questão da psicologia ou psiquiatria. Portanto, mais relevante para nós são explicações racionalistas. Vejam que explicações de corte neorealistas, que enfatizam variáveis no sistema internacional são justamente do tipo que estamos interessados. Atores racionais farão guerra se o sistema internacional produzir situações que levam à guerra. Fearon irá então dizer o seguinte: Não é suficiente dizer que, sob anarquia, nada impede um estado de usar a força, ou que estados devem contar apenas com a auto-ajuda em um sistema anárquico, o que gera suspeita mútua e por fim, conflito (por espiral de suspeita ou dilema da segurança). E o ponto dele é o que falei no começo. Guerra é custosa. Isso significa que, em princípio, estados poderiam chegar a um acordo que seria pareto superior e evitasse a guerra. É um pouco como o gatoro que sofre bullyng na escola, mas os valentões nunca precisam de fato bater no garoto, porque este antecipa a derrota e já entrega o lanche que os valentões pedem. Um conflito destruiria parte do valor do lanche (no mínimo ficaria mais frio etc.) e o resultado final seria o mesmo, situação pareto inferior. Anarquia não implica na guerra porque estados poderiam chegar a um acordo preferível á guerra, mesmo sob anarquia. Digamos, A toma 10% do território de B. Se esse é o resultado da guerra, melhor chegar a ele sem guerra. Similarmente, o dilema da segurança (um estado se tornar mais seguro torna outro relativamente menos seguro) não impede de um acordo ser feito que previna a guerra. Fearondirá que é preciso argumentos mais elaborados. Considere por exemplo a explicação típica de espiral. Um estado A se arma, tornando outro, B, relativamente mais inseguro. No limite, B decide fazer uma guerra preventiva. Se A sabe que é isso que irá acontecer e antecipa, então …. Se A falha em antecipar e não queria a guerra, então o problema é mais de cálculo errado do que de anarquia. E aí é preciso mostrar que uma negociação não poderia resolver o problema do erro de cálculo. Se uma potência declinante pensa em fazer uma guerra preventiva contra uma potência ascendente, então poderia fazer uma barganha envolvendo concessões no presente e no futuro, para evitar a guerra, que seria preferível por ambos os estados. Mais ainda, a potência delclinante, sabendo que barganhas no futuro são preferíveis à guerra, não teriam razão para ter medo de serem atacados no futuro. Outro tipo de explicação é sobre utilidade esperada da guerra diferente entre estados. Bruce Bueno de Mesquista argumentou, de maneira influente, que a guerra aconteceria quando ambos os estados esperam uma utilidade esperada do conflito (isto é, benefícios esperados maiores que os custos esperados) maior do que a da paz. Porém, por que não exisitiria um acordo a ser negociado que geraria maiores benefícios, ao evitar a guerra? Fearon irá então modelar o jogo entre dois estados, para formalizar essas intuições e argumentos. Dois estados, A e B, que têm preferências sobre um objeto (como um território), representado por \\(X = [0,1]\\). Estado A prefere soluções o mais próximas de 1 possível, enquanto B é o oposto (mais perto de zero). Podemos pensar que é a divisão de um território entre as partes, e pode ir de 0% a 100%, representando o percentual do território controlado por A. Se o resultado da disputa for \\(x \\in X\\), então estados têm utilidade \\(u_a(x)\\) e \\(u_b(1-x)\\). Funções de utilidade são de VNM, com aversão a risco ou neutralidade ao risco. E vamos definir que \\(u_i(1) = 1\\) e \\(u_i(0) = 0\\), \\(i \\in {A,B}\\). Dizer que o conjunto \\(X\\) contém acordos negociados preferíveis á guerra implica que podemos dizer como os estados avaliam conflito armado a opções negociadas. Se ocorre uma guerra, \\(A\\) vence com probabilidade \\(p\\) e perde com probabilidade \\(1-p\\). Quem vencer escolher o máximo do território. A utilidade esperada de A é: \\(p*u_a(1) + (1-p)*u_a(0) - c_a= p - c_a\\), em que \\(c_a\\) é o valor perdido (em utilidade) da guerra para A. Digamos, destruição econômica mais perdas de vidas humanas e perdas de equipamento militares. Similarmente para B: \\((1-p)*u_b(1) + p*u_b(0) - c_b= 1- p - c_b\\), Suponha que a função utilidade é \\(u(x) = x\\), que representa uma função de utilidade de neutralidade ao risco. Então, se existir algum \\(x^*\\), tal que, \\(u_a(x^*) &gt; p - c_a\\) e \\(u_b(x^*) &gt; 1 - p - c_b\\), então \\(x^*\\) é preferido por ambos os estados. Se existir mais de um ponto, ou mesmo um intervalo, então esse intervalo é preferível a guerra. Resolvendo o sistema de equações de desigualdade, temos que \\(x^* &gt; p - c_a\\) e \\(1 -x^* &gt; 1 - p - c_b\\) Suponha que \\(x^* = p - c_a - 0.1\\). A primeira equação é satisfeita trivialmente, e a segunda também é satisfeita, como é fácil ver, pois \\(1 -( p - c_a - 0.1) = 1 -p + c_a + 0.1 &gt; 1 - p - c_b\\) , pois 1 cancela, p cancela, ficando \\(c_a + 0.1 &gt; -c_b\\). Como \\(c_a\\) é positivo e \\(c_b\\) é positivo, o lado esquerdo da equação é maior que o lado direito. Do mesmo modo, o ponto \\(p + c_b - .01\\) também satisfaz as duas equações. Portanto, no intervalo \\([p - c_a - 0.1, p + c_b - .01]\\), ambos os estados estão melhores do que com a guerra. De maneira geral, no intervalo aberto, posso tirar o \\(.01\\) e ficar com: \\((p - c_a, p + c_b)\\). Para dar concretude. Se A ucrância e B Rússia. Digamos que \\(p\\), a probabilidade da Ucrância prevalecer fosse 10% antes da guerra começar, \\(c_a = 2%\\) e \\(c_b = .05%\\). Então, \\((.05 - .02, .05 + .005) = (3%, .5,5%)\\). Ou seja, a Ucrânia poderia ficar com 3% do seu território + epsiolon para evitar a guerra, e a Rússia aceitaria no máximo que a Ucrância ficasse com 5,5% do território. A intuição é que a utilidade esperada da Guerra pra Ucrância é uma utilidade equivalente a 3% do território (5% do território menos 2% de destruição da guerra). Ela não poderia dar mais de 5,5% do território, pois preferiria a guerra. Quais suposições substantivas foram feitas: 1. existe uma probabilidade \\(p\\), objetiva, que cada estado irá ganhar a guerra. Ainda que ambos os estados tenham estimativas diferentes e conflitivas e haja incerteza sobre seu valor, existe uma probabilidade real, que eles não sabem. E essa probabilidade dá ensejo ao intervalo de negociação e eles sabem disso (se são racionais). Portanto, a princípio uma solução negociada ainda poderia ser tentada. Assumimos que estados são neutros ao risco ou avessos ao risco. Parece plausível, já que um acordo certo seria preferível a uma aposta de tudo ou nada com o mesmo valor esperado. Por fim, assumimos que há uma continuidade de acordos possíveis. Ou seja, o objeto é perfeitamente divisível. Há casos em que isso não é divisível, como por exemplo quando é quem é o líder que ficará no governo. Só pode ser uma pessoa. Nesse caso, indivisibilidade poderia trnar o intervalo de negociação vazio. Porém, pagamentos laterais e issue-linkage podem tornar o objeto divisível. então teria de ser mostrado porque isso não foi possível. Fearon irá sugerir que o que pode explicar a guerra nesse paradigma é, portanto, blefe resultado de incentivos a superestimar suas capacidades militares e conseguir um acordo melhor na negociação, levando à guerra. Mas aqui é necessário mostrar porque estados não conseguem transmitir informações críveis sobre suas capacidades. Commitment problems (dificuldade de se comprometer). Potência em ascenção não pode fazer um compromisso crível de ser um hegemon benigno no futuro.^ 7.12 Exercícios Exercise 7.1 Ache todos os equilíbrios de Nash em estratégias puras do jogo abaixo. ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;format&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) C D A (-50,-50) (100,0) B (0,100) (0,0) Exercise 7.2 Considere o jogo do happy hour que você resolveu no capítulo 5. Ache os equilíbrios de Nash em estratégias puras. Exercise 7.3 Escreva a matriz de payoff dos seguintes jogos apresentados em aula: Dilema do Prisioneiro, Bach e Stravinsky, Jogo do Chicken e Stag Hunt. Ache os equilíbrios de Nash em estratégias puras desses jogos. Exercise 7.4 Considere o seguinte jogo representado na forma normal e responda Às seguintes perguntas: a) Existe alguma estratégia estritamente dominada para algum (ou ambos) jogador(es)? Se sim, qual? existe um equilírio de estratégia estritamente dominante? Se sim, qual? Existe algum equilíbrio de Eliminação Iterativa de Estratégias Estritamente Dominadas (EIEED)? Se sim, qual? Ele é ótimo de pareto? quais os equilíbrios de Nash em estratégias puras? ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;format&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) Esquerda Centro Direita Alto (2,3) (3,1) (1,2) Baixo (3,1) (1,0) (2,1) Exercise 7.5 Para esta questão, considere que uma estratégia A é fracamente dominada por B se B é fracamente preferida à A, ou seja, \\(u(A) &gt;= u(B)\\), independentemente das estratégias dos demais jogadores. Veja que isso implica que uma estratégia estritamente dominada é fracamente dominada, mas o contrário não é necessariamente verdade. Considere então o seguinte jogo e responda: Identifique, para a jogadora 2, a estratégia fracamente dominada. ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;format&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) Esquerda Centro Direita Alto (2,3) (3,1) (1,2) Baixo (3,1) (1,1) (2,1) Exercise 7.6 Nesta questão, iremos considerar a Eliminação Iterativa de Estratégias Fracamente Dominadas (EIEFD), definida de maneira similar à EIEED em classe (em vez de eliminar apenas estratégias estritamente dominadas, eliminamos as estratégias fracamente dominadas). Considere o seguinte jogo representado na forma normal e responda: Mostre que EIEFD pode levar a resultados diferentes usando ordens de eliminação de estratégias distintas. Dica: Implemente a EIEFD por uma estratégia fracamente dominada e depois repita o procedimento começando pela eliminação de outra estratégia fracamente dominada e compare os resultados. A apicação de EIEED em diferentes ordens, diferentemente de EIEFD, gera sempre o mesmo resultado. Como você interpreta essa diferença em termos das previsões de cada tipo de solução de um jogo? ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;format&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) Esquerda Centro Direita Alto (1,1) (1,3) (2,4) Baixo (2,3) (1,3) (2,2) Exercise 7.7 Em um pênalti no jogo de futebol, suponha que os jogadores podem chutar na esquerda, no centro ou no canto direito (desconsidere a altura da bola). Similarmente, o goleiro pode escolher umas das três opções para tentar agarrar a bola. Suponha também que batedores e goleiros devem escolher simultaneamente aonde a bola irá. Se o goleiro pular na mesma direção da bola, o goleiro ganha e o batedor perde. Se pular em uma direção diferente, o batedor ganha. Escreva o a matriz de payoff. Existe algum equilíbrio de Nash em estratégias puras? Se sim, quais são eles? Exercise 7.8 Três jogadoras vivem em um bairro e podem contribuir para custear uma iluminação de um poste. O valor (utilidade ou payoff) da iluminação é \\(3\\) unidades monetárias para cada jogadora e o valor (utilidade/payoff) de ficarem sem iluminação é \\(0\\). A associação do Bairro pede que cada jogadora contribua \\(1\\) unidade monetária cada (ou nada). Se pelo menos duas jogadoras contribuírem, a iluminação é instalada. Se uma ou nenhuma pessoa contribuir, a iluminação não é instalada e quem deu o dinheiro não terá ele de volta. Escreva a forma normal do jogo, a matriz de payoff e ache os equilíbrios de Nash em estratégias puras. Exercise 7.9 Em uma rede social, suponha que temos apenas três pessoas que se seguem (e não podem bloquear umas às outras) e podem fazer uma postagem sensacionalista ou não. Uma postagem sensacionalista atrai mais engajamento e mais seguidores do que a não-sensacionalista. Elas gostam de ganhar mais seguidores e não se importam se sua postagem é sensacionalista. Porém, se elas vêem em sua linha do tempo postagem sensacionalista de outras pessoas, acham isso ruim. Assim, suas preferências podem ser representadas pelos seguintes payoffs. Se uma jogadora posta algo sensacionalista, ganha \\(3\\) e se posta algo não sensacionalista, ganha \\(1\\). Se ela nao vir nenhuma mensagem sensancionalista alheia em sua linha do tempo, nem ganha nem perde nada (ganha zero). Se ela vir uma postagem alheia, perde 2 e se vir duas postagens alheias, perde 4. Todas têm as mesmas preferências. Suponha que devem decidir simultaneamente se irão postar algo sensacionalista ou não (rodada única). escreva o jogo na formal normal e a matriz de payoff. Dica: para escrever a matriz de payoff, faça duas matrizes de payoff usuais (2x2 estratégias e dois jogadores, porém com três payoffs em cada célula, o primeiro payoff da jogadora 1, o segundo da jogadora 2 e o terceiro da jogadora 3). Na primeira matriz, calcule os payofss supondo que a terceira jogadora joga a primeira estratégia, e na outra matriz, que ela joga a segunda estratégia. Assim, você representará todas as combinações de estratégias. existe um equilírio de estratégia estritamente dominante? Se sim, qual? Existe algum equilíbrio de Eliminação Iterativa de Estratégias Estritamente Dominadas (EIEED)? Se sim, qual? Ele é ótimo de pareto? Quais os equilíbrios de Nash em estratégias puras? Você acha que esse jogo simplificado captura algo relevante das redes sociais? Explique sua resposta. Exercise 7.10 Há dois bares em uma cidade, cujas proprietárias são A e B, que podem cobrar 2 reais, 4 reais ou 5 reais por bebida. Todos os dias, há 6.000 turistas e 4.000 moradores locais que decidem qual bar visitar. (Cada pessoa pode ir apenas a um bar e cada pessoa deve ir a pelo menos um bar, onde cada pessoa consome exatamente uma bebida.) Como os turistas não têm ideia sobre os bares, eles escolhem aleatoriamente sem levar em consideração os preços. No entanto, os moradores locais sempre vão ao bar mais barato (e escolhem aleatoriamente se os preços forem os mesmos). escreva o jogo na forma normal (Número de jogadores, estratégias e funções de utilidade). Suponha que quando um cliente aleatoriza, se dividem igualmente entre os dois bares. escreve a matriz de payoff (para simplificar, apresente os números em milhares de reais) Aplicando a eliminação iterativa de estratégias estritamente dominadas, existe algum equilíbrio para o jogo? Se sim, qual é ele? Quais os equilíbrios de Nash em estratégias puras? Suponha que as donas, A e B, decidam cobrar os preços de equilíbrio. Alguém pode melhorar mudando de estratégia? Justifique sua resposta. Suponha que, por um erro de impŕessão, a proprietária A anunciou um preço de 2 reais, enquanto B anunciou o preço de 4 reais. Se B sabe que foi um erro de impressão de A e A sabe que B sabe disso, qual deve ser o novo equilíbrio? no caso anterior, suponha que B descobriu que A acredita em numerologia e jamais cobrará 4 reais, podendo essa estratégia ser eliminada do jogo do ponto de vista de B. Qual o novo equilíbrio? Exercise 7.11 Considere o seguinte cenário de leilão. Duas pessoas, jogadora 1 e jogadora 2, estão competindo para obter um objeto de valor. Cada jogadora faz um lance em um envelope lacrado sem saber o lance da outra jogadora. Os lances devem ser em múltiplos de 100 reais e o valor máximo do lance é de 500 reais. O objeto tem um valor de 400 reais para a jogadora 1 e 300 reais para a jogadora 2. A licitante com o lance mais alto ganha o objeto. Em caso de empate, a jogadora 1 fica com o objeto. O vencedor do objeto paga o valor do seu lance. Se ela não ganhar o objeto, seu payoff é zero. Escreva a forma estratégica do jogo (número de jogadores, estratégias e função utilidade) deste jogo. Dica para a função utilidade: o payoff de cada jogadora é dado pelo valor do objeto para ela menos o valor do lance se ela ganha o leilão. Designe o valor do lance por \\(a_1\\) para a jogadora 1 e \\(a_2\\) para a jogadora 2. E a jogadora \\(1\\) ganha o leilão se \\(a_1 &gt;= a_2\\), e similarmente para a jogadora 2. Escreva a matriz de payoff. Quais os equilíbrios de Nash em estratégias puras desse jogo? Referências Powell, R. (2006). War as a commitment problem. International organization, 60(1), 169-203. Fearon, J. D. (1995). Rationalist explanations for war. International organization, 49(3), 379-414. Esse e outros modelos apresentados aqui foram adaptados de Formal Models of Domestic Politics, de Scott Gehlbach↩︎ inserir ref↩︎ "],["equilíbrio-de-nash-em-estratégias-mistas.html", "Capítulo8 Equilíbrio de Nash em Estratégias Mistas 8.1 Pedra-papel-tesoura 8.2 Exercícios 8.3 Referências", " Capítulo8 Equilíbrio de Nash em Estratégias Mistas Considere o jogo “cara” ou “coroa” a seguir. Nesse jogo, dois jogadores escolhem entre cara (heads) ou coroa (tails) ao mesmo tempo. Se as escolhas forem iguais, o Jogador 1 ganha um ponto. Caso contrário, o Jogador 2 ganha um ponto. O objetivo dos jogadores é maximizar sua pontuação. library(knitr) # Definindo a matriz de payoff payoff.mat &lt;- matrix(c(1, -1, -1, 1), nrow = 2, ncol = 2, dimnames = list(c(&quot;Cara&quot;, &quot;Coroa&quot;), c(&quot;Cara&quot;, &quot;Coroa&quot;))) # Renderizando a tabela de payoff kable(payoff.mat) ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;format&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) Cara Coroa Cara 1 -1 Coroa -1 1 Esse jogo é similar ao de par ou ímpar, que estamos acostumados Exercício 8.1: jogue par ou ímpar com outra pessoa por 5 rodadas. library(knitr) # Definindo a matriz de payoff payoff.mat &lt;- matrix(c(1, -1, -1, 1), nrow = 2, ncol = 2, dimnames = list(c(&quot;Par&quot;, &quot;Ímpar&quot;), c(&quot;Par&quot;, &quot;Ímpar&quot;))) # Renderizando a tabela de payoff kable(payoff.mat) ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;format&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) Par Ímpar Par 1 -1 Ímpar -1 1 Após o jogo, podemos perceber que os jogadores possuem interesses opostos e vocês esperam que o outro não consiga antecipar o que você irá fazer. Nesse caso, ele será indiferente entre jogar qualquer uma de suas estratégias, pois esperar que, na média, ambas gerem o mesmo payoff médio. Uma estratégia mista é justamente um antidoto contra as tentativas dos outros jogadores advinharem o que você irá fazer. Considere o jogo de tênis. No saque, se seu adversiário antecipar o que você irá fazer, ele terá uma vantagem. Então, você precisa jogar de um jeito que ele não consiga angtecipar ou advinhar suas estratégias. Considere o seguinte jogo. ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;format&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) C D A (4,25) (12,5) B (16,10) (8,15) É fácil ver que não há equilíbrio de Nash em estratégias puras. Vocês viram que no jogo do par ou ímpar, o ideal é jogar cada estratégia com 50% de chance. Vamos tentar colocar alguma probabilidade nesse jogo? Que tal 50% para cada estratégia também? Vamos calcular o payoff (utilidade) esperado das novas estratégias, para poder preenhcer a nova matriz de payoff aumentada. ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;format&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) C D 50% C, 50% D A (4,25) (12,5) (8,15) B (16,10) (8,15) (12.00,12.50) 50% C, 50% D (10.00,17.50) (10,10) (10.00,13.75) Vamos calcular o Equilíbrio de Nash, se existe? Novamente, não existe equilíbrio de Nash. Lembremos que estamos querendo deixar os jogadores indeferentes entre suas estratégias. Então, devemos procurar probabilidades que os deixem indiferentes. Isso significa que eles não poderão antecipar a estratégia do outro jogador se for um equilíbrio de Nash (é a melhor resposta simultaneamente). Como achar essas probabilidades? O payoff esperado de jogar A e B, para o jogador 1 deve ser o mesmo, pois ele é indiferente dado o que o jogador 2 está fazendo. E a estratégia mista de 1 deve deixar 2 indiferente entre jogar C e D. Formalmente: Se 2 está misturando suas estratpegias para deixar 1 indiferente, então a utilidade esperada de 1 jogar A, dado que 2 está jogando C com probabilidade \\(p_2c\\) e D com probabilidade $ 1 - p_2c$, deve ser a mesma de 1 jogar B, dado que 2 está jogando C com probabilidade \\(p_2c\\) e D com o complemento. Para o jogador 1, \\(E[U(A)] = E[U(B)]\\) e para o jogador 2, \\(E[U(C)] = E[U(D)]\\). Como calcular a utilidade esperada de jogar “A”? Suponha que o jogador 1 escolhe a com probabilidade \\(p_1\\), e B com probabilidade \\(1-p_2\\). Então: \\(E[U(A)] = p_2c*U(A| 2 joga C) + (1-p_2c)*U(A| dado 2 joga D ) = p_2c*4 + (1-p_2c)*12\\) \\(E[U(A)] = p_2c*4 + 12 -p_2c*12 = 12 - 8*p_2c\\) \\(E[U(B)] = p_2c*U(B| 2 joga C) + (1-p_2c)*U(B| dado 2 joga D ) = p_2c*16 + (1-p_2c)*8\\) \\(E[U(B)] = p_2c*16 + 8 -8*p_2c = 8 + 8*p_2c\\) Se 1 está indiferente, então: \\(E[U(A)] = E[U(B)]\\) \\(12 - 8*p_2c = 8 + 8*p_2c\\) \\(12 - 8 = 8*p_2c + 8*p_2c\\) \\(4 = 16*p_2c\\) \\(p_2c = 4/16\\) \\(p_2c = 1/4\\) \\(p_2d = 3/4\\) E agora fazemos a mesma coisa para o jogador 2. \\(E[U(C)] = E[U(D)]\\) \\(p_1a*U(C| 1 joga A) + (1-p_1a)*U(C| dado 1 joga B ) = p_1a*U(D| 1 joga A) + (1-p_1a)*U(B| dado 1 joga B )\\) \\(p_1a*25 + (1-p_1a)*10 = p_1a*5 + (1-p_1a)*15\\) \\(p_1a*25 + 10 -p_1a*10 = p_1a*5 + 15 - p_1a*15\\) \\(p_1a*15 + 10 = 15 - p_1a*10\\) \\(p_1a*25 = 5\\) \\(p_1a = 5/25\\) \\(p_1b = 4/5\\) Nossa matriz agora fica: ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;format&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) C D 1/4 C, 3/4 D A (4,25) (12,5) (10,10) B (16,10) (8,15) (10.00,13.75) 1/5 C, 4/5 D (13.60,13.00) (8.80,13.00) (10,13) Podemos ver, em primeiro lugar, que na nova matriz de payoff, 1 é indiferente entre jogar A, B ou sua estratégia mista de equilíbrio se 2 de fato está misturando suas estratégias C e D com as probabilidade de equilíbrio. Notem que ele sempre ganha 10. Do mesmo jeito, 2 sempre ganha 13 se 1 está em sua estratégia mista. Por fim, vemos que ambas são estratégias de equilíbrio de Nash. E, nesse caso, a única estratégia mista (ou pura) de equilíbrio. Vamos agora fazer o mesmo exercício para o jogo do par ou ímpar e para pedra, papel tesoura. Aplicação em ciência política. Suponha duas candidatas, 1 e 2, que devem decidir onde alocar seus dias finais de campanha, seja no estado A ou estado B, nos EUA. As pesquisas indicam que esses são os estados que podem decidir a batalha. Suponha que as probabilidades de cada candidata ganhar a eleição são dadas como segue: ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;format&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) A B A (0.5,0.5) (0.9,0.1) B (0.9,0.1) (0.6,0.6) Vamos calcular o ENEM (Eq. Nash em Estratégias Mistas)? Ambas vão para A com prob 3/7 (aprox. 0.43) e B com prob 4/7 (aprox. 0.57). Agora, suponha que, antes de implementar essas estratégias, novas pesquisas saem e a probabilidade muda. Se 1 for para B sozinha, sua prob é .7 e não .9. Isso é conhecimento comum. Portanto, isso poderia nos levar a crer que ela deveria gastar mais tempo em A, ou aumentar a probabilidade de ir para A. Mas os novos equilíbrios indicam que 1 agora vai para A com pob 1/5 e visitar b com 4/5. Isso porque 2 vai mudar sua estratégia e aumentar a prob de visitar A (de 3/7 para 3/5). E se ambos vão para A, a prob de 1 ganhar é menor do que se ela for para B sozinha. Esse tipo de coisa acontece com frequência em esportes. Um jogador veterano atacante se machuca e alguém das divisões de base entra no lugar. E aí, ele comeca a receber mais passes e tem mais oportunidades de gol e, por isso, marca mais gols do que o veterano. Ocorre que, como ele tem menos chance de criar jogadas e fazer gols, é melhor deixar ele mais livre e marcar outros jogadores. Isso aumenta a chance de gol do novato, mas diminui a de todos os outros jogadores. Então, embora ele esteja marcando mais gols que o veterano, o time no geral estará com desempenho pior. 8.1 Pedra-papel-tesoura Considere o jogo pedra-papel-tesoura. Assuma que vencer gera um payoff de 1, empate 0 e perder de -1. A matriz de payoff pode ser representada do seguinte modo: ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;format&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) Pedra Papel Tesoura Pedra (0,0) (-1,1) (1,-1) Papel (1,-1) (0,0) (-1,1) Tesoura (-1,1) (1,-1) (0,0) A correspondência de melhor resposta do jogador 1 para suas crenças a respeito do jogador 2 pode ser escrita da seguinte forma: \\(s_1(s_2) =\\) Papel quando \\(s_2 = Pedra\\) \\(s_1(s_2) =\\) Tesoura quando \\(s_2 = Papel\\) \\(s_1(s_2) =\\) Pedra quando \\(s_2 = Tesoura\\) E de maneira análoga para o jogador 2. É fácil ver que não existe equilíbrio de Nahs em estratégias puras nesse jogo. Raciocínios do tipo: “se ele acha que vou jogar pedra, então ele jogará papel, de forma que devo jogar tesoura. Porém, se ele antecipar isso, ele jogará pedra, de forma que devo jogar papel. Mas ele pode antecipar isso também e jogar tesoura, mas aí eu jogo pedra…” leva a uma regressão que nunca terminará. Em certo sentido, tanto faz o que você joga, porque não é possível advinhar o que você o outro jogador irá fazer. Mas dizer tanto faz pode ser pensado como se você aleatorizasse e jogasse cada uma das três ações com a mesma probabilidade \\(1/3\\), e o mesmo o jogador 2. Nesse caso, dizemos que os jogadores estão jogando uma estratégia mista. Neste caso em particular, joga cada uma das t^Res ações com probabilidade \\(1/3\\). Definição do Ronaldo Fiani (p. 192): Quando, em vez de escolher entre suas estratégias uma dada estratégia para jogá-la com certeza, um jogador decide alternar entre suas estratégias aleatoriamente, atribuindo uma probabilidade a cada estratégia a ser escolhida, diz-se que o jogador utiliza estratégias mistas. Caso contrário, diz-se que emprega estratégias puras. Nós vamos definir estratégias mistas da seguinte forma: Se o conjunto de estrartégias disponíveis para um jogador é \\(S = (s_1, s_2, ..., s_m)\\), então uma estratégia mista para aquele jogador é uma loteria sobre \\(S\\), \\(p = (p_1, p_2, ..., p_m)\\). Diz-se que o jogador escolheu a estratégia \\(p\\) se ele usa esta loteria para determinar qual estratégia pura irá implementar no jogo. Em outras plavras, uma estratégia mista é uma distribuição de probabilidade que determina como uma estratégia pura será jogada por meio da realização dessa distribuição. Definição 8.1. Se um conjunto de estatégias disponíveis para um jogador é \\(S = {s_1, s_2, ..., s_n}\\), então uma estratégia mista para aquele jogador é uma loteria sobre \\(S\\), \\(p = (p_1, p_2, ..., p_n)\\). Diz-se que o jogador escolhe essa estratégia \\(p\\) se ele usa essa loteria para determinar que estratégia pura irá implmentar quando de fato jogar o jogo. 8.2 Exercícios Exercise 8.1 Qual o equilíbrio de Nash em Estratégias Mistas (ENEM) do Dilema do Prisioneiro? Exercise 8.2 Qual o equilíbrio de Nash em Estratégias Mistas (ENEM)do jogo do Chicken?? Exercise 8.3 Para as perguntas abaixo, considere o seguinte jogo representado na forma estratégica: a) Existe algum equilíbrio de Nash em Estratégias Puras (ENEP)? Se sim, qual (ou quais)? b) Quantos equilíbrios de Nash em estratégias mistas existem? ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;format&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) Esquerda Centro Alto (3,3) (3,3) Baixo (3,3) (3,3) Exercise 8.4 Considere o seguinte jogo representado na forma estratégica para as perguntas abaixo: a) Existe algum equilíbrio de Nash em Estratégias Puras (ENEP)? Se sim, qual (ou quais)? Existe ENEM em que os jogadores aleatorizam entre A e B? Explique. Existe ENEM em que os jogadores aleatorizam entre B e c? Explique. ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;format&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) A B C A (4,4) (0,5) (-1,0) B (5,0) (1,1) (0,0) C (0,-1) (0,0) (1,1) Exercise 8.5 Uma funcionária (jogadora 1) que trabalha para uma chefe (jogadora 2) pode tanto trabalhar (T) quanto enrolar (E), enquanto sua chefe pode tanto monitorar a funcionária (M) quanto ignorá-la (I). Como em muitos relacionamentos entre funcionária e chefe, se a funcionária estiver trabalhando, a chefe prefere não monitorá-la, mas se a chefe não estiver monitorando, a funcionária prefere enrolar. A matriz de payoff abaixo representa uma situação como essa. Responda às seguintes perguntas: escreva a fução de melhor resposta de cada jogadora (isto é, para a jogadora 1, qual probabilidade \\(p\\) ela deve escolher para cada possível escolha de probabilidade \\(q\\) da jogadora 2). qual o equilíbrio de Nash do jogo? ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;format&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) M I T (1,1) (1,2) E (0,2) (2,1) 8.3 Referências Gauriot, R., Page, L., &amp; Wooders, J. (2023). Expertise, gender, and equilibrium play. Quantitative Economics, 14(3), 981-1020. "],["jogos-dinâmicos.html", "Capítulo9 Jogos Dinâmicos 9.1 Introdução 9.2 Jogo na forma extensiva 9.3 Jogo da confiança 9.4 Informações 9.5 Jogos de informação perfeita e imperfeita 9.6 Estratégias 9.7 Estratégias comportamentais 9.8 Representação estratégica de jogos na forma extensiva 9.9 Equilíbrio de Nash e Caminhos de jogada", " Capítulo9 Jogos Dinâmicos 9.1 Introdução Vamos falar de jogos din Considere novamente o jogo Bach e Stravinsky. Suponha que a jogadora 1 joga primeiro e e a jogadora 2 pode observar a esoclha de 1. Imagine que ela vai para um lugar, liga para a amiga e diz: estou aqui no lugar tal (espetáculo do Bach ou do Stravinsky). Veja que em termos de equilíbrios de Nash, continuamos com os mesmos dois equilíbrios de antes. Porém, não faz sentido achar que o equilíbrio (S,S) será jogado, pois a jogadora 1 sabe que, se for para Bach, 2 também irá. Jogos na forma normal não capturam muito bem a noção de jogos sequenciais e racionalidade sequencial. A forma estratégica do jogo, de fato, não traz informações nem sobre a ordem dos movimentos, nem as ações disponíveis para cada jogadora na sua vez de jogar. Por isso, iremos alterar a representação de nosso jogo, para a forma extensiva, que tornará explícito a ordem em que as jogadoras jogam, e o que cada jogadora sabe quando é sua vez de jogar. Nesse cenário, estratégias referem-se a planos contingentes de ações (como no jogo da bandeira), em vez de ações não-contigentes. Iremos introduzir a noção de indução reversa ou indução para trás como uma forma de solucionar jogos. Noção que for formalizada por Selten (1965) como equilíbrio de subjogo-perfeito e contempla situações em que jogadoras se movem simultaneamente em múltiplos períodos e a indução reversa não pode ser aplicada. Comecemos então pela introdução do que significa descrever um jogo na forma extensiva. 9.2 Jogo na forma extensiva Um jogo na forma extensiva pode ser visto como uma generalização multi-estágio de árvores de decisão. Figure 9.1: Representação do Jogo da coordenação A árvore do jogo é lida de cima para baixo. No topo está quem joga primeiro. O retângulo com o nome da jogadora é chamado de nó. No primeiro nó, Serena tem duas ações possíveis, “Bach” e “Stravinski”. Uma vez que ela escolha sua ação, é a vez da Nina, que também tem duas opções (“bach” e “stravinsky”, em caixa baixa, para distinguir as ações das duas jogadoras). Se Serena escolheu Bach, Nina está no galho da esquerda. Se Serena escolheu Stravinsky, Nina está no galo da direita. E uma vez que Nina faça sua escolha, o jogo acaba e os payoffs finais são mostrados. O primeiro payoff é da jogadora 1, e o segundo da jogadora 2. Assim, com a forma extensiva, temos como antes: Número de jogadoras, \\(N\\). Payoffs ou funções de utilidade em função dos resultados, \\(\\{u_i(\\cdot)\\}_{i \\in N}\\) E acrescentamos: Ordem dos movimentos Ações das jogadoras quando for a vez delas de se moverem. O conhecimento que as jogadoras possuem quando é sua vez de se moverem. O ponto 5 é importante para distinguir entre Nina joga depois da Serena de um lado, e Nina joga depois da Serena sabendo o que Serena jogou antes dela. Por fim, mantemos uma suposição feita em nossos jogos anteriores, agora estendida aos itens 1-6, que é: É conhecimento comum toda a estrutura do jogo representada pelos itens 1-6 para todas as jogadoras. 9.2.1 Definição de árvore de um jogo Uma árvore do jogo é formada por um conjunto de nós \\(x \\in X\\) com uma relação de precedência \\(x &gt; x&#39;\\), que significa “\\(x\\) precede a \\(x&#39;\\)”. Ou seja, \\(x\\) vem antes de \\(x&#39;\\). Cada nó só tem um predecessor. A relação de precedência é transitiva (\\(x &gt; x&#39;, x&#39; &gt; x&#39;&#39; \\implies x &gt; x&#39;&#39;\\)), assimetrica \\((x &gt; x&#39; \\implies \\neg (x&#39; &gt; x))\\), isto é, \\(x\\) precede \\(x&#39;\\), mas \\(x&#39;\\) não precede \\(x\\), e incompleta (nem todos os pares podem ser ordenados). Há um nó especial, chamado raiz da árvore, denotada por \\(n_1\\), que precede quaisquer outros nós \\(x \\in X\\). Nós que não precedem outros nós são chamados de nós terminais, denotados pelo conjunto \\(Z \\subset X\\). Nós terminais denotam o fim do jogo, com os payoffs associados. Cada nó \\(x\\) que não é terminal é atribuído a um jogador \\(i(x)\\) com o conjunto de ações \\(A_i(x)\\), ou para natureza. É uma definição longa, masque captura a estrutura “física” do jogo, ao mesmo tempo em que ignora as ações (escolhas) das jogadoras e o que sabem quando jogam. 9.3 Jogo da confiança Figure 9.2: Representação do Jogo da Confiança O jogador p1 joga primeiro. Logo, \\(i(n_1) = p_1\\). 9.4 Informações Quais informações cada jogador tem quando é sua vez de jogar? Uma jogadora pode ter informação bem fina sobre onde está no jogo, ou bem grosseira. Vamos então introduzir a seguinte definição: Definição conjunto de informações: Cada jogador \\(i\\) tem uma coleção de conjuntos de informação \\(h_i\\) the particiona (divide) os nós do jogo no qual uma jogadora \\(i\\) move com as seguintes propriedades: Se \\(h_i\\) é uma conjunto unitário (singleton) que inclui apenas \\(x\\), então a jogadora \\(i\\) que se move em \\(x\\) sabe que está em \\(x\\). Se \\(x \\neq x&#39;\\) e se ambos \\(x \\in h_i\\) e \\(x&#39; \\in h_i\\) então a jogadora \\(i\\) que se move em \\(x\\) não sabe se está em em \\(x\\) ou \\(x&#39;\\). Se \\(x \\neq x&#39;\\) e se ambos \\(x\\) e \\(x&#39; \\in h_i\\), então \\(A_i(x) = A_i(x&#39;)\\). Vamos entender esta definição formal. Considere novamente o jogo do Bach e Stravinsky na forma extensiva. Figure 9.3: Representação do Jogo da coordenação simultâneo No gráfico 9.1. temos \\(x_1\\), \\(x_2\\)… como nós. Considere quando a jogadora Nina se move em \\(x_1\\). A questão é: ela sabe que está em \\(x_1\\)? Ou não sabe se está em \\(x_1\\) ou \\(x_2\\)? Se a gente escreve \\(h_2 = {x_2}\\), então isso significa que o conjunto de informações em \\(x_1\\) é um conjunto unitário. Portanto, a jogadora a jogadora possui informação que diz “estou em x_2”, que é capturado pela propriedade 1 da definição. Nesse caso, segue-se que a jogadora 2 também tem outro conjunto de informação $h_2 = {x_3}. Se, por outro lado, Nina não sabe se está em \\(x_1\\) ou \\(x_2\\), como no jogo do Bach e Stravinsky simultâneo (figura 9.3), então deve ser verdade que sua informação é de que está em \\(x_1\\) ou \\(x_2\\), mas não sabe em qual dos dois. Nesse caso, escrevemos \\(h_2 = {x_1, x_2}\\). Esta é a propriedade 2. Finalmente, a propriedade 3 é essencial para manter a lógica da informação, em particular quando as ações disponíveis em cada nós forem diferentes para uma jogadora. Considere o jogo da confiança. Se ela não sabe se está no nó \\(x_1\\) (onde o jogo terminou e não tem o que fazer) ou \\(x_2\\), então ela não pode saber quais as ações disponíveis para ela. Por fim, em alguns casos é possível acrescentar eventos aleatórios. Por exemplo, o jogo acima poderia ser modificado para incluir a chance de chover. Suponha que o espetáculo de Bach é a céu aberto, e o de Stravinski, não. Então, se choveu os payoffs das jogadoras é diferente de se não choveu. Vamos supor que elas preferem ficar juntas sob chuva que separadas. Como representar essa possibilidade? A forma como fazemos isso é criar uma jogadora fictícia, que é a natureza, que joga aleatoriamente sem considerações estratégicas. Essa probabilidade é exógena, no sentido de que é fixa e determinada antes do jogo começar, de modo que não depende das escolhas das jogadoras. Eis como ficaria o jogo nesse caso: Figure 9.4: Representação do Jogo da coordenação, com a natureza movendo primerio Na 9.4, temos algumas mudanças. O primeiro nó está representado por um círculo vazado, para indicar que é a natureza quem está jogando (e não terá um payoff). Os demais nós são representados por círculos prreenchidos, sólidos. Portanto, a natureza joga e “escolhe” se fará sol ou chuva. Na prática as leis da natureza irão operar, e podemos calcular probabilidades (no caso, 50% de chance de chover), mas a jogadorta Serena só sabeá se haverá sol ou chuva na hora do espetáculo, após ter feito sua jogada. Isso significa que Serena não sabe em qual nós está, se no da esquerda, com chuva, ou no da direita, com sol. Para indicar essa ausência de informação, é comum circularmos com uma linha tracejada os nós nos quais uma jogadora não tem informação sobre qual nó ela está. Uma vez que Serena Joga, é a vez de Nina jogar. Note que não circulamos nós de Nina com linha tracejada, de modo que isso significa que Nina sabe em qual nó está, ou seja, sabe não apenas o que Serena jogou, mas o que a natureza jogou. Como é difícil imaginar tal situação, o melhor seria indicar também que Nina não sabe o que a Natureza jogou, mas sabe o que a Serena jogou. A árovre do jogo ficartão então. Figure 9.5: Representação do Jogo da coordenação, com a natureza movendo primerio, conjunto de informações corretos. Nessa árvore, vale destacar dois aspectos que são diferentes da árvore anterior. Em primeiro lugar, nós descrevemos a informação completa sobre em qual nó Nina está por meio de linha tracejada curva. Poderíamos ter usado o círculo tracejado, que daria na mesma. São duas formas distintas de representar a mesma coisa e estamos incluindo aqui para fins de completude. Em segundo lugar, note os nós que estão conectados pela linha. Quando é a vez de Nina jogar, ela não sabe o que a natureza jogou, mas sabe o que Serena jogou. Isso significa que se Serena jogou “Bach”, Nina não sabe se está no ramo “Bach” com chuva ou no ramo “Bach” som sol. Similarmente, se Serena jogou “Stravinski”, Nina não sabe em qual dos dois galhos de “Stravinski” ela está. É preciso, portanto, ter cuidado quando conectar nós, pois se fizemos errado, o jogo fica completamente outro. 9.5 Jogos de informação perfeita e imperfeita Os jogos na forma normal eram chamados de jogos de informação completa, pois todas as jogadores conheciam as ações disponíveis e as funções de payoff de todas as jogadoras, e isso era conhecimento comum. Agora, nós temos uma situação em que uma jogadora pode ter conhecimento perfeito ou imperfeito do nó em que está, a depender do particionamento do conjunto de informações. Portanto, vale a pena distinguir entre dois tipos de jogos de informação completa. Definição: Um jogo de informação completa no qual cada conjunto de informação é um conjunto unitário e não há jogadas da natureza é chamado um jogo de informação perfeita. Um jogo no qual pelo menos um conjunto de informação contém vários nós ou um jogo com movimentop da natureza é chamado um jogo de informação imperfeita. 9.6 Estratégias Nós já havíamos definido uma estratégia como um plano de ação contigente. Contudo, em jogos na forma normal, essa definição era pouco útil, pois estratégias (puras) coincidiam com as ações disponíveis para as jogadoras. Na forma externsiva, a nossa definição de estratégia se revelará mais útil. 9.6.1 Estratégias puras Consideremos novamente o jogo sequencial Bach-Stravinski na sua forma mais simples, representado pelo gráfico 9.1. Serena é a primeira a jogar e seu conjunto de informação possui apenas um nó e para ela uma estratégia pura é tão simples quanto jogar B ou S. Para Nina, a situação é um pouco mais complexa, posto que ela possui dois conjuntos de informação, um para cada estrarégia de Serena. Portanto, não basta dizer que as duas ações B e S são as estratégias de Ninas. Estratégias Puras em Jogos na forma Extensiva: Uma estratégia pura para a jogadora \\(i\\) é um plano completo de ação que descreve qual ação a jogadora \\(i\\) escolherá em cada um de seus conjuntos de informação. No jogo Bach-Stravinski 9.2, vemos que a estratégia de Serena é apenas \\(\\{\\text{Bach},\\text{Stravinski}\\}\\), e a de nina, \\(\\{\\text{B},\\text{S}\\}\\), pois ambas as jogadoras possuem apenas um conjunto de informação. Em outras palavras, o jogo na forma extensiva é idêntico ao jogo na forma estratégica. Já no jogo sequencial, como vimos, Nina tem dois con juntos de informação disintos no qual ela pode escolher entre duas ações (B,S), a depender de qual foi o movimento de Serena. Portanto, um plano completo de ação para Nina deve ter instruções do que fazer para cada escolha de Serena. A escolha do conjunto de ações \\(\\{\\text{B},\\text{S}\\}\\) deve ser contigente ao que Serena escolheu, do tipo: “Se Serena escolher Bach, escolha B”, ou “Se Serena escolher Bach, Nina escolherá S, já se Serena escolher Stravinski, Nina escolherá S” e assim por diante. Para resumir, descreveremos o conjunto de estratégias da seguinte forma: \\[ S_{\\text{Nina}} = \\{BB, BS, SB, SS\\} \\] Assim, a estratégia \\(BB\\) quer dizer, jogue B se Serena escolher Bach, e jogue B se Serena escolher Stravinski. Por outro lado, \\(BS\\) quer dizer, jogue B se Serena escolher Bach, e jogue S se Serena escolher Stravinski, e assim por diante. Para Serena, o conjunto de estratégias continua \\(S_{\\text{Serena}} = \\{Bach, Stravinski\\}\\). Agora podemos definir formalmente o que é uma estratégia pura, se adotarmos algumas notações específicas. Seja \\(H_i\\) a coleção de todos os conjuntos de informação no qual a jogadora \\(i\\) joga, e seja \\(h_i \\in H_i\\) um dos conjuntos de informação de \\(i\\). Seja \\(A_i(h_i)\\) as ações que a jogadora \\(i\\) pode tomar em \\(h_i\\), e seja \\(A_i\\) o conjunto de todas as ações da jogadora \\(i\\), \\(A_i = \\cup_{h_i \\in H_i}A_i(h_i)\\), isto é, a união de todos os elementos em todos os conjuntos \\(A_i(h_i)\\). Definição 9.3: Uma estratégia pura para uma jogadora \\(i\\) é um mapeamento \\(s_i:H_i \\rightarrow A_i\\) que atribui uma ação \\(s_i(h_i) \\in A_i(h_i)\\) para todo conjunto de informação \\(h_i \\in H_i\\). Denotamos por \\(S_i\\) o conjunto de todos os mapeamentos de estratégias puras \\(s_i \\in S_i\\). 9.6.2 Estratégias mistas Uma estratégia mista para a jogadora \\(i\\) é uma distribuição de probabilidade sobre suas estratégias puras \\(s_i \\in S_i\\). Uma vez que uma estratégia mista é uma aleatorização de estratégias puras, perdemos o componente dinâmico do jogo, já que as probabilidades devem ser definidas antes do jogo começar e uma vez sorteada a estratégia a jogar, joga a escolhida independentemente da dinâmica do jogo. No caso do jogo Bach-Strvinski, a jogadora 2 teria de aleatorizar entre (BB, BS, SB, SS). Mas não poderia ter uma estratégia do tipo, se 1 jogar “Bach”, jogo B, e se jogar “Stravinski”, jogo S com probabilidade \\(2/3\\). 9.7 Estratégias comportamentais Para permitir esse tipo de comportamento, definiremos o conceito de estratégia comportamental: ela especifica para cada conjunto de informação \\(h_i \\in H_i\\) uma distribuição de probabilidade independente sobre \\(A_i(h_i)\\) e é denotada por $_i:H_i A_i(h_i), em que \\(\\sigma_i(a_i(h_i))\\) é a probabilidade que a jogadora \\(i\\) joga a ação \\(a_i(h_i) \\in A_i(h_i)\\) no conjunto de informação \\(h_i\\). Pergunta: dada uma estratégia mista (não comportamental), podemos achar uma estratégia comportamental que leva ao mesmo resultado? Sim, sempre é possível fazer essa operação. E o oposto, dada uma estratégia comportamental, podemos achar uma mista que leva ao mesmo resultado? Sim, em jogos de lembrança perfeita (perfect recall). E um jogo é de lembrança perfeita se nenhuma jogadora jamais esquece uma informação que soube previamente. Portanto, estratégias mistas e comportamentais são equivalentes nessas classes de jogos, no sentido de que a mesma distribuição de resultados sempre pode ser alcançada com estratégias mistas e comportamentais. Definição: perfect recall (memória perfeita) 9.8 Representação estratégica de jogos na forma extensiva 9.9 Equilíbrio de Nash e Caminhos de jogada Como vimos, um dos equilíbrios de Nash do jogo Bach-Stravinski é (Bach, BB), e outro é (Bach, BS). E a diferença desses dois equilíbrio é o que a jogadora 2 joga no conjunto de informação fora do equilíbrio. Vejam que na forma extensiva, cara resultado é associado a um único caminho de jogo, já que há um único caminho do nó raiz para cada nó terminal. Isso segue da definição que cada nó deve ser precedido por apenas um nó. Em termos de equilíbrio de Nash, isso significa que se um perfil de estratégia \\(s^{\\star}\\) é um equilíbrio de Nash, então cada jogadora prefere seguir o caminho predito pelo equilíbrio do que escolher outro alternativo, dado o que as demais estão fazendo. O que nos leva a mais uma definição: Seja \\(\\sigma^{\\star} = (\\sigma_1^{\\star}, ..., \\sigma_n^{\\star})\\) um perfil de estratégias comportamentais de equilíbrio de Nash em um jogo na forma extensiva. Dizemos que um conjunto de informação está no caminho de equilíbrio se dado \\(\\sigma^{\\star}\\) ele é alcançado com probabilidade positiva. E dizemos que um conjunto de informação está fora do caminho de equilíbrio se dado \\(\\sigma^{\\star}\\) ele nunca é alcançado. Portanto, equilíbrios de Nash envolvem crenças do que irá ocorrer no caminho de equilíbrio e fora dele. Entretanto, deixa claro que ameaças não-críveis são aceitas pelas jogadores. Basicamente diz para jogadoras agirem racionalmente no caminho de equilíbrio, dadas as crenças dentro e fora do caminho de equilíbrio. Mas se as crenças no caminho fora de equilíbrio são importantes, agir racionalmente fora dele também deveriqa ser, certo? "],["credibilidade-e-racionalidade-sequencial.html", "Capítulo10 Credibilidade e racionalidade sequencial 10.1 Introdução 10.2 Racionalidade sequencial e indução reversa 10.3 Subjogo 10.4 Equilíbrio de Nash Perfeito de Subjogo 10.5 Exercícios", " Capítulo10 Credibilidade e racionalidade sequencial 10.1 Introdução 10.2 Racionalidade sequencial e indução reversa Nós já vimos que podemos usar a indução reversa para achar os únicos equilíbrios e Nash que demandam racionalidade dos jogadores dentro e fora do caminho de equilíbrio. Em outras palavras, os jogadores precisam jogar racionalmente em todo conjunto de informação. Chamamos esse princípio de racionalidade sequencial, pois implica que as jogadoras estão jogando racionalmente em cada estágio da sequência do jogo, seja dentro ou fora do caminho de equilíbrio. Contudo, quando o jogo é de informação imperfeita, não podemos aplicar a indução reversa para achar jogadas sequencialmente racional. Além disso, jogos que não são finitos tambpouco podem se beneficiar da indução reversa. Caso em que é mais vantajoso usar uma formalização desenvolvida por Selten (1975) de subjogo próprio (frequentemente chamada apenas de subjogo). 10.3 Subjogo Subjogo de um jogo extensivo com informação perfeita Um subjogo é qualquer parte de um jogo na forma extensiva que satisfaz as seguintes condições: Sempre se inicia em um único nó de decisão Não está em um nó terminal Contém todos os nós que se seguem após ele Em um jogo de informação imperfeita, acrescentamos: Se contiver qualquer nó de um conjunto de informação, ele conterá todos os nós do conjunto de informação. Nós chamamos de subjogo próprio todos os subjogos que não são a árvore do jogo na sua totalidade. Definição: Um subjogo próprio \\(G\\) de um jogo na forma extensiva \\(\\Gamma\\) consiste apenas de um nó e todos os seus sucessores em \\(\\Gamma\\) com a propriedade que se \\(x \\in G\\) e \\(x&#39; \\in h(x)\\) então \\(x&#39; \\in G\\). 10.4 Equilíbrio de Nash Perfeito de Subjogo A ideia é que iremos demandar que as jogadores joguem racionalmente em sequência em cada subjogo do jogo na forma extensiva. E chamaremos a isso de equilíbrio de Nash perfeito de subjogo. Fato: em jogos de informação perfeita finitos, os equilíbrios que sobrevivem a indução reversa são equilíbrios de Nash perfeitos de subjogo. Equilíbrio de Nash Perfeito em Subjogos Definição informal: Um equilíbrio perfeito em subjogos é um perfil estratégico \\(s^*\\) com a propriedade de que, em nenhum subjogo, qualquer jogador \\(i\\) pode se sair melhor escolhendo uma estratégia diferente de \\(s^*_i\\), dado que todos os outros jogadores \\(j\\) aderem a \\(s^*_j\\). Nessa definição (informal), requeremos que a estratrégia de cada jogadora seja ótima para toda história após ser a vez dela jogar, e não apenas no início do jogo, como no equlíbrio de Nash. Todo jogo extensivo finito com informação perfeita possui (pelo menos) um equilíbrio perfeito de subjogo. Um jogo finito significa que em nenhum momento um jogador possui infinitas opções de ações. Para dar um exemplo trivial (do Osborne): um único jogador escolhe um número menor que 1 e recebe um pagamento igual ao número que ela escolhe. Não há um número maior que todos os outros números menores que um, então o jogador único não possui uma ação ótima, e assim o jogo não possui um equilíbrio perfeito de subjogo. 10.5 Exercícios Ache todos os subjogos do jogo abaixo. Modelo o jogo como uma árvore (forma extensiva) e ache todos os subjogos do jogo abaixo. (exercício 156.2c do Osborne). Os políticos Rosa e Ernesto precisam tomar uma posição sobre um assunto. As opções são Berlim (B) ou Havana (H). Eles escolhem sequencialmente. Uma terceira pessoa, Karl, determina quem escolhe primeiro. Tanto Rosa quanto Ernesto se importam apenas com as ações que escolhem, não com quem escolhe primeiro. Rosa prefere o resultado em que ambos escolhem B ao resultado em que ambos escolhem H, e prefere esse resultado a qualquer um dos casos em que ela e Ernesto escolhem ações diferentes; ela é indiferente entre esses dois últimos resultados. As preferências de Ernesto diferem das de Rosa no sentido de que os papéis de B e H são invertidos. As preferências de Karl são as mesmas que as de Ernesto. Modele essa situação como um jogo extensivo com informação perfeita. (Especifique os componentes do jogo e represente o jogo em um diagrama.) Modele o jogo do Ultimato com três períodos e: conte quantos subjogos existem. Ache o equilíbrio de Nash Perfeito em Subjogos Considere um jogo de dois períodos em que um trabalhador busca emprego.No período 1, ele recebe uma oferta de um salário \\(S_1\\) e deve decidir se aceita ou não. Se aceitar, este é seu salário e para de procurar emprego. Caso não aceite, continua no período 2, e recebe uma oferta de salário \\(S_2 &gt; S_1\\) com probabilidade \\(p\\) e \\(0\\), isto é, não recebe oferta com probabilidade \\(1-p\\). Desenho o jogo na forma extensiva. Calcule quantos subjogos existem. Suponha que \\(S_2 = 2S_1\\) e \\(p=.8\\)? Qual o equilíbrio de Nash perfeito em Subjogos do jogo. "],["barganha.html", "Capítulo11 Barganha 11.1 Introdução 11.2 Jogo do Ultimato 11.3 2 períodos 11.4 3 Períodos. 11.5 T períodos (T ímpar) 11.6 Infinitos períodos 11.7 Modelo de Baron Ferejohn de Bargana legislativa 11.8 Ultimato Legislativo 11.9 Modelo de dois períodos 11.10 Horizonte infinito 11.11 A suposição de imprevisibilidade 11.12 Aplicações 11.13 Take away 11.14 Exercícios", " Capítulo11 Barganha 11.1 Introdução O jogo do ultimato é talvez o jogo mais simples de barganha que existe. No entanto, ele é útil porque pode ser generalizado e trazer insights úteis. 11.2 Jogo do Ultimato O jogo do ultimato consiste no seguinte. Serena e Martín precisam decidir como dividir um pedaço de bolo de tamanho \\(1\\). O pai informa que primeiro Serena fará uma proposta de divisão de \\(X\\) para ela e \\(1-X\\) para Martín. Se a proposta for aceita, o bolo é dividido daquela forma. Se for negada, ninguém fica com o bolo (porque não chegaram a um acordo). É fácil ver que a proposta \\((1,0)\\), isto é, Serena pega todo o bolo e Martín fica sem nada é um equilíbrio de Nash, pois nem Serena nem Martín podem melhorar unilateralmente. De maneira genérica, o jogo do ultimato pode ser generalizado da seguinte forma4: 11.3 2 períodos Vamos modificar o jogo do ultimato e admitir que se alguém não gosta da proposta da outra pessoa, pode fazer uma contraproposta, sempre de maneira alternada. Porém, o jogo acaba em até \\(T\\) rodadas se um acordo não for alcançado e ninguém fica com o bolo neste caso. Como existe passagem de tempo, precisamos descontar o futuro. A forma mais geral do problema é assumir que ambos Serena e Martín descontam o futuro em \\(0 &lt; \\delta_i &lt; 1\\), isto é, um acordo alcançado no período \\(t\\) com uma parcela \\(s_i\\) gera um payoff ou utilidade equivalente a \\(s_i \\delta_i^{t-1}\\) no presente. Porém, vamos simplificar e assumir que Martín e Serena têm a mesma taxa de impaciência \\((\\delta_i = \\delta_j = \\delta)\\). O Equilíbrio de Nash Pefeito em Subjogo pode ser achado por indução reversa. No período 2 (o último), temos um novo jogo do ultimato, e Martín irá oferecer todo o bolo para si e nada para Serena, e isso é um equilíbrio de Nash neste subjogo. Designando a oferta no período \\(t\\) por \\(X_t = (X_1, 1 - X_1)\\), e considerando a oferta é \\(X_2 = (0,1)\\), o equilíbrio neste subjogo é \\(X(0,1)\\), com payoffs \\(u_1 = 0\\) e \\(u_2 = \\delta\\). No período 1, se Serena oferecer menos do que \\(\\delta\\) para Martín, ele não aceitará, pois poderá obter \\(\\delta\\) no período subsequente. Então, ela oferece \\(\\delta\\) e fica com \\(1-\\delta\\) para si, ele aceita e o jogo acaba. As estratégias de equilíbrio (SPE) são: Serena oferta \\(X_1 = (1 - \\delta, \\delta)\\) no período e aceita qualquer oferta no período 2; e Martín aceita qualquer oferta \\(\\geq \\delta\\) no período 1 rejeita se for menor, caso em que propõe \\(X_2 = (0,1)\\). 11.4 3 Períodos. No terceiro período, Serena sabe que é um jogo ultimato e fica com tudo para si \\(X_3 = (1,0)\\). Os payoffs são: \\(u_1 = \\delta^2\\) e \\(u_2 = 0\\). Então, na rodada 2, Serena só aceita oferta que seja tão boa quanto pode obter no terceiro período, isto é: \\(u_1 \\geq \\delta^2\\). Digamso que Martín ofereça \\(x\\) no período 2. A utilidade nesse caso é \\(\\delta x\\), ou seja, \\(u_1 = \\delta x\\). Mas como \\(u_1 \\geq \\delta^2\\), apenas \\(x \\geq \\delta\\) é vantajoso, pois aí a utilidade será: \\(u_1 \\geq \\delta\\delta = delta^2\\). Martín, portanto, precisa oferecer pelo menos \\(\\delta\\), ficando com \\(1-\\delta\\) e payoff \\(u_2 = \\delta(1-\\delta)\\). Por fim, no primeiro período, Serena sabe que Martín pode ganhar \\(\\delta(1-\\delta)\\), portanto qualquer que seja o \\(x\\) de Serena (e consequente \\(1-x\\) para si), pode oferecer \\(1 - x \\geq \\delta(1-\\delta)\\) para Martín que ele irá aceitar e o jogo acaba na primeira rodada. Portanto, resolvendo a desigualdade, temos a melhor resposta de Serena: \\(x = 1 - \\delta(1-\\delta)\\) com equilíbrio: Serena oferece \\(X = (1 - \\delta + \\delta^2, 1-\\delta)\\) e Martín aceita e o jogo acaba. 11.5 T períodos (T ímpar) Conside \\(T\\) finito, mas ímpar. Isso quer dizer que Serena joga primeiro (first mover advantage) e por último (last mover advantage). No último período, \\(T\\), como sempre, Serena oferece \\(X_t=(1,0)\\), com payoff \\(u_1 = x\\delta^{T-1}\\) e \\(u_2 = 0\\). No período \\(T-1\\), Martín sabe que Serena pode ganhar pelos menos \\(\\delta^{T-1}\\). Para um dado \\(x\\) oferecido, \\(u_1 = \\delta^{T-2}x\\). E \\(\\delta^{T-2}x \\geq \\delta^{T-1}\\), ou seja, \\(x \\geq \\frac{\\delta^{T-1}}{\\delta^{T-2}} = \\delta\\). Então, \\(X = [\\delta; 1 - \\delta]\\), com payoffs $u_1 = ^{T-2} = ^{T-1} $ e \\(u_2=\\delta^{T-2} (1 - \\delta)\\). Em \\(T-2\\), qualquer que seja o \\(x\\) de Serena, Martín precisa ganhar \\(\\delta^{T-3}(1 - x) \\geq \\delta^{T-2} (1 - \\delta)\\). Simplificando a desigualdade, temos: \\[\\begin{aligned} \\delta^{T-3}(1 - x) \\geq \\delta^{T-2} (1 - \\delta) \\\\ (1 - x) \\geq \\frac{\\delta^{T-2} (1 - \\delta)}{\\delta^{T-3}} \\\\ x \\geq -1 + \\frac{\\delta^{T-2} (1 - \\delta)}{\\delta^{T-3}} \\\\ x \\leq 1 - \\frac{\\delta^{T-2} (1 - \\delta)}{\\delta^{T-3}} \\\\ x \\leq 1 - \\frac{(1 - \\delta)}{\\delta^{-1}} \\\\ x \\leq 1 - (1 - \\delta)\\delta \\\\ x \\leq 1 - \\delta + \\delta^2 \\\\ \\end{aligned}\\] Obviamente, Serena escolhe o maior valor possível para si de \\(x = 1 - \\delta + \\delta^2\\) e os payoffs são: \\(u_1 = \\delta^{T-3} (1 - \\delta + \\delta^2) = \\delta^{T-3} - \\delta^{T-2} + \\delta^{T-1}\\) $ e $u_2 = ^{T-3}(- ^2) = \\(\\delta^{T-2} - \\delta^{T-1}\\) No período \\(T-3\\), raciocínio se repete, e temos. Serena tem valor de continuação do jogo igual a \\(\\delta^{T-3} - \\delta^{T-2} + \\delta^{T-1}\\), Martín vai oferecer \\(x\\), com payoff \\(u_1 = \\delta^{T-4}x\\) e, portanto, \\(\\delta^{T-4}x \\geq \\delta^{T-3} - \\delta^{T-2} + \\delta^{T-1}\\) ou simplificando, \\(x = \\delta - \\delta^2 + \\delta^3\\), rendendo payoffs \\(u_1 = \\delta^{T-4}(\\delta - \\delta^2 + \\delta^3) = \\delta^{T-3} - \\delta^{T-2} + \\delta^{T-1}\\) e \\(u_2 = \\delta^{T-4} - \\delta^{T-3} + \\delta^{T-2} - \\delta^{T-1}\\). Se ficarmos repetindo esse exercício, temos um padrão que pode ser escrito do seguinte modo. Considere um período \\(T - s\\), em que \\(s\\) é par. Então, Serena oferecerá \\(x_{T-s} = 1 - \\delta + \\delta^2 - \\delta^3 + \\ldots + \\delta^s\\). Já para \\(s\\) par, a oferta feita por Martín é de \\(x_{T-s} = \\delta - \\delta^2 + \\delta^3 - \\delta^4 + \\ldots + \\delta^s\\). Podemos então utilizar esse padrão para resolver o jogo por indução reversa. No primeiro período, Serena oferece uma proposta que Martín aceita, tal que: \\[\\begin{aligned} x_1 = 1 - \\delta + \\delta^2 - \\delta^3 + \\ldots + \\delta^{T-1} \\\\ =&amp; (1 + \\delta^2 + \\delta^4 + \\ldots + \\delta^{T-1}) - (\\delta + \\delta^3 + \\delta^5 + \\ldots + \\delta^{T-2}) \\\\ =&amp; (\\delta^0 + \\delta^2 + \\delta^4 + \\ldots + \\delta^{T-1}) - (\\delta + \\delta^3 + \\delta^5 + \\ldots + \\delta^{T-2}) \\\\ =&amp; \\frac{1 - \\delta^{T+1}}{1-\\delta^2} - (\\frac{\\delta - \\delta^T}{1 - \\delta^2}) \\\\ =&amp; \\frac{1 + \\delta^T}{1+\\delta} \\end{aligned}\\] Em que usamos o fato de que a soma de uma P.G. finita é dada por \\(S_n = \\frac{a_1(1 - r^n)}{1-r}\\), em que \\(r\\) é a razão. E nossa soma é uma P.G. finita com primeiro termo \\(\\delta^0\\) e razão \\(r = \\delta^2\\) e \\(n=6\\). E similarmente para a segunda parte da soma. E os payoffs são: \\(u_1 = \\frac{1 + \\delta^T}{1+\\delta}\\) e \\(u_2 = \\frac{\\delta - \\delta^T}{1 + \\delta}\\). É fácil provar que o SPE é alcançado na primeira rodada, já que haveria desperdício de continuar o jogo. A intuição é que todos recebem o seu valor de continuação já na primeria rodada. 11.6 Infinitos períodos Com infinitos períodos, há múltiplos equilíbrios. Um equilíbrio de Nash, por exemplo, é um em que Serena nas rodadas ímpares sempre oferece \\(1\\) para si e \\(0\\) para Martín, e rejeita todas as ofertas feitas por ele nas rodadas pares exceto se receber \\(1\\). Já Martín, nas rodadas ímpares, sempre oferece \\(1\\) para Serena e \\(0\\) para si e aceita qualquer proposta de Serena nas rodadas pares. Esse par de estratégias encerra o jogo na rodada inicial e é um equilíbrio de Nash, pois ninguém pode melhorar sua situação, dado o que a outra jogadora está fazendo. Obviamente, não é equilíbrio de Nash Perfeito em Subjogos, pois a ameaça de Serena sempre rejeitar tudo que Martín oferecer não é crível, isto é, não é sequencialmente racional. E nós sabemos que sem racionalidade sequencial não há ENPS. De fato, se chegarmos no período 2, a estratégia de sempre rejeitar as ofertas de Martín implica que se ele não ofercer \\(1\\) para Serena, ela rejeitará a oferta e iremos para o período 3. Se por acaso ela obtiver \\(1\\) e o jogo acabar, esse payoff terá de ser descontado (em relação ao período 2) em \\(\\delta_1\\), de forma que se Martín, no período 2 oferecer um valor maior do que esse payoff descontado (mas menor que 1), naquele subjogo, Serena deveria aceitar essa oferta. Por isso que sua estratégia de sempre rejeitar qualquer coisa menor que \\(1\\) não é crível e, portanto, não constituir um ENPS. 11.6.1 Valor de Continuação O valor de continuação, definido mais genericamente, é o valor esperado de payoffs ou utilidades futuras, dado o estado atual e a adoção de estratégia ótima do ponto atual em diante. Em nosso contexto de berganha de Rubinstein, é o valor esperado que uma jogadora irá receber se um acordo não for fechado no período atual (jogando estratégia ótima, isto é, ENPS). Rubinstein (1982) provou que há um único ENPS: quando é chamado a jogar, a jogadora \\(i\\) propõe para si \\(\\frac{1 - \\delta_j}{1 - \\delta_i\\delta_j}\\) e para a outra jogadora \\(\\frac{\\delta_j(1 - \\delta_i)}{1 - \\delta_i\\delta_j}\\). E a jogadora \\(j\\) aceita qualquer proposta maior ou igual a essa. Se as taxas de descontos forem iguais \\(\\delta_i = \\delta_j = \\delta\\), isso simplifica para: o proponente demanda \\(\\frac{1}{1+\\delta}\\) e o respondente aceita oferta de no mínimo $. O proponente obtém mais que o respondente (first mover advantage). À medida que a paciência se aproxima de 1, a divisão tende a ficar igualitária. Prova de existência: Proponente não pode obter mais do que \\(\\frac{1}{1 + \\delta}\\) no presente, e esperar é pior. Se respondente rejeita, na melhor das hipóteses obtém \\(\\frac{1}{1 + \\delta}\\) no período seguinte, quando será proponente. Dado o desconto de \\(\\delta\\), seu valor de continuação é \\(\\frac{1}{1+\\delta}\\), ou seja, é o mínimo que tem de obter no presente. Prova de unicidade do ENPS. Antes, vamoa explicar os conceitos de supremo e ínfimo. Se um máximo existir, então ele é um supremo. Se um mínimo existir, então ele é um ínfimo. Considere o conjunto dos números reais maiores que zero e menores que 1. Não existe mínimo nem máximo. Porém, existem ínfimos e supremos. \\(0\\) é o ínfimo, e \\(1\\) é o supremo. Sejam \\(M\\) e \\(m\\) supremo e ínfimo do valor de continuação de um respondente, respectivamente. Um proponente pode obter pelo menos 1 - M. Portanto \\(m \\geq \\delta(1-M)\\). Um proponente não pode obter mais \\(1-m\\), portanto \\(M \\leq \\delta(1-m)\\) Combinando as desigualdades, temos: \\(m \\geq \\delta(1 - \\delta + \\delta m)\\) ou \\(m \\geq \\frac{\\delta}{1+\\delta}\\). O passo 4 decorre de: \\[\\begin{aligned} M \\leq \\delta(1-m) \\\\ \\text{subtraindo ambos os lados de 1, obtemos:} \\\\ M -1 \\leq \\delta(1-m) -1 \\\\ \\text{multiplicando ambos os lados por -1, obtemos:} \\\\ 1 - M \\geq 1 - \\delta(1-m) = 1 - \\delta - \\delta m\\\\ \\text{sabemos que } m \\geq \\delta(1-M) \\\\ m \\geq \\delta(1-M) \\geq \\delta (1 - \\delta - \\delta m) \\\\ m \\geq \\delta (1 - \\delta - \\delta m) = \\delta(1 - \\delta) + \\delta^2 m \\\\ m - \\delta^2 m \\geq \\delta(1 - \\delta) \\\\ m(1 - \\delta^2) \\geq \\delta(1 - \\delta) \\\\ \\text{ observe que } 1 - \\delta^2 = (1 - \\delta)(1 + \\delta) \\text{ e divida os dois lados por } (1 - \\delta) \\\\ m(1 + \\delta) \\geq \\delta \\\\ m\\geq \\frac{\\delta}{(1 + \\delta)} \\end{aligned}\\] De maneira similar, \\(M \\leq \\frac{\\delta}{1 + \\delta}\\). Portanto, \\(m = M = \\frac{\\delta}{1 + \\delta}\\). Respondente obtém \\(\\frac{\\delta}{1 + \\delta}\\), proponente \\(\\frac{1}{1 + \\delta}\\). 11.7 Modelo de Baron Ferejohn de Bargana legislativa Em artigo de 1989 publicado na APSR, Baron e Ferejohn (BF daqui por diante) desenvolveram um modelo que se tornou canônico para pensar barganhas legislativas. Claramente inspirado no modelo de Rubinstein, adapta-o para o contexto do legislativo com regra da maioria para aprovação de uma proposta de divisão do bolo. O modelo de BF considera, como no caso de Rubinstein, como pode ser feita a distribuição de um recurso ou excedente, que é comumente referida como distribuição de um bolo de tamanho \\(1\\). E de maneira similar ao que fizemos no caso do Rubinstein, nossa exposição se iniciará com um jogo do ultimato legislativo (um período), depois depois períodos e por fim com horizonte infinito. 11.8 Ultimato Legislativo Considere uma legislatura com \\(n \\geq 3\\), com \\(n\\) ímpar (para facilitar desempate), indexe os legisladores em \\(i = 1, 2, \\ldots, n\\) que adota regra da maioria para deicisões legislativa (isto é, é necessário pelo menos \\(\\frac{n+1}{2}\\) votos). Uma regra de reconhecimento determina quem pode fazer uma proposta legislativa de distribuição do bolo entre os membros. Procurando modelar a ideia de que esse processo é imprevisível, os autores tratam esse fato como exógeno, por meio de uma distribuição de probabilidade, isto é, cada membrro \\(i\\) do legislativo possui uma probabilidade \\(p_i\\) de ser reconhecido como proponente, com \\(\\sum_{i=1}^n p_i = 1\\). A cada período \\(t = 1, 2, \\ldots\\), um legislador é reconhecido como proponente que faz uma proposta de distribuição do recurso \\(x^i = (x_1, x_2, \\ldots, x_n)\\), com \\(\\sum_{i=1}^n x_i = 1\\). Legisladores votam sequenciamente (em cada período, por porposta) sim ou não e se a proposta for aceita, o jogo termina com payoffs \\(\\delta^tx\\). Se a maioria rejeita, o jogo vai para a próxima rodada. Se o jogo termi Se a proposta é aceita, cada legislador recebe uma utilidade igual ao valor proposto para ele, isto é, \\(u_i = x_i\\). Se a proposta for rejeitada, ele recebe um status quo, dada por \\(\\underline{x} = (\\underline{x}_1, \\underline{x}_2, \\ldots, \\underline{x}_n)\\), em que \\(\\sum_{i=1}^n \\underline{x}_i &lt; 1\\), isto é, há menos recursos sendo distribuídos. Em particular, podemos considerar, como no modelo de Rubinstein, que \\(\\sum_{i=1}^n \\underline{x}_i = 0\\), ou seja, todos recebem zero. E denotamos por \\(V_i\\) a utilidade esperada em equilíbrio para cada legislador \\(i\\), ou seja, será o valor de continuação do jogo em modelos de mais de um período. 11.8.1 Estratégias fracamente dominadas Uma pressuposição comum em modelos de votação é a de que os votantes (sejam eleitores ou, como aqui, legisladores) jogam estratégias fracamente dominadas. Em um contexto de modelo de teorema do eleitor mediano com dois partidos, por exemplo, essa suposição implica que voto estratégico e sincero são equivalentes. Com voto sincero, eleitores sempre votam pelo partido com plataforma mais próxima do seu ponto ideal. A importância de excluir equilíbrio em que jogadores jogam estratégias fracamente dominadas fica claro com o seguinte exemplo. Imagine dois partidos com plataformas distintas. Se os eleitores não forem pivô, seu voto não importa e não muda o resultado. Isso significa que se todos os eleitores votarem por um dos partidos, nenhum deles é pivô e, portanto, não pode melhorar unilateralmente, constituindo portanto um equilíbrio de Nash. Para evitar esse tipo de resultado se eleitores são estratégicos (ao contrário de sinceros), temos de excluir a possibilidade de jogarem estratégias fracamente dominadas, isto é, eleitores votam como se fossem pivôs (ou, o que dá no mesmo, sinceramente). Baron e Ferejohn adotam suposição similar, ou seja, legisladores votam como se fossem pivô, de modo que eliminamos um equilíbrio em que todo mundo vota a favor de uma proposta em que o proponente ganha todo o bolo, pois nenhum é pivô e, portanto, não podem melhorar desviando unilateralmente, dado o que todos os demais estão fazendo. 11.8.2 Equilíbrio no ultimato legislativo Como o jogo possui apenas uma rodada, quem quer que seja escolhido pode propor o mínimo possível para obter \\(\\frac{n-1}{2}\\) votos, e fica com o restante pa si, formando assim uma mínima coalizão vencedora. Em outras palavras, basta oferecer \\(x_i = \\underline{x}_i\\) para os \\(\\frac{n-1}{2}\\) legisladores com os menores valores de \\(\\underline{x}\\). No caso particular em que \\(\\underline{x}_i = 0\\) para todo \\(i\\), o proponente toma todo o recurso para si e isso é um equilíbrio de Nash. 11.8.3 Exercício para o leitor. Considere uma legislatura com \\(n = 3\\) e \\(\\underline{x} = (.1, .2, .1)\\). Assuma igual probabilidade de reconhecimento. Calcule o \\(V_i\\) para as três legisladoras, a partir da utilidade esperada em cada cenário em que \\(1\\), \\(2\\) ou \\(3\\) seja reconhecida. No caso de \\(2\\), assuma que ela faz coalizão com \\(1\\) com probabilidade \\(.5\\), e coalizão com \\(3\\) com probabilidade \\(.5\\) (isto é, joga uma estratégia mista). Verifique que as utilidades são uma função das características de todas as legisladores (\\(_pi\\) e \\(\\underline{x}\\)). 11.9 Modelo de dois períodos Agora vamos estender o modelo para dois períodos. Se uma proposta não for aprovada no primeiro período, uma nova pessoa é sorteada (possivelmente a mesma de antes) para ser a proponente no segundo período, de acordo com as mesmas probabilidades de antes. Legisladoras descontam o futuro por \\(\\delta_i\\), e de maneira simplifcada, \\(\\delta_i = \\delta\\). Se nenhuma política for aprovada ao final do segundo período, recebem o status quo \\(\\underline{x} = (\\underline{x}_1, \\underline{x}_2, \\ldots, \\underline{x}_n)\\), em particular \\(x_i = 0\\) para todo \\(i\\). E denotamos por \\(V_{it}\\) o valor de continuação do jogo no período \\(t\\), isto é, a utilidade esperada em equilíbrio. Utilizando indução reversa, como na barganha de Rubinstein, verificamos que no segundo período temos o jogo do ultimato legislativo e a proponente obtém tudo para si. No primeiro período, se a proposta não for aprovada, e antes de alguém ser escolhida para fazer nova proposta, a utilidade esperada \\(V_{it} = \\delta/n\\) para todas as legisladores. Logo, no período 1, a proponente precisa oferecer apenas \\(\\delta/n\\) para \\(\\frac{n-1}{2}\\) legisladoras e retém \\(1 - \\frac{(n-1)}{2}\\frac{\\delta}{n} &gt; \\frac{1}{2}\\). E qual a utilidade esperada no período \\(1\\), isto é, \\(V_{i1}\\)? Assumindo que todas as legisladores podem ser escolhidas para fazer parte da coalizão vencedora com igual probabilidade, então o valor de continuação no período 1 é o ganho se for reconhecida como proponente (com probabilidade \\(1/n\\)) mais o ganho se fizer parte da coalizão vencedora (com probabilidade \\(1/2\\) e com probabilidade \\(\\frac{(n-1)}{n}\\) de não ser proponente, isto é, probabilidade conjunta \\(\\frac{(n-1)}{n} \\frac{1}{2}\\)): \\(V_{i1} = \\frac{1}{n}[1 - \\frac{(n-1)}{2}\\frac{\\delta}{n}] + \\frac{(n-1)}{n} \\frac{1}{2} \\frac{\\delta}{n} = \\frac{1}{n}\\). Portanto, a utilidade esperada é a mesma do jogo do ultimato, o que se estende a todos os jogos finitos com número arbitrários de períodos. Esse resultado é diferente da barganha de Rubinstein, e a razão é que lá as proponentes são alternadas, e aqui, em cada período, todas têm a mesma probabilidade de propor. 11.10 Horizonte infinito No modelo de horizonte infinito, o jogo continua indefinidamente enquanto uma proposta não for aprovada. BF adotam um refinamento no conceito de equilíbrio em relação ao já tradicional Equilíbrio de Nash Perfeito em Subjogos, pois há múltiplos equilíbrios. Então supõem que estratégias são estacionárias, obtendo assim Equilíbrio de Nash Perfeito em Subjogos Estacionário. 11.10.1 Equilíbrio Estacionário O conceito de equilíbrio usado é o Nash Perfeito Estacionário em Subjogos (abreviado, em inglês, para SSPE de stationary subgame perfect equilibrium). Em um equilíbrio estacionário, um legislador que é reconhecido como proponente em deois períodos diferentes faz sempre a mesma proposta em ambos os períodos. Portanto, equilíbrios estacionários são independentes da história. Vamos considerar o seguinte exemplo para capturar a ideia de estacionariedade. Digamos que trabalho no quinto andar de um prédio e meu médico recomenda que devo subir pelo menos um andar de escadas todos os dias. Então adoto a seguinte estratégia: “Sempre que eu estiver um andar abaixo da minha sala, pego as escadas. Para qualquer outro andar, pego elevador”. Essa estratégia é estacionária porque, não importa quantos andares eu andei anteriormente, apenas o andar que estou agora. Além disso, é sempre a mesma estratégia. A gente diz que processos estacionários são sem memória. 11.10.2 Equilíbrio do jogo infinito Falar que é o mesmo equilíbrio do jogo finito. 11.11 A suposição de imprevisibilidade Ali-Bernheim-Fan (2018) estudam o papel da suposição de que o proponente é imprevisível. Em legislaturas, quem pode fazer propostas ao orçamento não é exatamente imprevisível. No Brasil, apenas o executivo pode propor o orçamento, os legisladores podem emendar. Antes do orçamento secreto, o poder de emendas era bem limitado (limitado a certos valores). Qual a previsão do modelo com relação a isso? Com o orçamento secreto, o relator orçamentário passa a ser muito importante. Quem pode ser escolhido como relator? É imprevisível? Ou existe previsibilidade? O paper de Ali-Bernheim-Fan ajuda a iluminar exatamente esse ponto. Nós já vimos que o modelo do jogo orinal de BF, existem m[ultiplos SPE. Se mantivermos esse conceito, então previsibilidade não importa. Resultado anterior se mantem. Podemos aplicar a mesma prova de antes se, por exemplo, há rotação em que irá ser o proponente. Os autores então se concentram em equilíbrio Markoviano perfeito (MPE). Aqui, isso quer dizer que jogadoras adotam a mesma estratégia em conjuntos de informação indistinguíveis. Então, previsibilidade importa (e muito): Teorema: Suponha que em cada período há uma maioria de legisladores que todo mundo sabe que não serão o próximo proponente. Então, em todo MPE o proponente obtém todo o bolo para si. A intuição é que não é suficiente que todo mundo possa proporar com a mesma frequência (exemplo, rotação). É preciso também imprevisibilidade, para que proponente não possa mirar legisladores mais fracos. Suppose that in each period there is a majority of voters who are certain not to be the next proposer. Then in every MPE the current proposer gets the entire surplus. These authors focus on ìMPEî(same strategies in indistinguishable information sets). Now predictability matters a lot: 11.12 Aplicações 11.12.1 Formação de governos parlamentaristas Considere três partidos, A, B e C, em que A obteve \\(45\\%\\) das cadeiras, B obteve \\(35\\%\\) e C \\(20\\%\\). Qual o valor de continuação do jogo de cada partido? 11.13 Take away O poder de propor ou controlar a agenda é uma dimensão importante do poder. Podemos definir a quantidade de poder de um agente como a quantidade de recursos de um bolo de tamanho \\(1\\) que esse agente espera obter em equilíbrio. Vemos que no modelo de BF, a proponente obtém mais de 50% do bolo, enquanto as demais esperam obter \\(\\delta/n\\). Em um parlamento com \\(101\\) legisladoras, por exemplo, e considerando \\(\\delta = 1\\), isso significa \\(1\\%\\). Então a proponente é 50x mais poderosa. 11.14 Exercícios Exercise 11.1 Serena e Martín utilizam o seguinte procedimento para dividir um bolo. Serena corta o bolo em dois pedaços, Martín pega primeiro um dos pedaços e Serena o restante. Suponha, para simplicar, qaue o bolo é continuamente divisível, o bolo é cortado perfeitamente (sem pedaços que sobram) e Martín e Serena gostam igualmente de todas as partes do bolo. Suponha que o bolo é perfeitamente homogêneo, de modo que Serena e Martín se importam apenas com o tamanho do pedaço do bolo que pegam. Explique como o bolo é dividido em um equilíbrio perfeito de subjogo. Discuta se a divisão do bolo é pareto eficiente ou não. Exercise 11.2 Em um jogo de barganha, a compradora move primeiro, oferecendo $500 ou $100 por um produto que ela valoriza em $600. O vendedor, cujo valor do produto é $50, responde aceitando (A) ou rejeitando (R) a oferta. Se o vendedor aceita, a compradora paga o valor oferecido e recebe o produto. Se o vendedor rejeita, nenhuma transação ocorre e ambos ficam com seus valores iniciais (a compradora sem o bem e sem gastar nada; o vendedor com o bem no valor de $50). Desenhe a árvore do jogo (forma extensiva) representando esse jogo de barganha. Resolva o jogo utilizando indução reversa para encontrar o equilíbrio perfeito em subjogos (SPNE). Exercise 11.3 Serena e Martín pessoas se revezam removendo pedras de um monte de n pedras. Serena começa jogando, e Martín joga depois. Eles se alternam a cada jogada. Em cada turno, cada um pode remover uma ou duas pedras. Quem retirar a última pedra vence e recebe 1 real de sua oponente. Encontre os equilíbrios perfeitos em subjogos dos jogos que modelam essa situação para n = 1 e n = 2. Determine a vencedora em cada equilíbrio perfeito em subjogos para n = 3, usando o fato de que o sub-jogo após a Serena remover uma pedra é o jogo para n = 2 em que a Martín é o primeira a jogar, e que o sub-jogo após Serena remover duas pedras é o jogo para n = 1 em que Martín é o primeira a mover. Use a mesma técnica para encontrar a vencedora em cada equilíbrio perfeito em subjogos para n = 4 e, se possível, para um valor arbitrário de n. Exercise 11.4 Três membros de um comitê (Jogadores 1, 2 e 3) devem escolher um (e apenas um) candidato de uma lista com quatro nomes \\(\\{A, B, C, D\\}\\) para preencher uma vaga. As preferências ordinais estritas dos membros do comitê (na ordem 1, 2 e 3) sobre esses quatro candidatos são as seguintes: \\(C \\succ B \\succ D \\succ A\\) \\(B \\succ C \\succ A \\succ D\\) \\(A \\succ B \\succ C \\succ D\\) onde \\(X \\succ Y\\) significa que o membro do comitê prefere estritamente o candidato \\(X\\) ao candidato \\(Y\\). O comitê acordou utilizar o procedimento de veto sucessivo para selecionar o candidato. Funciona assim: Primeiro, o membro 1 tem o direito de vetar (ou seja, eliminar) um dos candidatos da lista. Em seguida, o membro 2 veta um dos candidatos restantes. Por fim, o membro 3 veta um dos dois candidatos que sobraram. O candidato que não for vetado ao final do processo é o selecionado para ocupar a vaga. Desenhe a forma extensiva (árvore) desse jogo e encontre todos os equilíbrios perfeitos em subjogos (SPNE), assumindo que o jogo possui informação perfeita. Como mudaria o conjunto de equilíbrios perfeitos em subjogos (SPNE) se a ordem de jogo fosse: primeiro o membro 1, depois o membro 3 e, por fim, o membro 2? Encontre um equilíbrio de Nash em estratégias puras do jogo no item (a) que tenha como resultado final a seleção do candidato \\(B\\) (este item é opcional, no sentido que de não será um item da prova, embora os itens anteriores possam vir a ser). Exercise 11.5 Os exércitos I e II estão lutando pelo controle de uma ilha, que está inicialmente ocupada por um batalhão do exército II. O exército I possui 3 batalhões e o exército II possui 4 batalhões, incluindo o batalhão que já ocupa a ilha. Sempre que a ilha está ocupada por um dos exércitos, o exército adversário pode escolher lançar um ataque utilizando todos os seus batalhões disponíveis. O resultado de um ataque é o seguinte: - O exército com mais batalhões vence, passa a ocupar a ilha e mantém nela um número de batalhões igual à diferença entre o número de batalhões atacantes e defensores. - O exército derrotado perde todos os seus batalhões envolvidos no combate. Se ambos os exércitos tiverem o mesmo número de batalhões, o ataque fracassa e a ilha permanece com o exército defensor. Cada comandante deseja: - Maximizar o número de seus batalhões sobreviventes e controlar a ilha, que vale o equivalente a 1,5 batalhões Desenhe a árvore do jogo (forma extensiva) que representa esse conflito. Resolva o jogo utilizando indução reversa para encontrar o equilíbrio perfeito em subjogos (SPNE). figura retirada do livro do Tadellis, p. 222↩︎ "],["jogos-bayesianos.html", "Capítulo12 Jogos Bayesianos 12.1 Introdução 12.2 Exemplo inicial 12.3 Jogo Bayesiano: Incumbente Democrata ou Golpista 12.4 Jogo da coordenação Bayesiano 12.5 Cumplicidade ou duplicidade 12.6 Referências 12.7 Exercícios", " Capítulo12 Jogos Bayesianos 12.1 Introdução Nós iremos analisar agora os chamados jogos Bayesianos, às vezes também chamados de jogos com informação incompleta. Até o momento nós lidamos com jogos em que os agentes possuem informação completa ou crenças comuns sobre movimentos da natureza, por exemplo. É comum que os agentes saibam mais sobre si mesmo do que dos demais. Políticos sabem suas preferências mais que eleitores, grupos de interesse mais sobre seus setores do que políticos e burocratas, líderes políticos mais sobre sua decisão de ir à guerra do que outros estados. Essas são situações em que temos assimetria de informação. Em certo sentido, jogos simultâneos representam situações em que que os jogadores não sabem o que os demais escolhem, e devem fazer conjecturas sobre as escolhas dos outros, e elas devem ser mutuamente consistente para que possamos achar o equilíbrio do jogo. John Harsany foi possivelmente o primeiro a perceber a similaridade entre crenças sobre ações e crenças sobre preferências ou quem são os jogadores. Harsany, que viria a ganhar o prêmio Nobel de economia juntamente com Nash e Selten (que desenvolveu a noção de subjogo perfeito), desenvolvou uma forma elegante de pensar sobre as crenças que podemos formar sobre as características dos jogadores, o que iremos chamar de tipos dos jogadores. E nós chamamos jogos em que jogadores podem ser de diferentes tipos de jogos de informação incompleta. Vale destacar que nós consideramos que a incerteza ou assitemria de informação é sempre sobre os payoffs. Isso porque assimetria sobre estratégias sempre podem ser convertidas em assimetria de informação sobre payoffs. Digamos que não sabemos se o conjunto de estratégias disponíveis para a jogadora 1 é \\(\\{A,B\\}\\) ou \\(\\{A, B, C\\}\\). Nesse caso, podemos dizer que tempos dois tipos de jogadoras, uma em que \\(C\\) é uma estratégia estritamente dominada por \\(A\\) e \\(B\\) (e portanto nunca é jogada), ou um tipo em que \\(C\\) não é estritamente dominada e deve ser considerada como uma opção. Anteriomente, nós tínhamos três informações básicas para estruturar um jogo estático simultâneo de informação completa: Jogadoras Estratégias Payoffs/Preferências/Utilidades Agora, vamos precisar complexificar a estrutura 1 sobre as jogadoras. Diremos que as jogadoras possuem tipos, e precisamos ter crenças a priori sobre os tipos das jogadoras. Então, nosso jogo de informação incompleta é descrito por: Jogadoras 1.1 Tipos 1.2 Crenças (comuns) a priori sobre os tipos Estratégias Payoffs/Preferências/Utilidades 12.2 Exemplo inicial Nos tempos atuais, parece-mais do que apropriado introduzir a ideia de informação incompleta por meio de um jogo em um regime político democrático em que o líder poder ser do tipo golpista ou democrático. Considere dois partidos, incumbente e oposição. O incumbente pode ser um golpista, alguém que não aceitará transição pacífica caso perca eleição, ou um democrata, alguém que aceitará a transição pacífica de poder. A oposição pode escolher entre fazer oposição regular (business as usual) ou bloquear tudo (não-cooperar). Similarmente, o incumbente pode governar normalmente (business as usual) ou tentar acabar com a possibilidade de eleições livres (não cooperar). 12.3 Jogo Bayesiano: Incumbente Democrata ou Golpista Matriz de payoff - Incumbente Democrata ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;format&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) C (Cooperar) NC (Não Cooperar) C (Cooperar) (2,3) (2,3) NC (Não Cooperar) (3,2) (1,1) Matriz de payoff - Incumbente Golpista ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) C (Cooperar) NC (Não Cooperar) C (Cooperar) (2,3) (2,3) NC (Não Cooperar) (3,1) (1,2) 12.4 Jogo da coordenação Bayesiano Vamos retomar o jogo da coordenação. Porém, há incerteza se a jogadora é uma boa amiga ou má amiga. Se ela é uma boa amiga, prefere ir para os mesmo concerto (Bash ou Stravinski) que a amiga, a ficar sozinha. Já uma má amiga prefere ir pra seu show preferido a ficar sozinha. Digamos que a incerteza é apenas sobre a jogadora 2. A jogadora 1 é uma boa amiga sem dúvida. Dizemos nesse caso que temos um jogo de informação incompleta de um lado somente. Temos então, no fundo, dois jogos possíveis, um em que a jogadora 1 está diante de uma boa amiga, e outro em que joga com uma má amiga. O primeiro jgoo é como antes: ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;format&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) Bach Stravinski Bach (2,1) (0,0) Stravinski (0,0) (1,2) O segundo jogo (da amiga má) fica: ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;format&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) Bach Stravinski Bach (2,0) (0,2) Stravinski (0,1) (1,0) Veja que nós construimos os payoffs/utilidades para indicar que a amiga má prefere ficar sozinha a ficar com a amiga. 12.4.1 Exemplo Um exemplo pode ser útil. loren ipson 12.4.2 Aplicação - votação em um júri Uma das aplicações clássicas de jogos Bayesianos é a de votação de um júri, desenvolvido no trabalho de Feddersen e Pesendorfer (1998). Neste artigo eles mostram que a regra da unanimidade (em que é necessário unanimidade para condenar um acusado) pode mais prejudicar do que ajuda pessoas que estao em julgamento, quando comparada com regra da maioria. Para entender o modelo e seus resultados, vamos começar supondo que o júri é formado por uma única pessoa, já que este é o caso mais simples. A única jurada deve decidir se sentencia à reclusão ou absolve um réu acusado de um crime, ou seja, decide o resultado \\(x \\in \\{a,s\\}\\). A jurada não sabem se o acusado é Culpado ou Inocente. Portanto, o conjunto de estado das variáveis é \\(\\Omega \\in \\{C,I\\}\\). A jurada atribui probabilidade a priori \\(\\pi\\) ao estado \\(C\\), ou seja, acredita a priori que a probabilidade do réu ser culpado é \\(\\pi\\). Por fim, se condenar uma pessoa culpada ou absolver um inocente, recebem \\(0\\) de utilidade. De outro lado, se prender um inocente obtem \\(-q\\) e se absolver um culpado recebem \\(-(1-q)\\) de utilidade, em que \\(q \\in (0,1)\\). A ideia é que \\(q\\) representa o nível de “dúvida razoável” da jurada para condenar. Se ela acha que para condenar alguém deve ter \\(80/%\\) de certeza, então \\(q=.8\\) e se ela condenar um inocente obtém um payoff de \\(-.8\\) e se absolver um culpado o payoff é \\(-(1-.8) = -0.2\\). Ou seja, se o nível de dúvida razoável é maior que \\(.5\\), isso significa que é pior condenar um inocente do que absolver um culpado. Se \\(q=.5\\), a jurada vê como igualmente ruim errar condenando um inocente ou absolvendo um culpado. Dada a probabilidade a priori, podemos calcular a utilidade esperada da jurada sem novas informações adicionais. \\(\\mathbb{E}[U_i(\\text{veredito de culpado})] = 0\\pi + -q(1-\\pi) = -q + q\\pi\\) e \\(\\mathbb{E}[U_i(\\text{veredito de inocente})] = -(1-q)\\pi + 0(1-\\pi) = -\\pi + q\\pi\\). Queremos saber se \\(-q + q\\pi &gt; -1 + q\\pi\\) e, portanto, a jurada deve condenar ou não. \\(-q + q\\pi &gt; -\\pi + q\\pi = -q &gt; -pi = q &lt; \\pi\\) Ou seja, se a probabilidade a priori do réu ser culpado é maior do que o ponto de corte de dúvida razoável, deve condenar. Se não, deve absolver. Agora, vamos supor que ela observa um sinal correlacionado com o verdadeiro estado mundo, isto é, um sinal informativo. Pode ser alguma evidência da defesa ou da acusação. Para simplificar, vamos supor que apenas um único sinal é observado. Essa informação é um sinal binário sobre a culpabilidade do réu \\(\\theta_i \\in \\{0,1\\}\\), e por sinal informativo queremos dizer que é mais provável receber um sinal \\(\\theta_i = 1\\) quando o réu é culpado do que quando o réu é inocente e vice-versa. Vamos supor que \\(Pr(\\theta_i = 1|\\omega = C) = Pr(\\theta_i = 0|\\omega = I) = p &gt; 1/2\\). Disso se segue que \\(Pr(\\theta_i = 1|\\omega = I) = Pr(\\theta_i = 0|\\omega = C) = 1- p\\). Suponha inicialmente que o singal foi \\(1\\), isto é, de que o réu é culpado. A probabilidade a posteriori pode ser calculada usando o teorema de Bayes: \\[Pr(C|1) = \\frac{Pr(C)Pr(1|C)}{Pr(1)} = \\frac{\\pi p}{Pr(C)Pr(1|C) + Pr(I)Pr(1|I)} = \\frac{\\pi p}{\\pi p + (1-\\pi)(1-p)}\\] De maneira similar, podemos computar a probabilidade a posteri após observar um sinal de inocëncia: \\[Pr(I|1) = \\frac{Pr(I)Pr(1|I)}{Pr(1)} = \\frac{\\ (1-\\pi)(1-p)}{(1-\\pi)(1-p) + \\pi p}\\] \\(1-\\pi &lt; .5\\) e \\(q\\pi &lt; .25\\) e a utilidade esperada de condenar é \\(&lt; -.25\\). Por raciocínio análogo, a utilidade esperada de absolver é Ou seja, têm mais a ganhar condenando do que absolvendo. Vejam que a estratégia de escolher votar pela absolvição \\(a\\) é fracamente dominada por sentença \\(S\\). Se escolhermos eliminar estratégias fracamente dominadas, o que sobra é o equilíbrio de Nash em que todos condenam. Podemos agora computar as utilidades esperadas de setenciamento e absolvição. \\[\\mathbb{E}[U_i(\\text{veredito de culpado})] = 0Pr(C|1) + -q(1-Pr(I|1)) = -q\\frac{\\ (1-\\pi)(1-p)}{(1-\\pi)(1-p) + \\pi p}\\] \\[\\mathbb{E}[U_i(\\text{Inocente})] =-(1-q)Pr(C|1) + 0(1-Pr(I|1)) = -(1-q)\\frac{\\pi p}{\\pi p + (1-\\pi)(1-p)}\\] A jurada prefere condenar quando \\(-q\\frac{\\ (1-\\pi)(1-p)}{(1-\\pi)(1-p) + \\pi p} &gt; -(1-q)\\frac{\\pi p}{\\pi p + (1-\\pi)(1-p)}\\). Rearranjando, temos: \\(q &lt; \\frac{\\ (1-\\pi)(1-p)}{(1-\\pi)(1-p) + \\pi p}\\), ou seja, \\(q &lt; Pr(C|1)\\). Em palavras: como anteriormente, a jurada prefere condenar se probabilidade (a posteriori) de o réu ser culpado for maior do que o nível de “dúvida razoável”. Note também que se \\(\\pi = .5\\), isto é, a probabilidade a priori da culpabilidade do réu é de \\(50\\%\\), então \\(Pr(C|1) = p\\), a probabilidade de observar um sinal de culpado, dado que é culpado. Se fizermos raciocínio smilar para o caso dela observar um sinal de inocente, podemos calcular qual o valor de \\(q\\) que torna preferível absolver o réu, e isso é dado por: \\(q &gt; \\frac{\\pi(1-p)}{(1-\\pi) p + \\pi(1-p)}\\). Novamente, supondo que \\(\\pi = .5\\), podemos simplificar e concluir que ela votará pela absolvição sempre que \\(q &gt; 1- p\\). Juntanto o que concluímos antes, temos que a jurada votará com seu sinal sempre que \\(1 - p &lt; q &lt; p\\). Se \\(q = .5\\), como o sinal é informativo \\(p &gt; .5\\), então ela sempre votará com seu sinal. Dizemos que se ela vota de acordo com seu sinal, sua votação é informativa. 12.4.3 Votando contra seu sinal O que acontece se tivermos \\(n\\) juradas? Suponha agora que a promotoria e dedefesa apresentam informações sobre o verdadeiro estado da natureza (se o réu é culpado ou inocente). Aqui, vamos trabalhar com apenas uma informação sendo apresentada para cada jurado. A ideia é que cada jurado possui alguma expertise que o permite avaliar com mais qualidade uma das informações recebidas e as demais eles descartam. Em temros de teoria dos jogos, dizemos que cada jurado recebe uma informação privada. Essa informação é um sinal binário sobre a culpabilidade do réu \\(\\theta_i \\in \\{0,1\\}\\), correlacionado com a verdade, ou seja, o sinal é informativo, de tal forma que uma jurada é mais provável de receber um sinal \\(\\theta_i = 1\\) quando o réu é culpado do que quando o réu é inocente. Vamos supor que \\(Pr(\\theta_i = 1|\\omega = C) = Pr(\\theta_i = 0|\\omega = I) = p &gt; 1/2\\). Disso se segue que \\(Pr(\\theta_i = 1|\\omega = I) = Pr(\\theta_i = 0|\\omega = C) = 1- p\\). Após receber seu sinal privado, a jurada seleciona seu voto \\(v(\\theta_i)\\) de forma a maximizar a probabilidade da decisão correta. Se todas as juradas adotarem comportamento sincero, isto é, \\(v_i(1) = s\\) e \\(v_i(0) = a\\). Vamos aqui trabalhar com uma versão simplificada. Suponha que haja três jurados, ou seja, três jogadores \\(N = \\{1,2,3\\}\\), que são responsáveis por. 12.5 Cumplicidade ou duplicidade Quando estamos lidando com tipos de agentes ou jogadoras, em geral não conseguimos fazer distinção entre cumplicidade e duplicidade. Quando alguém colabora com um regime político odioso, pode fazê-lo com cumplicidade ou duplicidade. No primeiro caso, racionaliza para sim mesmo suas ações, cometendo uma espécie de auto-engano. Diz, por exemplo “o regime é horrível, mas é melhor eu atuar por dentro do que por fora, para o bem comum”. Já no segundo caso, a duplicidade tem a ver com ser “duas caras”, ou seja, um esforço deliberado para esconder suas reais motivações. 12.6 Referências Feddersen, T., &amp; Pesendorfer, W. (1998). Convicting the innocent: The inferiority of unanimous jury verdicts under strategic voting. American Political science review, 92(1), 23-35. 12.7 Exercícios Exercise 12.1 Considere o jogo do chicken em que, se ambos desviam, ganham um payoff de \\(0\\), se um desvia e o outro não, quem desvia ganha zeor, e quem não desvia ganha \\(R\\)m, de respeito dos pares, e se ambos não desviam, dividem o respeito da “galera”, R, e soferem perda \\(k\\), ou seja gaham um payoff \\(\\frac{R}{2} - k\\). Podemos pensar que \\(k\\) é a punição por um acidente pelos pais, e o valor de \\(k\\) depende se os pais são duros (H) ou lenientes (L). Se os pais são do tipo \\(H\\), então \\(k=H\\), e se são do tipo \\(L\\), \\(h = L\\). Escreva as duas matrizes de payoff, supondo que \\(R=8\\), \\(H=16\\) e \\(L=0\\). Ache o equilíbrio de Nash em estratégias puras (se existir) de cada matriz de payoff. Suponha que as probabilidade dos pais serem do tipo \\(H\\) ou \\(L\\) é 50% para ambos os adolescentes, e independentes entre si. Um influencer, que sabe um pouco de teoria dos jogos, decide usar esse modelo para dizer que mover uma sociedade em que todos os pais são lenientes terão efeitos negativos sobre o comportamento de adolescentes. Faça uma análise de equilíbrio para verficiar se é possível justificar essa afirmação do influencer? E se \\(H=0\\) e \\(L=8\\)? Exercise 12.2 Conflito armado: Considere a seguinte situação estratégia: dois países rivais planejam disputar um território. Cada país pode escolher atacar (A) ou não atacar (N). Além disso, cada país pode ter um exército poderoso (P) ou fraco (F) com igual probabilidade, e independente de cada exército. Cada país sabe o próprio tipo de exército. Um exército pode capturar um território se ele ataca e o rival não ou seu rival ataque, mas é um rival do tipo fraco e seu país é poderoso. Se ambos atacarem e forem de igual força, ninguém capturar o território. O território vale \\(m\\) se conquistado e cada exércio tem um custo iagual a \\(p\\) se é poderosos e \\(f\\) se é fraco, em que \\(p &lt; f\\). Se um exército ataca e o rival não, nenhum custo é incorrido por ambos os lados. Escreva o jogo na forma normal. Identifique todos os equilíbrios de Nash Bayesianos em estratégias puras para este jogo se \\(m=3\\), \\(f=2\\) e \\(p=1\\). E se \\(m=3\\), \\(f=4\\) e \\(p=2\\). Exercise 12.3 Considere o jogo do júri em que \\(p = \\frac{3}{4}\\) e \\(\\pi = \\fra{2}{3}\\). Suponha que \\(n\\) = 2. Caracterize o conjunto de equilíbrios de Nash Bayesianos do jogo. Suponha que \\(n &gt;2\\). Considere também que, em vez da regra da maioria, nós utilizamos unanimidade (se todos votam por condenar, o réu é condenado, se pelo menos um jurado vota por absolver, o réu é absolvido). Caracterize o equilíbrio de Nash Bayeriano do jogo. Exercise 12.4 Descreva o que é demandado dos jogadores em termos de racionalidade nos conceito de: Equilíbrio de estratégia estritamente dominante, equlíbrio de Eliminação Iterativa de Estratégia Estritamente Dominada, Equilíbrio de Nash em estratégias puras, Equilíbrio de Nash Perfeito de Subjogo (em estratégias puras) e Equilíbrio de Nash Bayesiano. Discuta o que se ganha e o que se perde quando movemos de um conceito de equilíbrio pouco demandante para um altamente demendante em termos de racionalidade. Em particular, discuta a questão do realismo dos pressupostos e assertividade das previsões da teoria. Exercise 12.5 Considere que uma empresa quer montar um painel para um evento com duas palestrantes. Ela pode escolher entre a palestrante A, B ou C (ou seja, escolher duas de três). Cada palestrante pode falar bem, neutro ou mal do produto X da empresa. Cada palestrante que falar bem gera utilidade de 1, 0 se fizer fala neutra e -1 se falar mal. Suponha que as probabiliades de cada palestrante falar bem, neutro ou mal são dadas pela tabela abaixo. Qual deve ser a composição do painel? "],["tópicos-especiais.html", "Capítulo13 Tópicos Especiais 13.1 Introdução 13.2 Discriminação 13.3 Taste-Based Discrimination 13.4 Discriminação estatística 13.5 Equilíbrio da discriminação estatística 13.6 Críticas 13.7 Discriminação institucional/sistêmica 13.8 Derivação do modelo de Phelps.", " Capítulo13 Tópicos Especiais 13.1 Introdução Vamos discutir aqui modelos formais de discriminação (usualmente racial, mas poderiam ser igualmente aplicados a discriminação de gênero ou outras características) que surgiram na economia ao longos dos últimos 50 anos. Gerard et. al. (2021). 13.2 Discriminação Como a literatura de economia tem definido Discriminação? Arrow (1973) argumenta do seguinte modo (tradução do GPT): “O fato de que diferentes grupos de trabalhadores, sejam eles qualificados ou não qualificados, negros ou brancos, homens ou mulheres, recebam salários diferentes convida à explicação de que os diferentes grupos devem diferir de acordo com alguma característica valorizada no mercado. Na teoria econômica padrão, pensamos primeiro nas diferenças de produtividade. A noção de discriminação envolve o conceito adicional de que características pessoais do trabalhador, não relacionadas à produtividade, também são valorizadas no mercado.” Essa definição é reconhecidamente problemática. Eis algunas problemas: Ela pressupõe que é possível distinguir a produtividade das características pessoais. Porém, se no mundo da publicidade o consumidor valoriza mais atores brancos que negros (homens versus mulheres etc.), brancos geram mais valor que negros e, portanto, a produtividade está associada à raça. A tecnologia, que impacta a produtividade, não é neutra. Fotografias de pessoas brancas historicamente possuiam melhor qualidade, pois foram historicamente calibradas para tons de pele mais claros. Por muitos anos, os padrões de calibração de filmes fotográficos e câmeras de vídeo foram baseados em modelos de referência com pele clara, conhecidos como “Shirley cards”. Nesse caso, a qualidade de filmes com atores brancos seria melhor do que com atores negros, e portanto, brancos seriam mais “produtivos” por causa da tecnologia. Outro exemplo é a iluminação. Para tons de pele mais escuros, a luz precisa ser controlada cuidadosamente para evitar sombras excessivas que podem ocultar detalhes faciais. Se o técnico que cuida disso não souber fazer os ajustes necessários, novamente a produtividade dos artistas negros será menor. 13.3 Taste-Based Discrimination O prêmio nobel de Economia Gary Becker apresentou o primeiro modelo canônico de discriminação racial (1957). Nesse modelo, a discriminação ocorre porque empresas comandadas por pessoas brancas têm preferências por contratar pessoas brancas versus pessoas negras. Ou seja, por preconceito pessoal delas. Então, ao contratar pessoas negrar isso gera uma “desutilidade” ou utilidade negativa para o contratante, de forma que, a pesar de igualmente produtivo a uma pessoa branca, o contratante paga salário menor por causa dessa disutilidade ou para receber o mesmo salário deve ser mais produtivo. Para que haja um diferencial de salários em equilíbrio no mercado, é preciso que haha um número suficientemente grande de empresas discriminatórias. A razão é que se o número for pequeno, trabalhadores negros iriam acabar trabalhando só em firmas que não discriminam, ganhando um salário igual aos brancos, e as firmas discriminadoras contratariam apenas brancos, e não haveria diferencial de salários em equilíbrio. Se houver um número grande de empresas discriminadoras, então trablhadores negros iriam primeiro buscar emprego nas empresas não-discriminadoras ou nas menos discriminadoras. As mais discriminadoras não contratariam, porque a desutilidade seria muito grande. Assim, o “último” trabalhador contratado pela firma no limite da discriminação é o que vai determinar o salário de equilíbro. Todos competem igualmente por essa vaga e ela determina o diferencial de salário. Ou seja, é a empresa marginal na discriminação, e não da discriminação média, que determina o diferencial. E a empresa marginal depende do número de trabalhadores negros e da distribuição da discriminação entre firmas. Do ponto de vista teórico, o problema desse modelo é que empresas sem preconceito seriam mais lucrativas e deveriam dominar o mercado, eliminando assim a discriminação. Mais recentemente, em particular a partir do trabalho de Black (1995), a literatura tem explicado como pode haver persistência de desigualdade salarial entre grupos raciais mesmo em um mercado competitivo. A ideia é introduzir fricção no mercado de trabalho, isto é, trabalhadoras não acham emprego imediatamente. Precusam procurar até achar, e esse tempo é custoso. Portanto, elas possuem um salário de reserva, que é quanto esperam ganhar se continuarem procurando emprego, em vez de aceitaram uma proposta qualquer. É como o valor de continuação do jogo que vimos no modelo de Baron-Ferejohn de barganhas no legislativo. Se a trabalhadora negra sabe que poderá receber ofertas piores de empresas discriminadoras, demorará mais tempo que uma pessoa branca para arranjar um emprego que pague sua produtividade marginal. Como o tempo é custoso, isso rebaixa seu salário de reserva, tornando um equilíbrio haver diferencial de salários permanentes. Portanto, o efeito se dá via rebaixamento de expectativas. 13.4 Discriminação estatística Phelps (1972) propôs uma explicação alternativa para a discriminação. A ideia é que não observamos diretamente a produtividade dos trabalhadores, e precisamos usar sinais correlacionados com produtividade. Eis o modelo. Cada trabalhador tem uma identidade \\(j \\in \\{B,W\\}\\) (chamado de tipo) e uma produtividade \\(p\\), que vem de uma distribuição \\(N(\\mu_j, \\sigma^2_j)\\). Um empregador quer contratar a trabalhadora e pagar o salário igual à produtividade dela. Entretando, o empregador só observa a identidade e um sinal da produtividade (digamos, currículo ou resultado de um teste): \\(\\theta = p + e\\), em que \\(e \\sim N(0, \\sigma^2_{ej})\\). É possível mostrarˆ[a derivação encontra-se ao final do capítulo, para os interessados] que a produtividade esperada da trabalhadora é: \\(\\mathbb{E}(p|\\theta, j) = \\theta \\frac{\\sigma^2_j}{\\sigma^2_j + \\sigma^2_{ej}} + \\mu_j \\frac{\\sigma^2_{ej}}{\\sigma^2_j + \\sigma^2_{ej}}\\) Digamos que \\(e = 0\\), isto é, a variância é zero, ou seja, o sinal é sem ruído. Então, a produtividade inferida independe da identidade. Em particular, \\(\\mathbb{E}(p|\\theta, j) = \\theta \\frac{\\sigma^2_j}{\\sigma^2_j} + \\mu_j\\frac{0}{\\sigma^2_j} = \\theta = p\\). Ou seja, todas as trabalhadoras recebem igual à sua produtividade, independentemente da sua identidade. 13.4.1 Definição de discriminação estatística individual “Uma abordagem possível é definir a discriminação em um nível individual: a discriminação estatística surge quando duas pessoas, com o mesmo resultado observável (realização do sinal θ), mas com identidades diferentes, recebem inferências de produtividade diferentes – e, portanto, salários diferentes – do empregador.” Se por outro lado o ruído é diferente de zero, então a produtividade inferida vai diferir entre os grupos. “Por exemplo, suponha que \\(\\sigma^2_B &gt; \\sigma^2_W\\), de forma que o sinal é mais ruidoso para os indivíduos do grupo B. A inferência de produtividade feita pelo empregador é, portanto, mais sensível ao sinal para o grupo W do que para o grupo B. Especificamente, uma pessoa do grupo B que obtém uma realização de sinal acima da média é interpretada como tendo uma produtividade esperada mais baixa do que uma pessoa do grupo W com a mesma realização de sinal. Por outro lado, uma pessoa do grupo B com uma realização de sinal abaixo da média é vista como mais produtiva do que se pertencesse ao grupo W.” Aqui, a discriminação ocorre ao nível individual, mas não no nível de grupo. Ou seja, há discriminação positiva e negativa que na média se compensam ao nível do grupo. Uma forma de se obter discriminação estatística ao nível do grupo é determinar que a escala salarial é não linear com relação Pa produtividade. Se, por exemplo, supusermos que empregadores são avessos ao risco, é possível mostrar que isso gera escala não-linear e, como consequência, trabalahdores do grupo \\(W\\) ganhando salários maiores, em média, do que trabalhadores do grupo \\(B\\). 13.5 Equilíbrio da discriminação estatística Um ponto mencionado inicialmente por Arrow é que, antecipando que serão remunerados diferentes, indivíduos de grupos diferentes podem tomar decisões diferentes de investimento em capital humano, criando profecias auto-realizáveis. O modelo de Coate and Loury (1993) é um exemplo desse tipo de situação Empresas possuem tarefas simples e complexas e precisam contratar um continuum de trabalhadores. Eles podem ser habilidosos (skilled - S) ou não-habilidosos (Unskilled- U) e pertencem a duas identidades, \\(B\\) e \\(W\\). Se o trabalhador é alocado para a tarefa simples, o salário é \\(0\\) e a firma tem lucro \\(0\\). Se for alocado para um trabalho complexo, recebe um salário positivo. A firma tem um payoff positivo se a pessoa no trabalho complexo é S, e negativo se é U. “Para calcular a probabilidade posterior bayesiana de que um trabalhador é qualificado, a firma usa a realização do sinal observado, bem como um prévio, que é dado pela suposição da firma sobre a proporção geral de trabalhadores que escolheram investir na aquisição de habilidades. Essa suposição prévia também pode depender da identidade do trabalhador – por exemplo, a firma pode pensar que trabalhadores do grupo W investem na aquisição de habilidades em uma proporção maior do que trabalhadores do grupo B. É aqui que a natureza autorrealizável do modelo se manifesta: Porque a suposição prévia da firma afeta sua interpretação do sinal imperfeito de habilidade, os incentivos para investir na aquisição de habilidades são, eles próprios, afetados pela suposição da firma. Em equilíbrio, a suposição da firma deve ser precisa. No entanto, devido à complementaridade entre a suposição prévia da firma e as ações dos trabalhadores, pode haver múltiplos equilíbrios, com diferentes níveis de investimento. De fato, Coate e Loury (1993) mostram que, sob algumas suposições sobre a distribuição dos custos de investimento, existem pelo menos dois desses equilíbrios. Além disso, os múltiplos equilíbrios são classificados por Pareto, de forma que tanto as firmas quanto os trabalhadores estão em melhor situação em equilíbrios onde as firmas (corretamente) supõem que uma proporção maior de trabalhadores adquire habilidades.” Moro and Norman (2004), relax Coate and Loury’s (1993) assumption of exogenous wages. They propose a general equilibrium model of statistical discrimination, where wages offered to workers of different identities are interdependent. Among other results, the authors show that the dominant identity may benefit from the discriminatory treatment of the disadvantaged group. statistical discrimination arises because workers of different identities play different equilibria. 13.5.1 Novas modificações Discuto agora um exemplo de modificação recente que ilustra como a literatura tem avançado, a partir do estudo de Bardhi, Guo e Strulovici (2023). Esses cenários representam propriedades inerentes ao tipo de tarefa realizada em uma determinada empresa. Por exemplo, a pesquisa científica pode ser vista como um ambiente de aprendizado por conquistas, onde a maioria das notícias observadas – como um novo artigo publicado ou uma concessão de bolsa – são notícias positivas sobre o tipo subjacente do pesquisador. Por outro lado, o trabalho de um vigia noturno ou de um piloto de avião ocorre em ambientes de aprendizado por falhas, onde as notícias observadas publicamente são geralmente negativas – por exemplo, uma tentativa de roubo bem-sucedida ou um pouso de emergência. O principal resultado de Bardhi, Guo e Strulovici (2023) é que, dependendo do ambiente de aprendizado subjacente, uma pequena diferença na qualidade esperada ex-ante entre o trabalhador A e o trabalhador B pode levar a grandes diferenças nas trajetórias de carreira e, consequentemente, nos ganhos. 13.5.2 Ambiente de Aprendizado por Conquistas (Breakthrough Learning): Descrição: Inicialmente, a firma aloca o trabalhador A (com expectativa ligeiramente superior) para a tarefa. Se A realiza uma conquista (como um sucesso significativo), é identificado como de alta qualidade e continua na tarefa permanentemente. Se nenhuma conquista é observada, a avaliação da firma sobre A diminui gradualmente até igualar a expectativa sobre o trabalhador B. A partir desse ponto, A e B são tratados de forma igual. Implicação: Quando as diferenças iniciais entre A e B são pequenas, o tempo para que A e B sejam tratados de forma simétrica é curto. Portanto, as trajetórias de carreira e recompensas esperadas para A e B são quase iguais, tornando a discriminação no início da carreira auto-corretiva. 13.5.3 Ambiente de Aprendizado por Falhas (Breakdown Learning): Descrição: A firma começa alocando o trabalhador A. Se A falha (como um incidente significativo), é identificado como de baixa qualidade e substituído permanentemente por B. Se nenhuma falha ocorre, A continua sendo empregado e sua avaliação melhora. B só é considerado se A falhar, resultando em B raramente ter a chance de mostrar suas habilidades. Implicação: Nesse cenário, a discriminação inicial entre A e B pode se agravar ao longo do tempo. Mesmo que A e B sejam quase iguais, A e B terão trajetórias de carreira e recompensas esperadas muito diferentes, com A mantendo uma vantagem considerável. Conclusões do Trecho: Heidhues, Köszegi e Strack (2019) também propõem um modelo comportamental de interpretação dos resultados individuais, onde as diferenças entre grupos são provocadas pela consideração do observador de que é possível que os resultados dos indivíduos sejam afetados pela discriminação em nível de grupo. Novamente, a discriminação é provocada pela existência de alguma distinção percebida entre grupos de identidade em primeiro lugar. Contexto do Modelo: Sociedade e Grupos: A sociedade é composta por múltiplos grupos que podem se sobrepor. Cada indivíduo (agente) é parte de um desses grupos, compete com outros grupos ou é um observador neutro. Resultados de Reconhecimento: Os resultados observados (como conquistas ou status) são influenciados tanto pelas habilidades subjacentes dos indivíduos quanto por algum grau de incerteza ou ruído. Percepção da Discriminação: Interpretação do Observador: Os indivíduos acreditam que seus resultados e os de outros podem ser influenciados por discriminação em nível de grupo. Isso significa que eles pensam que alguns grupos podem ser favorecidos ou desfavorecidos. Objetivo do Aprendizado: Os agentes tentam descobrir os verdadeiros padrões de discriminação observando os resultados, como um aprendiz Bayesiano que atualiza suas crenças com base em novas evidências. Comportamento de Excesso de Confiança: Crença Sobre Habilidade Própria: Cada agente tem uma crença excessivamente confiante sobre sua própria habilidade. Eles acreditam que são mais capazes do que realmente são. Teimosia: Mesmo quando os resultados observados não correspondem às suas expectativas excessivamente confiantes, os agentes teimosamente mantêm a crença de que são altamente capazes. Impacto no Aprendizado de Discriminação: Subestimação de Habilidade: Quando os agentes observam que seus resultados são inferiores às suas expectativas, eles não revisam suas crenças sobre sua própria habilidade (devido à sua teimosia excessivamente confiante). Atualização de Crenças Sobre Discriminação: Em vez disso, eles ajustam suas crenças sobre a discriminação na sociedade. Eles tendem a acreditar que a discriminação é maior contra os grupos aos quais pertencem e menor contra os grupos com os quais competem. Longo Prazo: A longo prazo, isso leva a uma superestimação da discriminação contra seus próprios grupos e uma subestimação da discriminação contra grupos competidores. Resumo: Crenças Iniciais e Observações: Os indivíduos começam com uma crença teimosamente excessiva sobre suas próprias habilidades. Eles observam os resultados de reconhecimento (como conquistas) na sociedade. Interpretação de Resultados: Quando seus próprios resultados não correspondem às suas expectativas, eles não ajustam suas crenças sobre sua própria habilidade, mas sim sobre a discriminação. Efeito na Percepção da Discriminação: Isso leva à percepção de que a discriminação é maior contra os grupos aos quais pertencem e menor contra os grupos com os quais competem. Implicações Sociais: Esse processo de aprendizado tendencioso pode explicar por que as pessoas frequentemente superestimam a discriminação contra si mesmas e subestimam a discriminação contra os outros, mesmo quando os dados observacionais podem não suportar essas crenças. 13.6 Críticas Small and Pager (2020) recognize that research in economics – both empirical and theoretical – has traditionally adopted either the taste-based or the statistical discrimination perspectives, focusing substantially on assessing which approach is a more appropriate description of discrimination as a sociological phenomenon. They go on to criticize this economic research agenda, arguing that it misses “what sociologists and others have called ‘institutional discrimination,’ ‘structural discrimination,’ and ‘institutional racism,’ which are all terms used to refer to the idea that something other than individuals may discriminate by race.” In their essay, they define “institutional discrimination” as “differential treatment that may be caused by organizational rules or by people following the law,” and say that it need not result from personal prejudice or from rational guesses on the basis of group characteristics. all either rooted on personal prejudices or based on rationally (or irrationally) biased beliefs. 13.6.1 Normas Sociais como instituições According to Young (2015), “As normas sociais são padrões de comportamento que se autoimpõem dentro de um grupo: todos se conformam, todos esperam que os outros se conformem, e todos desejam se conformar quando esperam que todos os outros se conformem. As normas sociais são frequentemente mantidas por múltiplos mecanismos, incluindo o desejo de coordenar, o medo de ser sancionado, a sinalização de pertencimento a um grupo, ou simplesmente seguir o exemplo dos outros.” 13.7 Discriminação institucional/sistêmica Bohren, Hull and Imas (2023) introduze uma noção de discriminação sistêmica, diferenciando da discriminação direta. Os autores apresentam um exemplo motivador que é útil. Na primeira etapa, um recrutador se encontra com um candidato potencial e faz uma avaliação. Esse recrutador é tendencioso e avalia consistentemente as candidatas do sexo feminino de forma menos favorável do que os candidatos do sexo masculino com habilidades iguais. Na segunda etapa, um gerente de contratação na empresa observa a avaliação do recrutador e toma a decisão de contratar. Suponha que um econometrista só consiga observar a segunda etapa do processo de contratação: ele vê as avaliações de todos os candidatos potenciais e as decisões de contratação. Analisando esses dados, o econometrista pode não encontrar diferenças estatisticamente significativas entre as probabilidades de contratação para candidatas femininas e candidatos masculinos, condicionadas à avaliação do recrutador. Nesse ponto, o econometrista pode concluir que o processo de contratação não é discriminatório, pois candidatos do sexo masculino e feminino com resultados observáveis iguais têm a mesma probabilidade de serem contratados. Bohren, Hull e Imas (2023) sugerem, em vez disso, que o econometrista deve concluir que “não há discriminação direta por parte do gerente de contratação.” ## Referências Gerard, F., Lagos, L., Severnini, E., &amp; Card, D. (2021). Assortative matching or exclusionary hiring? The impact of employment and pay policies on racial wage differences in Brazil. American Economic Review, 111(10), 3418-3457. 13.8 Derivação do modelo de Phelps. Sejam \\[ p \\sim N(\\mu_j, \\sigma_j^2) \\quad \\text{e} \\quad e \\sim N(0, \\sigma_{ej}^2), \\] com o sinal observado definido por \\[ \\theta = p + e. \\] A distribuição normal de \\(p\\) dada acima pode ser pensada como uma priori, cuja densidade tem fórmula igual a: \\[ f(p) = \\frac{1}{\\sqrt{2\\pi\\sigma_j^2}} \\exp\\left(-\\frac{(p-\\mu_j)^2}{2\\sigma_j^2}\\right). \\] Assim, podemos aplicar o teorema de Bayes, que diz que a probabilidade a posteriori, após observar um sinal, é proporcional à priori multiplicado pela verossimilhança. Esta, por sua vez, é dada por: Dado que o sinal é definido por \\(\\theta = p + e\\) e \\(e \\sim N(0, \\sigma_{ej}^2)\\), temos que \\[ \\theta|p \\sim N(p, \\sigma_{ej}^2). \\] Assim, a função de densidade condicional é: \\[ f(\\theta|p) = \\frac{1}{\\sqrt{2\\pi \\sigma_{ej}^2}} \\exp\\left(-\\frac{(\\theta-p)^2}{2\\sigma_{ej}^2}\\right). \\] Pelo teorema de Bayes: \\[ f(p|\\theta,j) \\propto f(\\theta|p) f(p) \\propto \\exp\\left(-\\frac{(p-\\mu_j)^2}{2\\sigma_j^2} -\\frac{(\\theta-p)^2}{2\\sigma_{ej}^2}\\right). \\] Reescrevendo o expoente: \\[ -\\frac{(p-\\mu_j)^2}{2\\sigma_j^2} -\\frac{(\\theta-p)^2}{2\\sigma_{ej}^2} = -\\frac{1}{2}\\left[\\frac{(p-\\mu_j)^2}{\\sigma_j^2} + \\frac{(p-\\theta)^2}{\\sigma_{ej}^2}\\right]. \\] Observando que \\[ \\frac{(p-\\mu_j)^2}{\\sigma_j^2} + \\frac{(p-\\theta)^2}{\\sigma_{ej}^2} = \\left(\\frac{1}{\\sigma_j^2}+\\frac{1}{\\sigma_{ej}^2}\\right)p^2 - 2\\left(\\frac{\\mu_j}{\\sigma_j^2}+\\frac{\\theta}{\\sigma_{ej}^2}\\right)p + \\text{constante}, \\] definindo \\[ A = \\frac{1}{\\sigma_j^2}+\\frac{1}{\\sigma_{ej}^2} \\quad \\text{e} \\quad B = \\frac{\\mu_j}{\\sigma_j^2}+\\frac{\\theta}{\\sigma_{ej}^2}, \\] podemos completar o quadrado: \\[ \\frac{(p-\\mu_j)^2}{\\sigma_j^2} + \\frac{(p-\\theta)^2}{\\sigma_{ej}^2} = A\\left[p - \\frac{B}{A}\\right]^2 + \\text{constante}. \\] Assim, \\[ f(p|\\theta,j) \\propto \\exp\\left(-\\frac{A}{2}\\left[p - \\frac{B}{A}\\right]^2\\right), \\] o que mostra que \\(p|\\theta,j \\sim N\\left(\\mu_{\\text{post}},\\sigma^2_{\\text{post}}\\right)\\), onde \\[ \\mu_{\\text{post}} = \\frac{B}{A} = \\frac{\\frac{\\mu_j}{\\sigma_j^2}+\\frac{\\theta}{\\sigma_{ej}^2}}{\\frac{1}{\\sigma_j^2}+\\frac{1}{\\sigma_{ej}^2}} \\] e \\[ \\sigma^2_{\\text{post}} = \\frac{1}{A} = \\frac{\\sigma_j^2\\sigma_{ej}^2}{\\sigma_j^2+\\sigma_{ej}^2}. \\] Simplificando a média: \\[ \\mu_{\\text{post}} = \\frac{\\mu_j\\sigma_{ej}^2+\\theta\\sigma_j^2}{\\sigma_j^2+\\sigma_{ej}^2} = \\frac{\\sigma_j^2}{\\sigma_j^2+\\sigma_{ej}^2}\\theta + \\frac{\\sigma_{ej}^2}{\\sigma_j^2+\\sigma_{ej}^2}\\mu_j. \\] Portanto, a esperança condicional é: \\[ \\mathbb{E}(p|\\theta,j) = \\mu_{\\text{post}} = \\frac{\\sigma_j^2}{\\sigma_j^2+\\sigma_{ej}^2}\\theta + \\frac{\\sigma_{ej}^2}{\\sigma_j^2+\\sigma_{ej}^2}\\mu_j. \\] "]]
